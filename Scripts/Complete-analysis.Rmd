---
title: "Complete FTLD Analysis Workflow"
author: "Joaquim Aumatell"
date: "2025-01-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries

```{r libraries, message=FALSE, warning=FALSE}
library(ggplot2)
library(openxlsx)
library(dplyr)
library(coin)
library(AnnotationDbi)
library(org.Hs.eg.db)
library(EnsDb.Hsapiens.v86)
library(Seurat)
library(edgeR)
library(GO.db)
library(xlsx)
suppressWarnings(library(BayesPrism))
```

This document consolidates the analytical workflow across bulk and single-cell datasets. Each numbered section mirrors the repository folder structure, embeds the corresponding R scripts verbatim, and reserves space for figures that summarize intermediate and final results.

## 0. SVA

Estimate surrogate variables (SVs) for each bulk RNA-seq cohort to control for unwanted variation prior to downstream analyses.

Scripts included in this step:

-   `0. SVA/SVA_FTLD_C9.R`
-   `0. SVA/SVA_FTLD_Pottier.R`
-   `0. SVA/SVA_FTLD_Rimmod.R`
-   `0. SVA/SVA_FTLD_TDP.R`
-   `0. SVA/SVA_FTLD_tau.R`

```{r code_0_sva_sva_ftld_c9_r, eval=FALSE}
library("sva")
library("DESeq2")

coldataTAU <- read.xlsx('/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx', sep = "\t")
ctsTAU <- as.matrix(read.csv('/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/DATA/C9orf72.csv', row.names = 1))

rownames(coldataTAU) <- coldataTAU$sample.ID
colnames(ctsTAU) <- gsub("X", "", colnames(ctsTAU))
common_IDs <- intersect(rownames(coldataTAU), colnames(ctsTAU))

coldataTAU <- coldataTAU[common_IDs,]
ctsTAU <- ctsTAU[, common_IDs]

# PROCESS 
ddsTAU <- DESeqDataSetFromMatrix(countData = round(ctsTAU), colData = coldataTAU, design = ~ group.ID)

idx <- rowSums( counts(ddsTAU, normalized=FALSE) >= 10 ) >= 20

ddsTAU_Filter <- ddsTAU[idx,]

ddsTAU_Filter_ <- DESeq(ddsTAU_Filter)

dat <- counts(ddsTAU_Filter_, normalized=TRUE)

mod <- model.matrix(~ group.ID, colData(ddsTAU_Filter_))

mod0 <- model.matrix(~ 1, colData(ddsTAU_Filter_))

num.sv(dat, mod) #Aquí ens diu quants cal aplicar#

svseqTau <- svaseq(dat, mod, mod0)

ddsTAU_Filter_SV2 <- ddsTAU_Filter_

ddsTAU_Filter_SV2$SV1 <- svseqTau$sv[,1]

ddsTAU_Filter_SV2$SV2 <- svseqTau$sv[,2]


###ddsTAU_Filter_SV2 conté ID, SV1 i SV2 (els dos SV que necessitem) ###

sva_dataframe_IDs <- rownames(coldataTAU)
sva_dataframe_disease <- coldataTAU[,"DiseaseCode"]
sva_dataframe_sv1 <- svseqTau$sv[,1]

sva_dataframe <- data.frame(
  ID = sva_dataframe_IDs,
  Disease = sva_dataframe_disease,
  SV1 = sva_dataframe_sv1,
  stringsAsFactors = FALSE
)

write.table(sva_dataframe, file = "/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/SURROGATED_VARIABLES/C9.csv", sep = "\t", row.names = FALSE, quote = FALSE)
```

```{r code_0_sva_sva_ftld_pottier_r, eval=FALSE}
library("sva")
library("DESeq2")

coldataTAU <- read.delim('/media/jaumatell/datos/URI/BAYESPRISM_12_3/NEW_BULK/METADATA/Sample_info.txt', sep = "\t", row.names = 1)
ctsTAU <- as.matrix(read.csv('/media/jaumatell/datos/URI/BAYESPRISM_12_3/NEW_BULK/DATA/merged_gene_count_FCX.csv',sep=",", row.names = 1))
ctsTAU <- ctsTAU[,-c(1,2,3,4,5,6)]

coldataTAU <- coldataTAU[coldataTAU$GROUP!= "FTLD-TDP-C", ]

colnames(ctsTAU) <- gsub("\\.", "-", colnames(ctsTAU))
common_IDs <- intersect(rownames(coldataTAU), colnames(ctsTAU))

coldataTAU <- coldataTAU[common_IDs,]
ctsTAU <- ctsTAU[, common_IDs]

ctsTAU <- apply(ctsTAU, 2, as.numeric)


# PROCESS 
ddsTAU <- DESeqDataSetFromMatrix(countData = round(ctsTAU), colData = coldataTAU, design = ~ GROUP)

idx <- rowSums( counts(ddsTAU, normalized=FALSE) >= 10 ) >= 20

ddsTAU_Filter <- ddsTAU[idx,]

ddsTAU_Filter_ <- DESeq(ddsTAU_Filter)

dat <- counts(ddsTAU_Filter_, normalized=TRUE)

mod <- model.matrix(~ GROUP, colData(ddsTAU_Filter_))

mod0 <- model.matrix(~ 1, colData(ddsTAU_Filter_))

num.sv(dat, mod) #Aquí ens diu quants cal aplicar#

svseqTau <- svaseq(dat, mod, mod0)

ddsTAU_Filter_SV2 <- ddsTAU_Filter_

ddsTAU_Filter_SV2$SV1 <- svseqTau$sv[,1]

sva_dataframe_IDs <- rownames(coldataTAU)
sva_dataframe_disease <- coldataTAU[,"GROUP"]
sva_dataframe_sv1 <- svseqTau$sv[,1]

sva_dataframe <- data.frame(
  ID = sva_dataframe_IDs,
  Disease = sva_dataframe_disease,
  SV1 = sva_dataframe_sv1,
  stringsAsFactors = FALSE
)

write.table(sva_dataframe, file = "/media/jaumatell/datos/URI/BAYESPRISM_12_3/NEW_BULK/METADATA/SVA_correcte.csv", sep = "\t", row.names = FALSE, quote = FALSE)
```

```{r code_0_sva_sva_ftld_rimmod_r, eval=FALSE}
library("sva")
library("DESeq2")

coldataTAU <- read.delim('/media/jaumatell/datos/URI/PROJECTE_SEURAT_BP/RiMod/rimod_ftd_dataset_table_v3.txt', sep = "\t", row.names = 1)
ctsTAU <- as.matrix(read.csv('/media/jaumatell/datos/URI/PROJECTE_SEURAT_BP/RiMod/rnaseq_salmon_results/counts.csv',sep=",", row.names = 1))

common_IDs <- intersect(rownames(coldataTAU), colnames(ctsTAU))

coldataTAU <- coldataTAU[common_IDs,]
ctsTAU <- ctsTAU[, common_IDs]

# PROCESS 
ddsTAU <- DESeqDataSetFromMatrix(countData = round(ctsTAU), colData = coldataTAU, design = ~ DiseaseCode)

idx <- rowSums( counts(ddsTAU, normalized=FALSE) >= 10 ) >= 20

ddsTAU_Filter <- ddsTAU[idx,]

ddsTAU_Filter_ <- DESeq(ddsTAU_Filter)

dat <- counts(ddsTAU_Filter_, normalized=TRUE)

mod <- model.matrix(~ DiseaseCode, colData(ddsTAU_Filter_))

mod0 <- model.matrix(~ 1, colData(ddsTAU_Filter_))

num.sv(dat, mod) #Aquí ens diu quants cal aplicar#

svseqTau <- svaseq(dat, mod, mod0)

ddsTAU_Filter_SV2 <- ddsTAU_Filter_

ddsTAU_Filter_SV2$SV1 <- svseqTau$sv[,1]

#ddsTAU_Filter_SV2$SV2 <- svseqTau$sv[,2]


###ddsTAU_Filter_SV2 conté ID, SV1 i SV2 (els dos SV que necessitem) ###

sva_dataframe_IDs <- rownames(coldataTAU)
sva_dataframe_disease <- coldataTAU[,"DiseaseCode"]
sva_dataframe_sv1 <- svseqTau$sv[,1]

sva_dataframe <- data.frame(
  ID = sva_dataframe_IDs,
  Disease = sva_dataframe_disease,
  SV1 = sva_dataframe_sv1,
  stringsAsFactors = FALSE
)

write.table(sva_dataframe, file = "/media/jaumatell/datos/URI/BAYESPRISM_12_3/RIMOD_BULK/METADATA/SVA.csv", sep = "\t", row.names = FALSE, quote = FALSE)
```

```{r code_0_sva_sva_ftld_tdp_r, eval=FALSE}
library("sva")
library("DESeq2")
library(openxlsx)
coldataTAU <- read.xlsx('/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx', sheet = 1)
ctsTAU <- as.matrix(read.csv('/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/DATA/TDP.csv',sep=",", row.names = 1))

rownames(coldataTAU) <- coldataTAU$sample.ID
colnames(ctsTAU) <- gsub("X", "", colnames(ctsTAU))
common_IDs <- intersect(rownames(coldataTAU), colnames(ctsTAU))

coldataTAU <- coldataTAU[common_IDs,]
ctsTAU <- ctsTAU[, common_IDs]

# PROCESS 
ddsTAU <- DESeqDataSetFromMatrix(countData = round(ctsTAU), colData = coldataTAU, design = ~ group.ID)

idx <- rowSums( counts(ddsTAU, normalized=FALSE) >= 10 ) >= 20

ddsTAU_Filter <- ddsTAU[idx,]

ddsTAU_Filter <- estimateSizeFactors(ddsTAU_Filter, type = "poscounts")
ddsTAU_Filter <- DESeq(ddsTAU_Filter)


dat <- counts(ddsTAU_Filter_, normalized=TRUE)

mod <- model.matrix(~ group.ID, colData(ddsTAU_Filter_))

mod0 <- model.matrix(~ 1, colData(ddsTAU_Filter_))

num.sv(dat, mod) #Aquí ens diu quants cal aplicar#

svseqTau <- svaseq(dat, mod, mod0)

ddsTAU_Filter_SV2 <- ddsTAU_Filter_

ddsTAU_Filter_SV2$SV1 <- svseqTau$sv[,1]

ddsTAU_Filter_SV2$SV2 <- svseqTau$sv[,2]


###ddsTAU_Filter_SV2 conté ID, SV1 i SV2 (els dos SV que necessitem) ###

sva_dataframe_IDs <- rownames(coldataTAU)
sva_dataframe_disease <- coldataTAU[,"DiseaseCode"]
sva_dataframe_sv1 <- svseqTau$sv[,1]

sva_dataframe <- data.frame(
  ID = sva_dataframe_IDs,
  Disease = sva_dataframe_disease,
  SV1 = sva_dataframe_sv1,
  stringsAsFactors = FALSE
)

write.table(sva_dataframe, file = "/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/SURROGATED_VARIABLES/TDP.csv", sep = "\t", row.names = FALSE, quote = FALSE)
```

```{r code_0_sva_sva_ftld_tau_r, eval=FALSE}
library("sva")
library("DESeq2")

coldataTAU <- read.xlsx('/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx', sheet = 1)
ctsTAU <- as.matrix(read.csv('/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/DATA/tau.csv', row.names = 1))

rownames(coldataTAU) <- coldataTAU$sample.ID
colnames(ctsTAU) <- gsub("X", "", colnames(ctsTAU))
common_IDs <- intersect(rownames(coldataTAU), colnames(ctsTAU))

coldataTAU <- coldataTAU[common_IDs,]
ctsTAU <- ctsTAU[, common_IDs]

# PROCESS 
ddsTAU <- DESeqDataSetFromMatrix(countData = round(ctsTAU), colData = coldataTAU, design = ~ group.ID)

idx <- rowSums( counts(ddsTAU, normalized=FALSE) >= 10 ) >= 20

ddsTAU_Filter <- ddsTAU[idx,]

ddsTAU_Filter_ <- DESeq(ddsTAU_Filter)

dat <- counts(ddsTAU_Filter_, normalized=TRUE)

mod <- model.matrix(~ group.ID, colData(ddsTAU_Filter_))

mod0 <- model.matrix(~ 1, colData(ddsTAU_Filter_))

num.sv(dat, mod) #Aquí ens diu quants cal aplicar#

svseqTau <- svaseq(dat, mod, mod0)

ddsTAU_Filter_SV2 <- ddsTAU_Filter_

ddsTAU_Filter_SV2$SV1 <- svseqTau$sv[,1]

#ddsTAU_Filter_SV2$SV2 <- svseqTau$sv[,2]


###ddsTAU_Filter_SV2 conté ID, SV1 i SV2 (els dos SV que necessitem) ###

sva_dataframe_IDs <- rownames(coldataTAU)
sva_dataframe_disease <- coldataTAU[,"group.ID"]
sva_dataframe_sv1 <- svseqTau$sv[,1]

sva_dataframe <- data.frame(
  ID = sva_dataframe_IDs,
  Disease = sva_dataframe_disease,
  SV1 = sva_dataframe_sv1,
  stringsAsFactors = FALSE
)

write.table(sva_dataframe, file = "/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/SURROGATED_VARIABLES/tau.csv", sep = "\t", row.names = FALSE, quote = FALSE)
```

```{r fig_0_sva_1, echo=FALSE, eval=FALSE}
# knitr::include_graphics("figures/fig_0_sva_1.png")
```

```{r fig_0_sva_2, echo=FALSE, eval=FALSE}
# knitr::include_graphics("figures/fig_0_sva_2.png")
```

## 1. Bulk DEA

Run edgeR likelihood-ratio tests on bulk RNA-seq counts to identify genes differentially expressed between case and control groups.

Scripts included in this step:

-   `1. Bulk DEA/1.Bulk_DEA(All).R`

```{r code_1_bulk_dea_1_bulk_deaall_r, eval=FALSE}
# EDGER on Bulk RNASEQ LRT

library(edgeR)
library(dplyr)
library(GO.db)
library(xlsx)

################################################################################
# Paths and parameters
BULK_COUNTS_PATH <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/DATA/TDP.csv"  # Path to bulk RNA-seq count matrix CSV
CASE_LEGEND <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx"
OUTPUT_DIRECTORY <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/EDGER/BULK_DEA/FTLD/TDP_LRT"
REFERENCE_GROUP <- "Healthy"
CONDITIONS <- "TDP"  # Same condition(s) you want to test

################################################################################

# Load sample metadata
case_legend <- read.xlsx(CASE_LEGEND, sheetIndex = 1)
case_legend$sample.ID <- paste0("X", case_legend$sample.ID)
case_legend$group_ID <- factor(case_legend$group.ID)
case_legend$group.ID <- NULL

# Load bulk count data
bulk_data <- read.csv(BULK_COUNTS_PATH, row.names = 1)
# Make sure rownames (sample IDs) match those in case_legend
bulk_data <- t(bulk_data)

# Keep only samples in both case_legend and bulk_data
common_samples <- intersect(case_legend$sample.ID, rownames(bulk_data))
case_legend <- case_legend[match(common_samples, case_legend$sample.ID), ]
bulk_data <- bulk_data[common_samples, ]

# Create output directory
if (!file.exists(OUTPUT_DIRECTORY)) {
  dir.create(OUTPUT_DIRECTORY, recursive = TRUE)
}

# Process each condition (here just one condition "TDP")
for (condition in CONDITIONS) {
  
  condition_folder <- file.path(OUTPUT_DIRECTORY, condition)
  if (!file.exists(condition_folder)) {
    dir.create(condition_folder, recursive = TRUE)
  }
  
  tryCatch({
    # Subset metadata for groups of interest
    comparison_data <- case_legend[case_legend$group_ID %in% c(REFERENCE_GROUP, condition), ]
    comparison_data$group_ID <- relevel(factor(comparison_data$group_ID, levels = c(REFERENCE_GROUP, condition)), ref = condition)
    comparison_data <- comparison_data[order(comparison_data$group_ID), ]
    
    # Select bulk samples present in metadata
    common_ids <- intersect(comparison_data$sample.ID, rownames(bulk_data))
    bulk_subset <- bulk_data[common_ids, ]
    bulk_ordered <- bulk_subset[match(comparison_data$sample.ID, rownames(bulk_subset)), ]
    
    # Replace missing values with small value (if any)
    bulk_ordered[is.na(bulk_ordered)] <- 1e-8
    
    group <- factor(comparison_data$group_ID)
    y <- DGEList(counts = t(bulk_ordered), group = group)  # transpose counts
    
    # Filter low expression genes
    keep <- filterByExpr(y, group = group)
    y <- y[keep, , keep.lib.sizes=FALSE]
    
    # Normalize
    y <- calcNormFactors(y)
    
    # Plot average log CPM
    AveLogCPM <- aveLogCPM(y)
    y <- normLibSizes(y)
    
    # MD plot
    plot_filename <- file.path(condition_folder, "MD_plot.png")
    png(file = plot_filename)
    plotMD(y, column = 1)
    abline(h = 0, col = "red", lty = 2, lwd = 2)
    dev.off()
    
    # Design matrix
    design <- model.matrix(~ 0 + group)
    colnames(design) <- levels(group)
    
    # Estimate dispersion
    y <- estimateDisp(y, design)
    
    # Fit model
    fit <- glmFit(y, design)
    
    # Contrast
    contrast <- makeContrasts(contrasts = paste0(make.names(condition), " - ", make.names(REFERENCE_GROUP)), levels = design)
    res <- glmLRT(fit, contrast = contrast, coef = 2)
    
    # Decide DE
    is.de <- decideTests(res, adjust.method = "fdr", p.value = 0.05, lfc = 0)
    
    # Add adjusted p-values and results
    results_table <- res$table
    results_table$adj_pval <- p.adjust(results_table$PValue, method = "fdr")
    results_table <- cbind(results_table, data.frame(is.de))
    
    # Save results
    write.csv(results_table, file = file.path(condition_folder, "results_adj_bulk.csv"))
    
    # Histogram plot of AveLogCPM
    plot_filename <- file.path(condition_folder, "histogram_plot.png")
    png(file = plot_filename)
    hist(AveLogCPM)
    dev.off()
    
    # BCV plot
    plot_filename <- file.path(condition_folder, "BCV_plot.png")
    png(file = plot_filename)
    plotBCV(y)
    dev.off()
    
    # MD plot with DE status (volcano-like)
    plot_filename <- file.path(condition_folder, "MD_res_plot.png")
    png(file = plot_filename)
    plotMD(res, status = is.de)
    dev.off()
    
    # Heatmap top DE genes
    logCPM <- cpm(y, prior.count = 2, log = TRUE)
    tr <- glmTreat(fit, contrast = contrast, lfc = log2(1.5))
    o <- order(tr$table$PValue)
    top_genes <- head(o, 30)
    logCPM_top <- logCPM[top_genes, ]
    
    plot_filename <- file.path(condition_folder, "Heatmap.png")
    png(file = plot_filename)
    coolmap(logCPM_top, margins = c(7, 7), lhei = c(1, 6), lwid = c(1, 3))
    dev.off()
    
  }, error = function(e) {
    print(paste("Error processing condition:", condition))
    print(e)
  })
}


################################################################################
# NEW LRTFIT

# EDGER on Bulk RNASEQ
library(edgeR)
library(dplyr)
library(GO.db)
library(xlsx)

BULK_COUNTS_PATH <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/NEW_BULK/DATA/merged_gene_count_FCX.csv"
CASE_LEGEND <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/NEW_BULK/METADATA/Sample_info.txt"
OUTPUT_DIRECTORY <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/EDGER/BULK_DEA/NEW_LRT_SVAcorrect/"
SURROGATE_VARIABLES <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/NEW_BULK/METADATA/SVA_correcte.csv"
REFERENCE_GROUP <- "Healthy"
CONDITIONS <- "TDP"

# Load metadata
case_legend <- read.delim(CASE_LEGEND, row.names = 1, sep = "\t")
case_legend$sample.ID <- gsub("-", "\\.", rownames(case_legend))
case_legend <- case_legend[case_legend$GROUP != "FTLD-TDP-C", ]
case_legend$GROUP[case_legend$GROUP == "Control"] <- "Healthy"
case_legend$GROUP[case_legend$GROUP != "Healthy"] <- "TDP"
case_legend$group_ID <- factor(case_legend$GROUP)


# Load surrogate variables 
surrogate_variables <- read.csv(SURROGATE_VARIABLES, row.names = 1, sep = "\t")
case_legend$rn <- rownames(case_legend)
surrogate_variables$rn <- rownames(surrogate_variables)

case_legend <- merge(case_legend, surrogate_variables, by.x = "rn", by.y = "rn")
case_legend$rn <- NULL
surrogate_variables$rn <- NULL

# Load bulk 
bulk_raw <- read.csv(BULK_COUNTS_PATH, row.names = 1)
bulk_raw <-t(bulk_raw)
colnames(bulk_raw) <- bulk_raw["GeneName", ]
bulk_data <- bulk_raw[!(rownames(bulk_raw) %in% c("Chromosome", "Start", "End", "Length", "GeneName", "GeneBiotype")), ]
rownames(bulk_data) <- gsub("-", ".", rownames(bulk_data))

common_samples <- intersect(case_legend$sample.ID, rownames(bulk_data))
case_legend <- case_legend[match(common_samples, case_legend$sample.ID), ]
bulk_data <- bulk_data[common_samples, ]
rownames(bulk_data) <- common_samples
colnames_bulk <- colnames(bulk_data)
rownames_bulk <- rownames(bulk_data)
bulk_data <- as.data.frame(apply(bulk_data, 2, function(x) as.numeric(trimws(x))))

colnames(bulk_data) <-colnames_bulk
rownames(bulk_data) <- rownames_bulk

if (!file.exists(OUTPUT_DIRECTORY)) {
  dir.create(OUTPUT_DIRECTORY, recursive = TRUE)
}

for (condition in CONDITIONS) {
  condition_folder <- file.path(OUTPUT_DIRECTORY, condition)
  if (!file.exists(condition_folder)) {
    dir.create(condition_folder, recursive = TRUE)
  }

  tryCatch({
    comparison_data <- case_legend[case_legend$group_ID %in% c(REFERENCE_GROUP, condition), ]
    comparison_data$group_ID <- relevel(factor(comparison_data$group_ID, levels = c(REFERENCE_GROUP, condition)), ref = condition)
    comparison_data <- comparison_data[order(comparison_data$group_ID), ]

    common_ids <- intersect(comparison_data$sample.ID, rownames(bulk_data))
    bulk_subset <- bulk_data[common_ids, ]
    bulk_ordered <- bulk_subset[match(comparison_data$sample.ID, rownames(bulk_subset)), ]
    bulk_ordered[is.na(bulk_ordered)] <- 1e-8

    group <- factor(comparison_data$group_ID)
    y <- DGEList(counts = t(bulk_ordered), group = group)

    keep <- filterByExpr(y, group = group)
    y <- y[keep, , keep.lib.sizes = FALSE]
    y <- calcNormFactors(y)
    AveLogCPM <- aveLogCPM(y)
    y <- normLibSizes(y)

    png(file.path(condition_folder, "MD_plot.png"))
    plotMD(y, column = 1)
    abline(h = 0, col = "red", lty = 2, lwd = 2)
    dev.off()

    design <- model.matrix(~ 0 + group + comparison_data$SV1, data = comparison_data)
    colnames(design) <- c(levels(group),"SV1")
    y <- estimateDisp(y, design)
    fit <- glmFit(y, design)
    contrast <- makeContrasts(contrasts = paste0(make.names(condition), " - ", make.names(REFERENCE_GROUP)), levels = design)
    res <- glmLRT(fit, contrast = contrast, coef = 2)
    is.de <- decideTests(res, adjust.method = "fdr", p.value = 0.05, lfc = 0)

    results_table <- res$table
    results_table$adj_pval <- p.adjust(results_table$PValue, method = "fdr")
    results_table <- cbind(results_table, data.frame(is.de))
    write.csv(results_table, file = file.path(condition_folder, "results_adj_bulk.csv"))

    png(file.path(condition_folder, "histogram_plot.png"))
    hist(AveLogCPM)
    dev.off()

    png(file.path(condition_folder, "BCV_plot.png"))
    plotBCV(y)
    dev.off()

    png(file.path(condition_folder, "MD_res_plot.png"))
    plotMD(res, status = is.de)
    dev.off()

    # logCPM <- cpm(y, prior.count = 2, log = TRUE)
    # tr <- glmTreat(fit, contrast = contrast, lfc = log2(1.5))
    # o <- order(tr$table$PValue)
    # top_genes <- head(o, 30)
    # logCPM_top <- logCPM[top_genes, ]
    # 
    # png(file.path(condition_folder, "Heatmap.png"))
    # coolmap(logCPM_top, margins = c(7, 7), lhei = c(1, 6), lwid = c(1, 3))
    # dev.off()

  }, error = function(e) {
    print(paste("Error processing condition:", condition))
    print(e)
  })
}



################################################################################
# FTLD C9

# EDGER on Bulk RNASEQ
library(edgeR)
library(dplyr)
library(GO.db)
library(xlsx)

BULK_COUNTS_PATH <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/DATA/C9orf72.csv"
CASE_LEGEND <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx"
OUTPUT_DIRECTORY <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/EDGER/BULK_DEA/FTLD_C9_sv"
SURROGATE_VARIABLES <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/SURROGATED_VARIABLES/SV1_C9_HC_QUIM.csv"
REFERENCE_GROUP <- "Healthy"
CONDITIONS <- "C9orf72"

# Load metadata
case_legend <- read.xlsx(CASE_LEGEND, row.names = 1, sheetIndex = 1)
case_legend$group_ID <- factor(case_legend$group.ID)

# Load surrogate variables 
surrogate_variables <- read.csv(SURROGATE_VARIABLES, row.names = 1, sep = ",")
case_legend$rn <- rownames(case_legend)
rownames(surrogate_variables) <- gsub("long", "", rownames(surrogate_variables))
surrogate_variables$rn <- rownames(surrogate_variables)

case_legend <- merge(case_legend, surrogate_variables, by.x = "rn", by.y = "rn")
case_legend$sample.ID <- case_legend$rn 
surrogate_variables$rn <- NULL

# Load bulk 
bulk_raw <- read.csv(BULK_COUNTS_PATH, row.names = 1)
bulk_raw <-t(bulk_raw)
rownames(bulk_raw) <- gsub("X", "", rownames(bulk_raw))
colnames(bulk_raw) <- bulk_raw["GeneName", ]
bulk_data <- bulk_raw[!(rownames(bulk_raw) %in% c("Chromosome", "Start", "End", "Length", "GeneName", "GeneBiotype")), ]
rownames(bulk_data) <- gsub("-", ".", rownames(bulk_data))

common_samples <- intersect(case_legend$sample.ID, rownames(bulk_data))
case_legend <- case_legend[match(common_samples, case_legend$sample.ID), ]
bulk_data <- bulk_data[common_samples, ]
rownames(bulk_data) <- common_samples
colnames_bulk <- colnames(bulk_data)
rownames_bulk <- rownames(bulk_data)
bulk_data <- as.data.frame(apply(bulk_data, 2, function(x) as.numeric(trimws(x))))

colnames(bulk_data) <-colnames_bulk
rownames(bulk_data) <- rownames_bulk

if (!file.exists(OUTPUT_DIRECTORY)) {
  dir.create(OUTPUT_DIRECTORY, recursive = TRUE)
}

for (condition in CONDITIONS) {
  condition_folder <- file.path(OUTPUT_DIRECTORY, condition)
  if (!file.exists(condition_folder)) {
    dir.create(condition_folder, recursive = TRUE)
  }
  
  tryCatch({
    comparison_data <- case_legend[case_legend$group_ID %in% c(REFERENCE_GROUP, condition), ]
    comparison_data$group_ID <- relevel(factor(comparison_data$group_ID, levels = c(REFERENCE_GROUP, condition)), ref = condition)
    comparison_data <- comparison_data[order(comparison_data$group_ID), ]
    
    common_ids <- intersect(comparison_data$sample.ID, rownames(bulk_data))
    bulk_subset <- bulk_data[common_ids, ]
    bulk_ordered <- bulk_subset[match(comparison_data$sample.ID, rownames(bulk_subset)), ]
    bulk_ordered[is.na(bulk_ordered)] <- 1e-8
    
    group <- factor(comparison_data$group_ID)
    y <- DGEList(counts = t(bulk_ordered), group = group)
    
    keep <- filterByExpr(y, group = group)
    y <- y[keep, , keep.lib.sizes = FALSE]
    y <- calcNormFactors(y)
    AveLogCPM <- aveLogCPM(y)
    y <- normLibSizes(y)
    
    png(file.path(condition_folder, "MD_plot.png"))
    plotMD(y, column = 1)
    abline(h = 0, col = "red", lty = 2, lwd = 2)
    dev.off()
    
    design <- model.matrix(~ 0 + group + comparison_data$SV1, data = comparison_data)
    colnames(design) <- c(levels(group),"SV1")
    y <- estimateDisp(y, design)
    fit <- glmFit(y, design)
    contrast <- makeContrasts(contrasts = paste0(make.names(condition), " - ", make.names(REFERENCE_GROUP)), levels = design)
    res <- glmLRT(fit, contrast = contrast, coef = 2)
    is.de <- decideTests(res, adjust.method = "fdr", p.value = 0.05, lfc = 0)
    
    results_table <- res$table
    results_table$adj_pval <- p.adjust(results_table$PValue, method = "fdr")
    results_table <- cbind(results_table, data.frame(is.de))
    write.csv(results_table, file = file.path(condition_folder, "results_adj_bulk.csv"))
    
    png(file.path(condition_folder, "histogram_plot.png"))
    hist(AveLogCPM)
    dev.off()
    
    png(file.path(condition_folder, "BCV_plot.png"))
    plotBCV(y)
    dev.off()
    
    png(file.path(condition_folder, "MD_res_plot.png"))
    plotMD(res, status = is.de)
    dev.off()
    
    # logCPM <- cpm(y, prior.count = 2, log = TRUE)
    # tr <- glmTreat(fit, contrast = contrast, lfc = log2(1.5))
    # o <- order(tr$table$PValue)
    # top_genes <- head(o, 30)
    # logCPM_top <- logCPM[top_genes, ]
    # 
    # png(file.path(condition_folder, "Heatmap.png"))
    # coolmap(logCPM_top, margins = c(7, 7), lhei = c(1, 6), lwid = c(1, 3))
    # dev.off()
    
  }, error = function(e) {
    print(paste("Error processing condition:", condition))
    print(e)
  })
}



################################################################################
# Rimmod

# EDGER on Bulk RNASEQ
library(edgeR)
library(dplyr)
library(GO.db)
library(xlsx)

BULK_COUNTS_PATH <- "/media/jaumatell/datos/URI/PROJECTE_SEURAT_BP/RiMod/rnaseq_salmon_results/counts.csv"
CASE_LEGEND <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/RIMOD_BULK/DATA/rimod_ftd_dataset_table_v3.txt"
OUTPUT_DIRECTORY <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/EDGER/BULK_DEA/Rimmod_LRT_SV_2/"
SURROGATE_VARIABLES <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/RIMOD_BULK/METADATA/SVA.csv"
REFERENCE_GROUP <- "Healthy"
CONDITIONS <- "C9orf72"

# Load metadata
case_legend <- read.delim(CASE_LEGEND, row.names = 1, sep = "\t")
case_legend$sample.ID <- rownames(case_legend)
case_legend <- case_legend[case_legend$DiseaseCode != "FTD-GRN", ]
case_legend <- case_legend[case_legend$DiseaseCode != "FTD-MAPT", ]
case_legend$DiseaseCode[case_legend$DiseaseCode == "control"] <- "Healthy"
case_legend$DiseaseCode[case_legend$DiseaseCode != "Healthy"] <- "C9orf72"
case_legend$group_ID <- factor(case_legend$DiseaseCode)


# Load surrogate variables 
surrogate_variables <- read.csv(SURROGATE_VARIABLES, row.names = 1, sep = "\t")
case_legend$rn <- rownames(case_legend)
surrogate_variables$rn <- rownames(surrogate_variables)

case_legend <- merge(case_legend, surrogate_variables, by.x = "rn", by.y = "rn")
case_legend$rn <- NULL
surrogate_variables$rn <- NULL

# Load bulk 

bulk_raw <- read.csv(BULK_COUNTS_PATH, row.names = 1, sep = ",")
bulk_raw <-t(bulk_raw)
#colnames(bulk_raw) <- bulk_raw["GeneName", ]
bulk_data <- bulk_raw[!(rownames(bulk_raw) %in% c("Chromosome", "Start", "End", "Length", "GeneName", "GeneBiotype")), ]


common_samples <- intersect(case_legend$sample.ID, rownames(bulk_data))
case_legend <- case_legend[match(common_samples, case_legend$sample.ID), ]
bulk_data <- bulk_data[common_samples, ]
rownames(bulk_data) <- common_samples
colnames_bulk <- colnames(bulk_data)
rownames_bulk <- rownames(bulk_data)
bulk_data <- as.data.frame(apply(bulk_data, 2, function(x) as.numeric(trimws(x))))

colnames(bulk_data) <-colnames_bulk
rownames(bulk_data) <- rownames_bulk

if (!file.exists(OUTPUT_DIRECTORY)) {
  dir.create(OUTPUT_DIRECTORY, recursive = TRUE)
}

for (condition in CONDITIONS) {
  condition_folder <- file.path(OUTPUT_DIRECTORY, condition)
  if (!file.exists(condition_folder)) {
    dir.create(condition_folder, recursive = TRUE)
  }
  
  tryCatch({
    comparison_data <- case_legend[case_legend$group_ID %in% c(REFERENCE_GROUP, condition), ]
    comparison_data$group_ID <- relevel(factor(comparison_data$group_ID, levels = c(REFERENCE_GROUP, condition)), ref = condition)
    comparison_data <- comparison_data[order(comparison_data$group_ID), ]
    
    common_ids <- intersect(comparison_data$sample.ID, rownames(bulk_data))
    bulk_subset <- bulk_data[common_ids, ]
    bulk_ordered <- bulk_subset[match(comparison_data$sample.ID, rownames(bulk_subset)), ]
    bulk_ordered[is.na(bulk_ordered)] <- 1e-8
    
    group <- factor(comparison_data$group_ID)
    y <- DGEList(counts = t(bulk_ordered), group = group)
    
    keep <- filterByExpr(y, group = group)
    y <- y[keep, , keep.lib.sizes = FALSE]
    y <- calcNormFactors(y)
    AveLogCPM <- aveLogCPM(y)
    y <- normLibSizes(y)
    
    png(file.path(condition_folder, "MD_plot.png"))
    plotMD(y, column = 1)
    abline(h = 0, col = "red", lty = 2, lwd = 2)
    dev.off()
    
    design <- model.matrix(~ 0 + group + comparison_data$SV1, data = comparison_data)
    colnames(design) <- c(levels(group),"SV1")
    y <- estimateDisp(y, design)
    fit <- glmFit(y, design)
    contrast <- makeContrasts(contrasts = paste0(make.names(condition), " - ", make.names(REFERENCE_GROUP)), levels = design)
    res <- glmLRT(fit, contrast = contrast, coef = 2)
    is.de <- decideTests(res, adjust.method = "fdr", p.value = 0.05, lfc = 0)
    
    results_table <- res$table
    results_table$adj_pval <- p.adjust(results_table$PValue, method = "fdr")
    results_table <- cbind(results_table, data.frame(is.de))
    write.csv(results_table, file = file.path(condition_folder, "results_adj_bulk.csv"))
    
    png(file.path(condition_folder, "histogram_plot.png"))
    hist(AveLogCPM)
    dev.off()
    
    png(file.path(condition_folder, "BCV_plot.png"))
    plotBCV(y)
    dev.off()
    
    png(file.path(condition_folder, "MD_res_plot.png"))
    plotMD(res, status = is.de)
    dev.off()
    
    # logCPM <- cpm(y, prior.count = 2, log = TRUE)
    # tr <- glmTreat(fit, contrast = contrast, lfc = log2(1.5))
    # o <- order(tr$table$PValue)
    # top_genes <- head(o, 30)
    # logCPM_top <- logCPM[top_genes, ]
    # 
    # png(file.path(condition_folder, "Heatmap.png"))
    # coolmap(logCPM_top, margins = c(7, 7), lhei = c(1, 6), lwid = c(1, 3))
    # dev.off()
    
  }, error = function(e) {
    print(paste("Error processing condition:", condition))
    print(e)
  })
}
```

```{r fig_1_bulk_dea_1, echo=FALSE, eval=FALSE}
# knitr::include_graphics("figures/fig_1_bulk_dea_1.png")
```

```{r fig_1_bulk_dea_2, echo=FALSE, eval=FALSE}
# knitr::include_graphics("figures/fig_1_bulk_dea_2.png")
```

## 2. Bayesprism

Perform BayesPrism deconvolution to estimate cell-type proportions in each FTLD cohort using reference single-cell signatures.

Scripts included in this step:

-   `2. Bayesprism/2.Baysprism_FTLD_C9.R`
-   `2. Bayesprism/2.Baysprism_FTLD_TDP.R`
-   `2. Bayesprism/2.Baysprism_Pottier.R`
-   `2. Bayesprism/2.Baysprism_Rimod.R`

```{r code_2_bayesprism_2_baysprism_ftld_c9_r, eval=FALSE}
library("ggplot2")
library("openxlsx")
library("dplyr")
library("coin")
library("AnnotationDbi")
library("org.Hs.eg.db")
library('EnsDb.Hsapiens.v86')
library("Seurat")
library("edgeR")
library("GO.db")
library("xlsx")
suppressWarnings(library("BayesPrism"))
suppressWarnings(library(org.Hs.eg.db))
library(dplyr) 
library("AnnotationDbi")
library("org.Hs.eg.db")
library('EnsDb.Hsapiens.v86')
library("Seurat")



################################################################################
# Single cell data
load("/media/jaumatell/datos/URI/BAYESPRISM_12_3/SINGLE_CELL/DATA/Merge_FC_complete.RData")
# Bulk data
bk.dat <-  read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/DATA/C9orf72.csv")
###############################################################################
#Set colnames and rownames
rownames(bk.dat)<-bk.dat[,1]
bk.dat <- bk.dat[,-1]
bk.dat <- t(bk.dat)

sc.dat <- t(merged@assays$Assay_name$counts)

A <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/SINGLE_CELL/METADATA/S03_annotation_mapping.csv")
A[44,"SubType" ] <- "T_Cell"
A[20,"SubType" ] <- "OPC"
A[19,"SubType" ] <- "Oligo"
A[18,"SubType" ] <- "Micro"

# Update metadata to take into account DGE groups.
merged@meta.data <- merged@meta.data %>%
  left_join(A, by = c("cellstate" = "SubType"))

# Cell type and state
cell.state.labels <- merged@meta.data$cellstate
cell.type.labels <- merged@meta.data$CellType
rm(merged)
gc()

# Pre-processing
plot.cor.phi (input=sc.dat, 
              input.labels=as.factor(cell.state.labels),
              title="cell state correlation",
              pdf.prefix="gbm.cor.cs",
              cexRow=0.2, 
              cexCol=0.2,
              margins=c(2,2)
)

plot.cor.phi (input=sc.dat,
              input.labels=as.factor(cell.type.labels),
              title="cell type correlation",
              pdf.prefix="gbm.cor.ct",
              cexRow=0.5, 
              cexCol=0.5,
)

sc.stat <- plot.scRNA.outlier(
  input=sc.dat, #make sure the colnames are gene symbol or ENSMEBL ID
  cell.type.labels=as.factor(cell.type.labels),
  species="hs", #currently only human(hs) and mouse(mm) annotations are supported
  return.raw=TRUE, #return the data used for plotting.
  pdf.prefix="SC_stats"
)
write.csv(sc.stat, "sc.stat.csv")

print("bk.stat")
bk.stat <- plot.bulk.outlier(
  bulk.input = bk.dat,
  sc.input = sc.dat,
  cell.type.labels = cell.type.labels,
  species = "hs",
  return.raw = TRUE,
  pdf.prefix = "BK_stats"
)
write.csv(bk.dat, "bk.stat.csv")


print("sc.stat.filtered")
sc.dat.filtered <- cleanup.genes (input=sc.dat,
                                  input.type="count.matrix",
                                  species="hs",
                                  gene.group=c( "Rb","Mrp","other_Rb","chrM","MALAT1","chrX","chrY") ,
                                  exp.cells=5
)
rm(sc.dat)
gc()
write.csv(sc.dat.filtered, "sc.dat.filtered.csv")

print("bk.stat.filtered")
plot.bulk.vs.sc (sc.input = sc.dat.filtered,
                 bulk.input = bk.dat,
                 pdf.prefix="Bulk_vs_Sc"
)

print("sc.dat.filtered.pc")
sc.dat.filtered.pc <- select.gene.type (sc.dat.filtered,
                                        gene.type = "protein_coding")
rm(sc.dat.filtered)
gc()
write.csv(sc.dat.filtered.pc, "sc.dat.filtered.pc.csv")

# SORT bk.dat so the colnames are sorted equaly in both tables. 
common_columns <- intersect(colnames(bk.dat), colnames(sc.dat.filtered.pc))
bk.dat <- bk.dat[, common_columns]
sc.dat.filtered.pc <- sc.dat.filtered.pc[, common_columns]

rm(sc.dat)
rm(sc.dat.filtered)
rm(bk.stat)
rm(sc.stat)

myPrism <- new.prism(
  reference=sc.dat.filtered.pc,
  mixture=as.matrix(bk.dat[,2:ncol(bk.dat)]),
  input.type="count.matrix",
  cell.type.labels = cell.type.labels,
  cell.state.labels = cell.state.labels,
  key=NULL,
  outlier.cut=0.01,
  outlier.fraction=0.1,
)
save(myPrism, file = "myPrism.RData")

bp.res <- run.prism(prism = myPrism, n.cores=50)
save(bp.res, file = "bp.res.RData")

theta <- get.fraction (bp=bp.res,
                       which.theta="final",
                       state.or.type="type")
write.csv(theta, "theta.csv")

theta.cv <- bp.res@posterior.theta_f@theta.cv
write.csv(theta.cv, "theta.cv.csv")

bp.res.initial <- run.prism(prism = myPrism, 
                            n.cores=50, 
                            update.gibbs=FALSE)
save(bp.res.initial, file = "bp.res.initial.RData")
#bp.res.update <- update.theta (bp = bp.res.initial)
#save(bp.res.update, file = "bp.res.update.RData")

theta.state <- get.fraction (bp=bp.res.initial,
                             which.theta="first",
                             state.or.type="state")
write.csv(theta.state, "theta.state_cellstate.csv")

# Make new directories
new_dir_name <- "CELL TYPE"
if (file.exists(new_dir_name)){
  print("", end = "")
} else {
  dir.create(new_dir_name)
}

new_dir_name <- "CELL STATE ORIGINAL"
if (file.exists(new_dir_name)){
  print("", end = "")
} else {
  dir.create(new_dir_name)
}

for (cell_type in levels(as.factor(cell.type.labels))){
  exp_type <- get.exp(bp = bp.res, 
                      state.or.type = "type", 
                      cell.name = cell_type)
  write.csv(exp_type, paste0("CELL TYPE/", cell_type, ".csv"))
}


for (cell_state in levels(as.factor(cell.state.labels))){
  exp_type <- get.exp(bp = bp.res, 
                      state.or.type = "state", 
                      cell.name = cell_state)
  write.csv(exp_type, paste0("CELL STATE ORIGINAL/", cell_state, ".csv"))
}
```

```{r code_2_bayesprism_2_baysprism_ftld_tdp_r, eval=FALSE}
library("ggplot2")
library("openxlsx")
library("dplyr")
library("coin")
library("AnnotationDbi")
library("org.Hs.eg.db")
library('EnsDb.Hsapiens.v86')
library("Seurat")
library("edgeR")
library("GO.db")
library("xlsx")
suppressWarnings(library("BayesPrism"))
suppressWarnings(library(org.Hs.eg.db))
library(dplyr) 
library("AnnotationDbi")
library("org.Hs.eg.db")
library('EnsDb.Hsapiens.v86')
library("Seurat")


################################################################################
# Single cell data
load("/media/jaumatell/datos/URI/BAYESPRISM_12_3/SINGLE_CELL/DATA/Merge_FC_complete.RData")
# Bulk data
bk.dat <-  read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/DATA/TDP.csv")
###############################################################################
#Set colnames and rownames
rownames(bk.dat)<-bk.dat[,1]
bk.dat <- bk.dat[,-1]
bk.dat <- t(bk.dat)

sc.dat <- t(merged@assays$Assay_name$counts)

A <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/SINGLE_CELL/METADATA/S03_annotation_mapping.csv")
A[44,"SubType" ] <- "T_Cell"
A[20,"SubType" ] <- "OPC"
A[19,"SubType" ] <- "Oligo"
A[18,"SubType" ] <- "Micro"

# Update metadata to take into account DGE groups.
merged@meta.data <- merged@meta.data %>%
  left_join(A, by = c("cellstate" = "SubType"))

# Cell type and state
cell.state.labels <- merged@meta.data$cellstate
cell.type.labels <- merged@meta.data$CellType
rm(merged)

# Pre-processing
plot.cor.phi (input=sc.dat, 
              input.labels=as.factor(cell.state.labels),
              title="cell state correlation",
              pdf.prefix="gbm.cor.cs",
              cexRow=0.2, 
              cexCol=0.2,
              margins=c(2,2)
)

plot.cor.phi (input=sc.dat,
              input.labels=as.factor(cell.type.labels),
              title="cell type correlation",
              pdf.prefix="gbm.cor.ct",
              cexRow=0.5, 
              cexCol=0.5,
)

sc.stat <- plot.scRNA.outlier(
  input=sc.dat, #make sure the colnames are gene symbol or ENSMEBL ID
  cell.type.labels=as.factor(cell.type.labels),
  species="hs", #currently only human(hs) and mouse(mm) annotations are supported
  return.raw=TRUE, #return the data used for plotting.
  pdf.prefix="SC_stats"
)
write.csv(sc.stat, "sc.stat.csv")

print("bk.stat")
bk.stat <- plot.bulk.outlier(
  bulk.input = bk.dat,
  sc.input = sc.dat,
  cell.type.labels = cell.type.labels,
  species = "hs",
  return.raw = TRUE,
  pdf.prefix = "BK_stats"
)
write.csv(bk.dat, "bk.stat.csv")


print("sc.stat.filtered")
sc.dat.filtered <- cleanup.genes (input=sc.dat,
                                  input.type="count.matrix",
                                  species="hs",
                                  gene.group=c( "Rb","Mrp","other_Rb","chrM","MALAT1","chrX","chrY") ,
                                  exp.cells=5
)
write.csv(sc.dat.filtered, "sc.dat.filtered.csv")

print("bk.stat.filtered")
plot.bulk.vs.sc (sc.input = sc.dat.filtered,
                 bulk.input = bk.dat,
                 pdf.prefix="Bulk_vs_Sc"
)

print("sc.dat.filtered.pc")
sc.dat.filtered.pc <- select.gene.type (sc.dat.filtered,
                                        gene.type = "protein_coding")
write.csv(sc.dat.filtered.pc, "sc.dat.filtered.pc.csv")

# SORT bk.dat so the colnames are sorted equaly in both tables. 
common_columns <- intersect(colnames(bk.dat), colnames(sc.dat.filtered.pc))
bk.dat <- bk.dat[, common_columns]
sc.dat.filtered.pc <- sc.dat.filtered.pc[, common_columns]

rm(sc.dat)
rm(sc.dat.filtered)
rm(bk.stat)
rm(sc.stat)

myPrism <- new.prism(
  reference=sc.dat.filtered.pc,
  mixture=as.matrix(bk.dat[,2:ncol(bk.dat)]),
  input.type="count.matrix",
  cell.type.labels = cell.type.labels,
  cell.state.labels = cell.state.labels,
  key=NULL,
  outlier.cut=0.01,
  outlier.fraction=0.1,
)
save(myPrism, file = "myPrism.RData")

bp.res <- run.prism(prism = myPrism, n.cores=50)
save(bp.res, file = "bp.res.RData")

theta <- get.fraction (bp=bp.res,
                       which.theta="final",
                       state.or.type="type")
write.csv(theta, "theta.csv")

theta.cv <- bp.res@posterior.theta_f@theta.cv
write.csv(theta.cv, "theta.cv.csv")

bp.res.initial <- run.prism(prism = myPrism, 
                            n.cores=50, 
                            update.gibbs=FALSE)
#save(bp.res.initial, file = "bp.res.initial.RData")
#bp.res.update <- update.theta (bp = bp.res.initial)
#save(bp.res.update, file = "bp.res.update.RData")

theta.state <- get.fraction (bp=bp.res.initial,
                             which.theta="first",
                             state.or.type="state")
write.csv(theta.state, "theta.state_original.csv")

# Make new directories
new_dir_name <- "CELL TYPE"
if (file.exists(new_dir_name)){
  print("", end = "")
} else {
  dir.create(new_dir_name)
}

new_dir_name <- "CELL STATE ORIGINAL"
if (file.exists(new_dir_name)){
  print("", end = "")
} else {
  dir.create(new_dir_name)
}

for (cell_type in levels(as.factor(cell.type.labels))){
  exp_type <- get.exp(bp = bp.res, 
                      state.or.type = "type", 
                      cell.name = cell_type)
  write.csv(exp_type, paste0("CELL TYPE/", cell_type, ".csv"))
}


for (cell_state in levels(as.factor(cell.state.labels))){
  exp_type <- get.exp(bp = bp.res, 
                      state.or.type = "state", 
                      cell.name = cell_state)
  write.csv(exp_type, paste0("CELL STATE ORIGINAL/", cell_state, ".csv"))
}
```

```{r code_2_bayesprism_2_baysprism_pottier_r, eval=FALSE}
library("ggplot2")
library("openxlsx")
library("dplyr")
library("coin")
library("AnnotationDbi")
library("org.Hs.eg.db")
library('EnsDb.Hsapiens.v86')
library("Seurat")
library("edgeR")
library("GO.db")
library("xlsx")
suppressWarnings(library("BayesPrism"))
suppressWarnings(library(org.Hs.eg.db))
library(dplyr) 
library("AnnotationDbi")
library("org.Hs.eg.db")
library('EnsDb.Hsapiens.v86')
library("Seurat")

################################################################################
# Single cell data
load("/media/jaumatell/datos/URI/BAYESPRISM_12_3/SINGLE_CELL/DATA/Merge_FC_complete.RData")
# Bulk data
bk.dat <-  read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/NEW_BULK/DATA/merged_gene_count_FCX.csv")
###############################################################################
#Set colnames and rownames
bk.dat<-bk.dat[, -c(1,2,3,4,5,7)]
bk.dat <- aggregate(. ~ GeneName, data = bk.dat, FUN = sum) # Aggregate rows with same gene
rownames(bk.dat)<-bk.dat[,1]
bk.dat <- bk.dat[,-1]
bk.dat <- t(bk.dat)


sc.dat <- t(merged@assays$Assay_name$counts)
# El matrix es el que dona problemes!!!!!!
#sc.dat <- t(as.matrix(merged@assays$Assay_name$counts))
A <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/SINGLE_CELL/METADATA/S03_annotation_mapping.csv")
A[44,"SubType" ] <- "T_Cell"
A[20,"SubType" ] <- "OPC"
A[19,"SubType" ] <- "Oligo"
A[18,"SubType" ] <- "Micro"


# Update metadata to take into account DGE groups.

merged@meta.data <- merged@meta.data %>%
  left_join(A, by = c("cellstate" = "SubType"))


# Cell type and state
cell.state.labels <- merged@meta.data$cellstate
cell.type.labels <- merged@meta.data$CellType
rm(merged)

# Pre-processing
plot.cor.phi (input=sc.dat, 
              input.labels=as.factor(cell.state.labels),
              title="cell state correlation",
              pdf.prefix="gbm.cor.cs",
              cexRow=0.2, 
              cexCol=0.2,
              margins=c(2,2)
)

plot.cor.phi (input=sc.dat,
              input.labels=as.factor(cell.type.labels),
              title="cell type correlation",
              pdf.prefix="gbm.cor.ct",
              cexRow=0.5, 
              cexCol=0.5,
)

sc.stat <- plot.scRNA.outlier(
  input=sc.dat, #make sure the colnames are gene symbol or ENSMEBL ID
  cell.type.labels=as.factor(cell.type.labels),
  species="hs", #currently only human(hs) and mouse(mm) annotations are supported
  return.raw=TRUE, #return the data used for plotting.
  pdf.prefix="SC_stats"
)
write.csv(sc.stat, "sc.stat.csv")

print("bk.stat")
bk.stat <- plot.bulk.outlier(
  bulk.input = bk.dat,
  sc.input = sc.dat,
  cell.type.labels = cell.type.labels,
  species = "hs",
  return.raw = TRUE,
  pdf.prefix = "BK_stats"
)
write.csv(bk.dat, "bk.stat.csv")


print("sc.stat.filtered")
sc.dat.filtered <- cleanup.genes (input=sc.dat,
                                  input.type="count.matrix",
                                  species="hs",
                                  gene.group=c( "Rb","Mrp","other_Rb","chrM","MALAT1","chrX","chrY") ,
                                  exp.cells=5
)
write.csv(sc.dat.filtered, "sc.dat.filtered.csv")

print("bk.stat.filtered")
plot.bulk.vs.sc (sc.input = sc.dat.filtered,
                 bulk.input = bk.dat,
                 pdf.prefix="Bulk_vs_Sc"
)

print("sc.dat.filtered.pc")
sc.dat.filtered.pc <- select.gene.type (sc.dat.filtered,
                                        gene.type = "protein_coding")
write.csv(sc.dat.filtered.pc, "sc.dat.filtered.pc.csv")

# SORT bk.dat so the colnames are sorted equaly in both tables. 
common_columns <- intersect(colnames(bk.dat), colnames(sc.dat.filtered.pc))
bk.dat <- bk.dat[, common_columns]
sc.dat.filtered.pc <- sc.dat.filtered.pc[, common_columns]

rm(sc.dat)
rm(sc.dat.filtered)
rm(bk.stat)
rm(sc.stat)

myPrism <- new.prism(
  reference=sc.dat.filtered.pc,
  mixture=as.matrix(bk.dat[,2:ncol(bk.dat)]),
  input.type="count.matrix",
  cell.type.labels = cell.type.labels,
  cell.state.labels = cell.state.labels,
  key=NULL,
  outlier.cut=0.01,
  outlier.fraction=0.1,
)
save(myPrism, file = "myPrism.RData")

bp.res <- run.prism(prism = myPrism, n.cores=50,)
save(bp.res, file = "bp.res.RData")

theta <- get.fraction (bp=bp.res,
                       which.theta="final",
                       state.or.type="type")
write.csv(theta, "theta.csv")

theta.cv <- bp.res@posterior.theta_f@theta.cv
write.csv(theta.cv, "theta.cv.csv")

bp.res.initial <- run.prism(prism = myPrism, 
                            n.cores=50, 
                            update.gibbs=FALSE)
save(bp.res.initial, file = "bp.res.initial.RData")
bp.res.update <- update.theta (bp = bp.res.initial)
save(bp.res.update, file = "bp.res.update.RData")

theta.state <- get.fraction (bp=bp.res.initial,
                             which.theta="first",
                             state.or.type="state")
write.csv(theta.state, "theta.state_cellstate.csv")

# Make new directories
new_dir_name <- "CELL TYPE"
if (file.exists(new_dir_name)){
  print("", end = "")
} else {
  dir.create(new_dir_name)
}

new_dir_name <- "CELL STATE ORIGINAL"
if (file.exists(new_dir_name)){
  print("", end = "")
} else {
  dir.create(new_dir_name)
}

for (cell_type in levels(as.factor(cell.type.labels))){
  exp_type <- get.exp(bp = bp.res, 
                      state.or.type = "type", 
                      cell.name = cell_type)
  write.csv(exp_type, paste0("CELL TYPE/", cell_type, ".csv"))
}


for (cell_state in levels(as.factor(cell.state.labels))){
  exp_type <- get.exp(bp = bp.res, 
                      state.or.type = "state", 
                      cell.name = cell_state)
  write.csv(exp_type, paste0("CELL STATE ORIGINAL/", cell_state, ".csv"))
}
```

```{r code_2_bayesprism_2_baysprism_rimod_r, eval=FALSE}
library("ggplot2")
library("openxlsx")
library("dplyr")
library("coin")
library("AnnotationDbi")
library("org.Hs.eg.db")
library('EnsDb.Hsapiens.v86')
library("Seurat")
library("edgeR")
library("GO.db")
library("xlsx")
suppressWarnings(library("BayesPrism"))
suppressWarnings(library(org.Hs.eg.db))
library(dplyr) 
library("AnnotationDbi")
library("org.Hs.eg.db")
library('EnsDb.Hsapiens.v86')
library("Seurat")




################################################################################
# Single cell data
load("/media/jaumatell/datos/URI/BAYESPRISM_12_3/SINGLE_CELL/DATA/Merge_FC_complete.RData")
# Bulk data
bk.dat <-  read.csv("/media/jaumatell/datos/URI/PROJECTE_SEURAT_BP/RiMod/rnaseq_salmon_results/counts.csv")
###############################################################################
#Set colnames and rownames
rownames(bk.dat)<-bk.dat[,1]
bk.dat <- bk.dat[,-1]
bk.dat <- t(bk.dat)

sc.dat <- t(merged@assays$Assay_name$counts)

A <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/SINGLE_CELL/METADATA/S03_annotation_mapping.csv")
A[44,"SubType" ] <- "T_Cell"
A[20,"SubType" ] <- "OPC"
A[19,"SubType" ] <- "Oligo"
A[18,"SubType" ] <- "Micro"

# Update metadata to take into account DGE groups.
merged@meta.data <- merged@meta.data %>%
  left_join(A, by = c("cellstate" = "SubType"))

# Cell type and state
cell.state.labels <- merged@meta.data$cellstate
cell.type.labels <- merged@meta.data$CellType
rm(merged)

# Pre-processing
plot.cor.phi (input=sc.dat, 
              input.labels=as.factor(cell.state.labels),
              title="cell state correlation",
              pdf.prefix="gbm.cor.cs",
              cexRow=0.2, 
              cexCol=0.2,
              margins=c(2,2)
)

plot.cor.phi (input=sc.dat,
              input.labels=as.factor(cell.type.labels),
              title="cell type correlation",
              pdf.prefix="gbm.cor.ct",
              cexRow=0.5, 
              cexCol=0.5,
)

sc.stat <- plot.scRNA.outlier(
  input=sc.dat, #make sure the colnames are gene symbol or ENSMEBL ID
  cell.type.labels=as.factor(cell.type.labels),
  species="hs", #currently only human(hs) and mouse(mm) annotations are supported
  return.raw=TRUE, #return the data used for plotting.
  pdf.prefix="SC_stats"
)
write.csv(sc.stat, "sc.stat.csv")

print("bk.stat")
bk.stat <- plot.bulk.outlier(
  bulk.input = bk.dat,
  sc.input = sc.dat,
  cell.type.labels = cell.type.labels,
  species = "hs",
  return.raw = TRUE,
  pdf.prefix = "BK_stats"
)
write.csv(bk.dat, "bk.stat.csv")


print("sc.stat.filtered")
sc.dat.filtered <- cleanup.genes (input=sc.dat,
                                  input.type="count.matrix",
                                  species="hs",
                                  gene.group=c( "Rb","Mrp","other_Rb","chrM","MALAT1","chrX","chrY") ,
                                  exp.cells=5
)
write.csv(sc.dat.filtered, "sc.dat.filtered.csv")

print("bk.stat.filtered")
plot.bulk.vs.sc (sc.input = sc.dat.filtered,
                 bulk.input = bk.dat,
                 pdf.prefix="Bulk_vs_Sc"
)

print("sc.dat.filtered.pc")
sc.dat.filtered.pc <- select.gene.type (sc.dat.filtered,
                                        gene.type = "protein_coding")
write.csv(sc.dat.filtered.pc, "sc.dat.filtered.pc.csv")

# SORT bk.dat so the colnames are sorted equaly in both tables. 
common_columns <- intersect(colnames(bk.dat), colnames(sc.dat.filtered.pc))
bk.dat <- bk.dat[, common_columns]
sc.dat.filtered.pc <- sc.dat.filtered.pc[, common_columns]

rm(sc.dat)
rm(sc.dat.filtered)
rm(bk.stat)
rm(sc.stat)

myPrism <- new.prism(
  reference=sc.dat.filtered.pc,
  mixture=as.matrix(bk.dat[,2:ncol(bk.dat)]),
  input.type="count.matrix",
  cell.type.labels = cell.type.labels,
  cell.state.labels = cell.state.labels,
  key=NULL,
  outlier.cut=0.01,
  outlier.fraction=0.1,
)
save(myPrism, file = "myPrism.RData")

bp.res <- run.prism(prism = myPrism, n.cores=50)
save(bp.res, file = "bp.res.RData")

theta <- get.fraction (bp=bp.res,
                       which.theta="final",
                       state.or.type="type")
write.csv(theta, "theta.csv")

theta.cv <- bp.res@posterior.theta_f@theta.cv
write.csv(theta.cv, "theta.cv.csv")

bp.res.initial <- run.prism(prism = myPrism, 
                            n.cores=50, 
                            update.gibbs=FALSE)
save(bp.res.initial, file = "bp.res.initial.RData")
#bp.res.update <- update.theta (bp = bp.res.initial)
#save(bp.res.update, file = "bp.res.update.RData")

theta.state <- get.fraction (bp=bp.res.initial,
                             which.theta="first",
                             state.or.type="state")
write.csv(theta.state, "theta.state_cellstate.csv")

# Make new directories
new_dir_name <- "CELL TYPE"
if (file.exists(new_dir_name)){
  print("", end = "")
} else {
  dir.create(new_dir_name)
}

new_dir_name <- "CELL STATE ORIGINAL"
if (file.exists(new_dir_name)){
  print("", end = "")
} else {
  dir.create(new_dir_name)
}

for (cell_type in levels(as.factor(cell.type.labels))){
  exp_type <- get.exp(bp = bp.res, 
                      state.or.type = "type", 
                      cell.name = cell_type)
  write.csv(exp_type, paste0("CELL TYPE/", cell_type, ".csv"))
}


for (cell_state in levels(as.factor(cell.state.labels))){
  exp_type <- get.exp(bp = bp.res, 
                      state.or.type = "state", 
                      cell.name = cell_state)
  write.csv(exp_type, paste0("CELL STATE ORIGINAL/", cell_state, ".csv"))
}
```

```{r fig_2_bayesprism_1, echo=FALSE, eval=FALSE}
# knitr::include_graphics("figures/fig_2_bayesprism_1.png")
```

```{r fig_2_bayesprism_2, echo=FALSE, eval=FALSE}
# knitr::include_graphics("figures/fig_2_bayesprism_2.png")
```

## 3. CELL PROP DIFFERENCES

Compare inferred cell-type proportions across diagnosis groups using multiple statistical tests and data transformations.

Scripts included in this step:

-   `3. CELL PROP DIFFERENCES/3. Diferences in cell proportions with transformations.R`
-   `3. CELL PROP DIFFERENCES/FTLD_C9_CELL_PROP_DIFFERENCES.R`
-   `3. CELL PROP DIFFERENCES/FTLD_TDP_CELL_PROP_DIFFERENCES.R`
-   `3. CELL PROP DIFFERENCES/Pottier_CELL_PROP_DIFFERENCES.R`
-   `3. CELL PROP DIFFERENCES/Rimod_CELL_PROP_DIFFERENCES.R`
-   `3. CELL PROP DIFFERENCES/TDP_CELL_PROP_DIFFERENCES.R`

```{r code_3_cell_prop_differences_3_diferences_in_cell_proportions_with_transformations_r, eval=FALSE}

### FTLD TDP
#### Log

library("ggplot2")
library("openxlsx")
library("dplyr")
library("coin")  

#################################T.TESTS########################################
# FILE PATHS
frequency_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMATED_PROPORTIONS/Log/FTLD/TDP/Log_Cell_state_proportions.csv"
metadata_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx"
output_path <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMED_RESULTS/FTLD/TDP/Log/"
################################################################################

if (!file.exists(output_path)) {
  dir.create(output_path, recursive = TRUE)
}
if (!file.exists(file.path(output_path,"Significative"))) {
  dir.create(file.path(output_path,"Significative"), recursive = TRUE)
}

data <- read.xlsx(metadata_file)

freq_cell_types <- read.csv(frequency_file)
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("long", "", x))
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("X", "", x))

merged_data <- merge(data, freq_cell_types, by.x = "sample.ID", by.y = "X")
merged_data[merged_data == 0] <- 1e-10

################################################################################
# Generate needed objects

m_conditions <- unique(merged_data$group.ID)
m_conditions_nh <- m_conditions[m_conditions != "Healthy"]
files_to_iterate <- colnames(merged_data)[4:length(colnames(merged_data))]
m_cond <- m_conditions_nh[1]
counter = 0

significatives <- data.frame(matrix(nrow = length(files_to_iterate), ncol = 3))
colnames(significatives)<- c("cell", "group+sv", "group")


for (column in colnames(freq_cell_types)[2:length(colnames(freq_cell_types))]){
  counter <- counter + 1
  filename <- paste0("Kruskal_", column, "_", m_cond, ".txt")
  
  subset_data <- merged_data[merged_data$group.ID %in% c("Healthy", m_cond), 
                             c("group.ID", column)]
  
  # Ensure group.ID is treated as a factor
  subset_data$group.ID <- factor(subset_data$group.ID, levels = c("Healthy", m_cond))
  
  # Calculate group means
  mean_healthy <- mean(subset_data[[column]][subset_data$group.ID == "Healthy"], na.rm = TRUE)
  mean_condition <- mean(subset_data[[column]][subset_data$group.ID == m_cond], na.rm = TRUE)
  
  # Calculate fold change
  fold_change <- ifelse(mean_healthy == 0, NA, mean_condition / mean_healthy)  # Avoid division by zero
  
  # Log-transform the fold change (optional)
  log2_fold_change <- ifelse(is.na(fold_change), NA, log2(fold_change))
  
  # Check if both groups (Healthy and m_cond) have at least 2 observations
  save = TRUE
  tryCatch({
    if (save == TRUE){sink(paste0(output_path, filename))}
    
    print(filename)
    
    # Model A: Kruskal-Wallis Test (without covariates)
    kruskal_A <- kruskal.test(subset_data[[column]], subset_data$group.ID)
    print("Kruskal-Wallis Test (General model)")
    print(kruskal_A)
    if (save == TRUE){sink()}
    
  }, error = function(e) {
    message("Error in processing column ", column, ": ", e$message)
    next
  })
  
  # Store the p-values, fold change, and means in the significatives data frame
  significatives[counter, 1] <- column
  significatives[counter, 3] <- kruskal_A$p.value  # Group (from Kruskal-Wallis test)
  significatives[counter, 4] <- fold_change  # Fold change
  significatives[counter, 5] <- log2_fold_change  # Log2 fold change
  significatives[counter, 6] <- mean_healthy  # Mean of the Healthy group
  significatives[counter, 7] <- mean_condition  # Mean of the specific condition group
}

# Update column names of the significatives data frame
colnames(significatives) <- c("cell", "group+sv", "group", "fold_change", 
                              "log2_fold_change", "mean_healthy", "mean_condition")

# Save the significatives data frame as a TSV file
tsv_output_path <- file.path(output_path, "significatives_nonparametric_with_means_cs.tsv")
write.table(significatives, 
            file = tsv_output_path, 
            sep = "\t",          
            row.names = FALSE,   
            col.names = TRUE,    
            quote = FALSE)



### FTLD TDP
#### Log2

library("ggplot2")
library("openxlsx")
library("dplyr")
library("coin")  

#################################T.TESTS########################################
# FILE PATHS
frequency_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMATED_PROPORTIONS/Log2/FTLD/TDP/Log2_Cell_state_proportions.csv"
metadata_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx"
output_path <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMED_RESULTS/FTLD/TDP/Log2/"
################################################################################

if (!file.exists(output_path)) {
  dir.create(output_path, recursive = TRUE)
}
if (!file.exists(file.path(output_path,"Significative"))) {
  dir.create(file.path(output_path,"Significative"), recursive = TRUE)
}

data <- read.xlsx(metadata_file)

freq_cell_types <- read.csv(frequency_file)
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("long", "", x))
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("X", "", x))

merged_data <- merge(data, freq_cell_types, by.x = "sample.ID", by.y = "X")
merged_data[merged_data == 0] <- 1e-10

################################################################################
# Generate needed objects

m_conditions <- unique(merged_data$group.ID)
m_conditions_nh <- m_conditions[m_conditions != "Healthy"]
files_to_iterate <- colnames(merged_data)[4:length(colnames(merged_data))]
m_cond <- m_conditions_nh[1]
counter = 0

significatives <- data.frame(matrix(nrow = length(files_to_iterate), ncol = 3))
colnames(significatives)<- c("cell", "group+sv", "group")


for (column in colnames(freq_cell_types)[2:length(colnames(freq_cell_types))]){
  counter <- counter + 1
  filename <- paste0("Kruskal_", column, "_", m_cond, ".txt")
  
  subset_data <- merged_data[merged_data$group.ID %in% c("Healthy", m_cond), 
                             c("group.ID", column)]
  
  # Ensure group.ID is treated as a factor
  subset_data$group.ID <- factor(subset_data$group.ID, levels = c("Healthy", m_cond))
  
  # Calculate group means
  mean_healthy <- mean(subset_data[[column]][subset_data$group.ID == "Healthy"], na.rm = TRUE)
  mean_condition <- mean(subset_data[[column]][subset_data$group.ID == m_cond], na.rm = TRUE)
  
  # Calculate fold change
  fold_change <- ifelse(mean_healthy == 0, NA, mean_condition / mean_healthy)  # Avoid division by zero
  
  # Log-transform the fold change (optional)
  log2_fold_change <- ifelse(is.na(fold_change), NA, log2(fold_change))
  pval <- NA
  # Check if both groups (Healthy and m_cond) have at least 2 observations
  save = TRUE
  tryCatch({
    #if (save == TRUE){sink(paste0(output_path, filename))}
    
    print(filename)
    kruskal_A <- kruskal.test(subset_data[[column]], subset_data$group.ID)
    pval <- kruskal_A$p.value
  }, error = function(e) {
    message("Error in processing column ", column, ": ", e$message)
    #if (save == TRUE){sink()}
    #next
  })
  
  # Store the p-values, fold change, and means in the significatives data frame
  significatives[counter, 1] <- column
  significatives[counter, 3] <- pval  # Group (from Kruskal-Wallis test)
  significatives[counter, 4] <- fold_change  # Fold change
  significatives[counter, 5] <- log2_fold_change  # Log2 fold change
  significatives[counter, 6] <- mean_healthy  # Mean of the Healthy group
  significatives[counter, 7] <- mean_condition  # Mean of the specific condition group
}

# Update column names of the significatives data frame
colnames(significatives) <- c("cell", "group+sv", "group", "fold_change", 
                              "log2_fold_change", "mean_healthy", "mean_condition")

# Save the significatives data frame as a TSV file
tsv_output_path <- file.path(output_path, "significatives_nonparametric_with_means_cs.tsv")
write.table(significatives, 
            file = tsv_output_path, 
            sep = "\t",          
            row.names = FALSE,   
            col.names = TRUE,    
            quote = FALSE)



### FTLD TDP
#### Logit
library(car)
library("ggplot2")
library("openxlsx")
library("dplyr")
library("coin")  

#################################T.TESTS########################################
# FILE PATHS
frequency_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMATED_PROPORTIONS/Logit/FTLD/TDP/Logit_Cell_state_proportions.csv"
metadata_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx"
output_path <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMED_RESULTS/FTLD/TDP/Logit/"
################################################################################

if (!file.exists(output_path)) {
  dir.create(output_path, recursive = TRUE)
}
if (!file.exists(file.path(output_path,"Significative"))) {
  dir.create(file.path(output_path,"Significative"), recursive = TRUE)
}

data <- read.xlsx(metadata_file)

freq_cell_types <- read.csv(frequency_file)
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("long", "", x))
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("X", "", x))

merged_data <- merge(data, freq_cell_types, by.x = "sample.ID", by.y = "X")
merged_data[merged_data == 0] <- 1e-10

################################################################################
# Generate needed objects

m_conditions <- unique(merged_data$group.ID)
m_conditions_nh <- m_conditions[m_conditions != "Healthy"]
files_to_iterate <- colnames(merged_data)[4:length(colnames(merged_data))]
m_cond <- m_conditions_nh[1]
counter = 0

significatives <- data.frame(matrix(nrow = length(files_to_iterate), ncol = 3))
colnames(significatives)<- c("cell", "group+sv", "group")


for (column in colnames(freq_cell_types)[2:length(colnames(freq_cell_types))]){
  counter <- counter + 1
  filename <- paste0("Kruskal_", column, "_", m_cond, ".txt")
  
  subset_data <- merged_data[merged_data$group.ID %in% c("Healthy", m_cond), 
                             c("group.ID", column)]
  
  # Ensure group.ID is treated as a factor
  subset_data$group.ID <- factor(subset_data$group.ID, levels = c("Healthy", m_cond))
  
  # Calculate group means
  mean_healthy <- mean(subset_data[[column]][subset_data$group.ID == "Healthy"], na.rm = TRUE)
  mean_condition <- mean(subset_data[[column]][subset_data$group.ID == m_cond], na.rm = TRUE)
  
  # Calculate fold change
  fold_change <- ifelse(mean_healthy == 0, NA, mean_condition / mean_healthy)  # Avoid division by zero
  
  # Log-transform the fold change (optional)
  log2_fold_change <- ifelse(is.na(fold_change), NA, log2(fold_change))
  
  # Check if both groups (Healthy and m_cond) have at least 2 observations
  save = TRUE
  tryCatch({
    if (save == TRUE){sink(paste0(output_path, filename))}
    
    print(filename)
    
    # Model A: Kruskal-Wallis Test (without covariates)
    kruskal_A <- kruskal.test(subset_data[[column]], subset_data$group.ID)
    print("Kruskal-Wallis Test (General model)")
    print(kruskal_A)
    if (save == TRUE){sink()}
    
  }, error = function(e) {
    message("Error in processing column ", column, ": ", e$message)
    next
  })
  
  # Store the p-values, fold change, and means in the significatives data frame
  significatives[counter, 1] <- column
  significatives[counter, 3] <- kruskal_A$p.value  # Group (from Kruskal-Wallis test)
  significatives[counter, 4] <- fold_change  # Fold change
  significatives[counter, 5] <- log2_fold_change  # Log2 fold change
  significatives[counter, 6] <- mean_healthy  # Mean of the Healthy group
  significatives[counter, 7] <- mean_condition  # Mean of the specific condition group
}

# Update column names of the significatives data frame
colnames(significatives) <- c("cell", "group+sv", "group", "fold_change", 
                              "log2_fold_change", "mean_healthy", "mean_condition")

# Save the significatives data frame as a TSV file
tsv_output_path <- file.path(output_path, "significatives_nonparametric_with_means_cs.tsv")
write.table(significatives, 
            file = tsv_output_path, 
            sep = "\t",          
            row.names = FALSE,   
            col.names = TRUE,    
            quote = FALSE)



### FTLD TDP
#### ArcSin

library("ggplot2")
library("openxlsx")
library("dplyr")
library("coin")  

#################################T.TESTS########################################
# FILE PATHS
frequency_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMATED_PROPORTIONS/ArcSin/FTLD/TDP/Arcsin_Cell_state_proportions.csv"
metadata_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx"
output_path <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMED_RESULTS/FTLD/TDP/ArcSin/"
################################################################################

if (!file.exists(output_path)) {
  dir.create(output_path, recursive = TRUE)
}
if (!file.exists(file.path(output_path,"Significative"))) {
  dir.create(file.path(output_path,"Significative"), recursive = TRUE)
}

data <- read.xlsx(metadata_file)

freq_cell_types <- read.csv(frequency_file)
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("long", "", x))
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("X", "", x))

merged_data <- merge(data, freq_cell_types, by.x = "sample.ID", by.y = "X")
merged_data[merged_data == 0] <- 1e-10

################################################################################
# Generate needed objects

m_conditions <- unique(merged_data$group.ID)
m_conditions_nh <- m_conditions[m_conditions != "Healthy"]
files_to_iterate <- colnames(merged_data)[4:length(colnames(merged_data))]
m_cond <- m_conditions_nh[1]
counter = 0

significatives <- data.frame(matrix(nrow = length(files_to_iterate), ncol = 3))
colnames(significatives)<- c("cell", "group+sv", "group")


for (column in colnames(freq_cell_types)[2:length(colnames(freq_cell_types))]){
  counter <- counter + 1
  filename <- paste0("Kruskal_", column, "_", m_cond, ".txt")
  
  subset_data <- merged_data[merged_data$group.ID %in% c("Healthy", m_cond), 
                             c("group.ID", column)]
  
  # Ensure group.ID is treated as a factor
  subset_data$group.ID <- factor(subset_data$group.ID, levels = c("Healthy", m_cond))
  
  # Calculate group means
  mean_healthy <- mean(subset_data[[column]][subset_data$group.ID == "Healthy"], na.rm = TRUE)
  mean_condition <- mean(subset_data[[column]][subset_data$group.ID == m_cond], na.rm = TRUE)
  
  # Calculate fold change
  fold_change <- ifelse(mean_healthy == 0, NA, mean_condition / mean_healthy)  # Avoid division by zero
  
  # Log-transform the fold change (optional)
  log2_fold_change <- ifelse(is.na(fold_change), NA, log2(fold_change))
  
  # Check if both groups (Healthy and m_cond) have at least 2 observations
  save = TRUE
  tryCatch({
    if (save == TRUE){sink(paste0(output_path, filename))}
    
    print(filename)
    
    # Model A: Kruskal-Wallis Test (without covariates)
    kruskal_A <- kruskal.test(subset_data[[column]], subset_data$group.ID)
    print("Kruskal-Wallis Test (General model)")
    print(kruskal_A)
    if (save == TRUE){sink()}
    
  }, error = function(e) {
    message("Error in processing column ", column, ": ", e$message)
    next
  })
  
  # Store the p-values, fold change, and means in the significatives data frame
  significatives[counter, 1] <- column
  significatives[counter, 3] <- kruskal_A$p.value  # Group (from Kruskal-Wallis test)
  significatives[counter, 4] <- fold_change  # Fold change
  significatives[counter, 5] <- log2_fold_change  # Log2 fold change
  significatives[counter, 6] <- mean_healthy  # Mean of the Healthy group
  significatives[counter, 7] <- mean_condition  # Mean of the specific condition group
}

# Update column names of the significatives data frame
colnames(significatives) <- c("cell", "group+sv", "group", "fold_change", 
                              "log2_fold_change", "mean_healthy", "mean_condition")

# Save the significatives data frame as a TSV file
tsv_output_path <- file.path(output_path, "significatives_nonparametric_with_means_cs.tsv")
write.table(significatives, 
            file = tsv_output_path, 
            sep = "\t",          
            row.names = FALSE,   
            col.names = TRUE,    
            quote = FALSE)


### FTLD C9
#### LOG
library("ggplot2")
library("openxlsx")
library("dplyr")
library("coin")  

#################################T.TESTS########################################
# FILE PATHS
frequency_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMATED_PROPORTIONS/Log/FTLD/C9/Log_Cell_state_proportions.csv"
metadata_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx"
output_path <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMED_RESULTS/FTLD/C9/Log/"
################################################################################

if (!file.exists(output_path)) {
  dir.create(output_path, recursive = TRUE)
}
if (!file.exists(file.path(output_path,"Significative"))) {
  dir.create(file.path(output_path,"Significative"), recursive = TRUE)
}

data <- read.xlsx(metadata_file)

freq_cell_types <- read.csv(frequency_file)
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("long", "", x))
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("X", "", x))

merged_data <- merge(data, freq_cell_types, by.x = "sample.ID", by.y = "X")
merged_data[merged_data == 0] <- 1e-10

################################################################################
# Generate needed objects

m_conditions <- unique(merged_data$group.ID)
m_conditions_nh <- m_conditions[m_conditions != "Healthy"]
files_to_iterate <- colnames(merged_data)[4:length(colnames(merged_data))]
m_cond <- m_conditions_nh[1]
counter = 0

significatives <- data.frame(matrix(nrow = length(files_to_iterate), ncol = 3))
colnames(significatives)<- c("cell", "group+sv", "group")


for (column in colnames(freq_cell_types)[2:length(colnames(freq_cell_types))]){
  counter <- counter + 1
  filename <- paste0("Kruskal_", column, "_", m_cond, ".txt")
  
  subset_data <- merged_data[merged_data$group.ID %in% c("Healthy", m_cond), 
                             c("group.ID", column)]
  
  # Ensure group.ID is treated as a factor
  subset_data$group.ID <- factor(subset_data$group.ID, levels = c("Healthy", m_cond))
  
  # Calculate group means
  mean_healthy <- mean(subset_data[[column]][subset_data$group.ID == "Healthy"], na.rm = TRUE)
  mean_condition <- mean(subset_data[[column]][subset_data$group.ID == m_cond], na.rm = TRUE)
  
  # Calculate fold change
  fold_change <- ifelse(mean_healthy == 0, NA, mean_condition / mean_healthy)  # Avoid division by zero
  
  # Log-transform the fold change (optional)
  log2_fold_change <- ifelse(is.na(fold_change), NA, log2(fold_change))
  
  # Check if both groups (Healthy and m_cond) have at least 2 observations
  save = TRUE
  tryCatch({
    if (save == TRUE){sink(paste0(output_path, filename))}
    
    print(filename)
    
    # Model A: Kruskal-Wallis Test (without covariates)
    kruskal_A <- kruskal.test(subset_data[[column]], subset_data$group.ID)
    print("Kruskal-Wallis Test (General model)")
    print(kruskal_A)
    if (save == TRUE){sink()}
    
  }, error = function(e) {
    message("Error in processing column ", column, ": ", e$message)
    next
  })
  
  # Store the p-values, fold change, and means in the significatives data frame
  significatives[counter, 1] <- column
  significatives[counter, 3] <- kruskal_A$p.value  # Group (from Kruskal-Wallis test)
  significatives[counter, 4] <- fold_change  # Fold change
  significatives[counter, 5] <- log2_fold_change  # Log2 fold change
  significatives[counter, 6] <- mean_healthy  # Mean of the Healthy group
  significatives[counter, 7] <- mean_condition  # Mean of the specific condition group
}

# Update column names of the significatives data frame
colnames(significatives) <- c("cell", "group+sv", "group", "fold_change", 
                              "log2_fold_change", "mean_healthy", "mean_condition")

# Save the significatives data frame as a TSV file
tsv_output_path <- file.path(output_path, "significatives_nonparametric_with_means_cs.tsv")
write.table(significatives, 
            file = tsv_output_path, 
            sep = "\t",          
            row.names = FALSE,   
            col.names = TRUE,    
            quote = FALSE)


### FTLD C9
#### LOG2
library("ggplot2")
library("openxlsx")
library("dplyr")
library("coin")  

#################################T.TESTS########################################
# FILE PATHS
frequency_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMATED_PROPORTIONS/Log2/FTLD/C9/Log2_Cell_state_proportions.csv"
metadata_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx"
output_path <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMED_RESULTS/FTLD/C9/Log2/"
################################################################################

if (!file.exists(output_path)) {
  dir.create(output_path, recursive = TRUE)
}
if (!file.exists(file.path(output_path,"Significative"))) {
  dir.create(file.path(output_path,"Significative"), recursive = TRUE)
}

data <- read.xlsx(metadata_file)

freq_cell_types <- read.csv(frequency_file)
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("long", "", x))
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("X", "", x))

merged_data <- merge(data, freq_cell_types, by.x = "sample.ID", by.y = "X")
merged_data[merged_data == 0] <- 1e-10

################################################################################
# Generate needed objects

m_conditions <- unique(merged_data$group.ID)
m_conditions_nh <- m_conditions[m_conditions != "Healthy"]
files_to_iterate <- colnames(merged_data)[4:length(colnames(merged_data))]
m_cond <- m_conditions_nh[1]
counter = 0

significatives <- data.frame(matrix(nrow = length(files_to_iterate), ncol = 3))
colnames(significatives)<- c("cell", "group+sv", "group")


for (column in colnames(freq_cell_types)[2:length(colnames(freq_cell_types))]){
  counter <- counter + 1
  filename <- paste0("Kruskal_", column, "_", m_cond, ".txt")
  
  subset_data <- merged_data[merged_data$group.ID %in% c("Healthy", m_cond), 
                             c("group.ID", column)]
  
  # Ensure group.ID is treated as a factor
  subset_data$group.ID <- factor(subset_data$group.ID, levels = c("Healthy", m_cond))
  
  # Calculate group means
  mean_healthy <- mean(subset_data[[column]][subset_data$group.ID == "Healthy"], na.rm = TRUE)
  mean_condition <- mean(subset_data[[column]][subset_data$group.ID == m_cond], na.rm = TRUE)
  
  # Calculate fold change
  fold_change <- ifelse(mean_healthy == 0, NA, mean_condition / mean_healthy)  # Avoid division by zero
  
  # Log-transform the fold change (optional)
  log2_fold_change <- ifelse(is.na(fold_change), NA, log2(fold_change))
  
  # Check if both groups (Healthy and m_cond) have at least 2 observations
  save = TRUE
  tryCatch({
    if (save == TRUE){sink(paste0(output_path, filename))}
    
    print(filename)
    
    # Model A: Kruskal-Wallis Test (without covariates)
    kruskal_A <- kruskal.test(subset_data[[column]], subset_data$group.ID)
    print("Kruskal-Wallis Test (General model)")
    print(kruskal_A)
    if (save == TRUE){sink()}
    
  }, error = function(e) {
    message("Error in processing column ", column, ": ", e$message)
    next
  })
  
  # Store the p-values, fold change, and means in the significatives data frame
  significatives[counter, 1] <- column
  significatives[counter, 3] <- kruskal_A$p.value  # Group (from Kruskal-Wallis test)
  significatives[counter, 4] <- fold_change  # Fold change
  significatives[counter, 5] <- log2_fold_change  # Log2 fold change
  significatives[counter, 6] <- mean_healthy  # Mean of the Healthy group
  significatives[counter, 7] <- mean_condition  # Mean of the specific condition group
}

# Update column names of the significatives data frame
colnames(significatives) <- c("cell", "group+sv", "group", "fold_change", 
                              "log2_fold_change", "mean_healthy", "mean_condition")

# Save the significatives data frame as a TSV file
tsv_output_path <- file.path(output_path, "significatives_nonparametric_with_means_cs.tsv")
write.table(significatives, 
            file = tsv_output_path, 
            sep = "\t",          
            row.names = FALSE,   
            col.names = TRUE,    
            quote = FALSE)




### FTLD C9
#### LOGIT
library("ggplot2")
library("openxlsx")
library("dplyr")
library("coin")  

#################################T.TESTS########################################
# FILE PATHS
frequency_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMATED_PROPORTIONS/Logit/FTLD/C9/Logit_Cell_state_proportions.csv"
metadata_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx"
output_path <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMED_RESULTS/FTLD/C9/Logit/"
################################################################################

if (!file.exists(output_path)) {
  dir.create(output_path, recursive = TRUE)
}
if (!file.exists(file.path(output_path,"Significative"))) {
  dir.create(file.path(output_path,"Significative"), recursive = TRUE)
}

data <- read.xlsx(metadata_file)

freq_cell_types <- read.csv(frequency_file)
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("long", "", x))
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("X", "", x))

merged_data <- merge(data, freq_cell_types, by.x = "sample.ID", by.y = "X")
merged_data[merged_data == 0] <- 1e-10

################################################################################
# Generate needed objects

m_conditions <- unique(merged_data$group.ID)
m_conditions_nh <- m_conditions[m_conditions != "Healthy"]
files_to_iterate <- colnames(merged_data)[4:length(colnames(merged_data))]
m_cond <- m_conditions_nh[1]
counter = 0

significatives <- data.frame(matrix(nrow = length(files_to_iterate), ncol = 3))
colnames(significatives)<- c("cell", "group+sv", "group")


for (column in colnames(freq_cell_types)[2:length(colnames(freq_cell_types))]){
  counter <- counter + 1
  filename <- paste0("Kruskal_", column, "_", m_cond, ".txt")
  
  subset_data <- merged_data[merged_data$group.ID %in% c("Healthy", m_cond), 
                             c("group.ID", column)]
  
  # Ensure group.ID is treated as a factor
  subset_data$group.ID <- factor(subset_data$group.ID, levels = c("Healthy", m_cond))
  
  # Calculate group means
  mean_healthy <- mean(subset_data[[column]][subset_data$group.ID == "Healthy"], na.rm = TRUE)
  mean_condition <- mean(subset_data[[column]][subset_data$group.ID == m_cond], na.rm = TRUE)
  
  # Calculate fold change
  fold_change <- ifelse(mean_healthy == 0, NA, mean_condition / mean_healthy)  # Avoid division by zero
  
  # Log-transform the fold change (optional)
  log2_fold_change <- ifelse(is.na(fold_change), NA, log2(fold_change))
  
  # Check if both groups (Healthy and m_cond) have at least 2 observations
  save = TRUE
  tryCatch({
    if (save == TRUE){sink(paste0(output_path, filename))}
    
    print(filename)
    
    # Model A: Kruskal-Wallis Test (without covariates)
    kruskal_A <- kruskal.test(subset_data[[column]], subset_data$group.ID)
    print("Kruskal-Wallis Test (General model)")
    print(kruskal_A)
    if (save == TRUE){sink()}
    
  }, error = function(e) {
    message("Error in processing column ", column, ": ", e$message)
    next
  })
  
  # Store the p-values, fold change, and means in the significatives data frame
  significatives[counter, 1] <- column
  significatives[counter, 3] <- kruskal_A$p.value  # Group (from Kruskal-Wallis test)
  significatives[counter, 4] <- fold_change  # Fold change
  significatives[counter, 5] <- log2_fold_change  # Log2 fold change
  significatives[counter, 6] <- mean_healthy  # Mean of the Healthy group
  significatives[counter, 7] <- mean_condition  # Mean of the specific condition group
}

# Update column names of the significatives data frame
colnames(significatives) <- c("cell", "group+sv", "group", "fold_change", 
                              "log2_fold_change", "mean_healthy", "mean_condition")

# Save the significatives data frame as a TSV file
tsv_output_path <- file.path(output_path, "significatives_nonparametric_with_means_cs.tsv")
write.table(significatives, 
            file = tsv_output_path, 
            sep = "\t",          
            row.names = FALSE,   
            col.names = TRUE,    
            quote = FALSE)




### FTLD C9
#### ArcSin
library("ggplot2")
library("openxlsx")
library("dplyr")
library("coin")  

#################################T.TESTS########################################
# FILE PATHS
frequency_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMATED_PROPORTIONS/ArcSin/FTLD/C9/Arcsin_Cell_state_proportions.csv"
metadata_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx"
output_path <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMED_RESULTS/FTLD/C9/ArcSin/"
################################################################################

if (!file.exists(output_path)) {
  dir.create(output_path, recursive = TRUE)
}
if (!file.exists(file.path(output_path,"Significative"))) {
  dir.create(file.path(output_path,"Significative"), recursive = TRUE)
}

data <- read.xlsx(metadata_file)

freq_cell_types <- read.csv(frequency_file)
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("long", "", x))
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("X", "", x))

merged_data <- merge(data, freq_cell_types, by.x = "sample.ID", by.y = "X")
merged_data[merged_data == 0] <- 1e-10

################################################################################
# Generate needed objects

m_conditions <- unique(merged_data$group.ID)
m_conditions_nh <- m_conditions[m_conditions != "Healthy"]
files_to_iterate <- colnames(merged_data)[4:length(colnames(merged_data))]
m_cond <- m_conditions_nh[1]
counter = 0

significatives <- data.frame(matrix(nrow = length(files_to_iterate), ncol = 3))
colnames(significatives)<- c("cell", "group+sv", "group")


for (column in colnames(freq_cell_types)[2:length(colnames(freq_cell_types))]){
  counter <- counter + 1
  filename <- paste0("Kruskal_", column, "_", m_cond, ".txt")
  
  subset_data <- merged_data[merged_data$group.ID %in% c("Healthy", m_cond), 
                             c("group.ID", column)]
  
  # Ensure group.ID is treated as a factor
  subset_data$group.ID <- factor(subset_data$group.ID, levels = c("Healthy", m_cond))
  
  # Calculate group means
  mean_healthy <- mean(subset_data[[column]][subset_data$group.ID == "Healthy"], na.rm = TRUE)
  mean_condition <- mean(subset_data[[column]][subset_data$group.ID == m_cond], na.rm = TRUE)
  
  # Calculate fold change
  fold_change <- ifelse(mean_healthy == 0, NA, mean_condition / mean_healthy)  # Avoid division by zero
  
  # Log-transform the fold change (optional)
  log2_fold_change <- ifelse(is.na(fold_change), NA, log2(fold_change))
  
  # Check if both groups (Healthy and m_cond) have at least 2 observations
  save = TRUE
  tryCatch({
    if (save == TRUE){sink(paste0(output_path, filename))}
    
    print(filename)
    
    # Model A: Kruskal-Wallis Test (without covariates)
    kruskal_A <- kruskal.test(subset_data[[column]], subset_data$group.ID)
    print("Kruskal-Wallis Test (General model)")
    print(kruskal_A)
    if (save == TRUE){sink()}
    
  }, error = function(e) {
    message("Error in processing column ", column, ": ", e$message)
    next
  })
  
  # Store the p-values, fold change, and means in the significatives data frame
  significatives[counter, 1] <- column
  significatives[counter, 3] <- kruskal_A$p.value  # Group (from Kruskal-Wallis test)
  significatives[counter, 4] <- fold_change  # Fold change
  significatives[counter, 5] <- log2_fold_change  # Log2 fold change
  significatives[counter, 6] <- mean_healthy  # Mean of the Healthy group
  significatives[counter, 7] <- mean_condition  # Mean of the specific condition group
}

# Update column names of the significatives data frame
colnames(significatives) <- c("cell", "group+sv", "group", "fold_change", 
                              "log2_fold_change", "mean_healthy", "mean_condition")

# Save the significatives data frame as a TSV file
tsv_output_path <- file.path(output_path, "significatives_nonparametric_with_means_cs.tsv")
write.table(significatives, 
            file = tsv_output_path, 
            sep = "\t",          
            row.names = FALSE,   
            col.names = TRUE,    
            quote = FALSE)


# POTTIER TDP

#### Log

library("ggplot2")
library("openxlsx")
library("dplyr")
library("coin")  

#################################T.TESTS########################################
# FILE PATHS
frequency_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMATED_PROPORTIONS/Log/Pottier/TDP/Log_Cell_state_proportions.csv"
metadata_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/NEW_BULK/METADATA/Sample_info.txt"
output_path <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMED_RESULTS/Pottier/TDP/Log/"
################################################################################

if (!file.exists(output_path)) {
  dir.create(output_path, recursive = TRUE)
}
if (!file.exists(file.path(output_path,"Significative"))) {
  dir.create(file.path(output_path,"Significative"), recursive = TRUE)
}

data <- read.delim(metadata_file)
data$group.ID <- data$GROUP
data$GROUP <- NULL
data <- data[!data$group.ID == "FTLD-TDP-C",]
data$group.ID[data$group.ID == "Control"] <- "Healthy"
data$group.ID[!data$group.ID == "Healthy"] <- "TDP"

freq_cell_types <- read.csv(frequency_file)
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("\\.", "-", x))

merged_data <- merge(data, freq_cell_types, by.x = "FCX_ID", by.y = "X")
merged_data[merged_data == 0] <- 1e-10

################################################################################
# Generate needed objects

m_conditions <- unique(merged_data$group.ID)
m_conditions_nh <- m_conditions[m_conditions != "Healthy"]
files_to_iterate <- colnames(merged_data)[4:length(colnames(merged_data))]
m_cond <- m_conditions_nh[1]
counter = 0

significatives <- data.frame(matrix(nrow = length(files_to_iterate), ncol = 3))
colnames(significatives)<- c("cell", "group+sv", "group")


for (column in colnames(freq_cell_types)[2:length(colnames(freq_cell_types))]){
  counter <- counter + 1
  filename <- paste0("Kruskal_", column, "_", m_cond, ".txt")
  
  subset_data <- merged_data[merged_data$group.ID %in% c("Healthy", m_cond), 
                             c("group.ID", column)]
  
  # Ensure group.ID is treated as a factor
  subset_data$group.ID <- factor(subset_data$group.ID, levels = c("Healthy", m_cond))
  
  # Calculate group means
  mean_healthy <- mean(subset_data[[column]][subset_data$group.ID == "Healthy"], na.rm = TRUE)
  mean_condition <- mean(subset_data[[column]][subset_data$group.ID == m_cond], na.rm = TRUE)
  
  # Calculate fold change
  fold_change <- ifelse(mean_healthy == 0, NA, mean_condition / mean_healthy)  # Avoid division by zero
  
  # Log-transform the fold change (optional)
  log2_fold_change <- ifelse(is.na(fold_change), NA, log2(fold_change))
  
  # Check if both groups (Healthy and m_cond) have at least 2 observations
  save = TRUE
  tryCatch({
    if (save == TRUE){sink(paste0(output_path, filename))}
    
    print(filename)
    
    # Model A: Kruskal-Wallis Test (without covariates)
    kruskal_A <- kruskal.test(subset_data[[column]], subset_data$group.ID)
    print("Kruskal-Wallis Test (General model)")
    print(kruskal_A)
    if (save == TRUE){sink()}
    
  }, error = function(e) {
    message("Error in processing column ", column, ": ", e$message)
    next
  })
  
  # Store the p-values, fold change, and means in the significatives data frame
  significatives[counter, 1] <- column
  significatives[counter, 3] <- kruskal_A$p.value  # Group (from Kruskal-Wallis test)
  significatives[counter, 4] <- fold_change  # Fold change
  significatives[counter, 5] <- log2_fold_change  # Log2 fold change
  significatives[counter, 6] <- mean_healthy  # Mean of the Healthy group
  significatives[counter, 7] <- mean_condition  # Mean of the specific condition group
}

# Update column names of the significatives data frame
colnames(significatives) <- c("cell", "group+sv", "group", "fold_change", 
                              "log2_fold_change", "mean_healthy", "mean_condition")

# Save the significatives data frame as a TSV file
tsv_output_path <- file.path(output_path, "significatives_nonparametric_with_means_cs.tsv")
write.table(significatives, 
            file = tsv_output_path, 
            sep = "\t",          
            row.names = FALSE,   
            col.names = TRUE,    
            quote = FALSE)



# POTTIER TDP

#### Log2

library("ggplot2")
library("openxlsx")
library("dplyr")
library("coin")  

#################################T.TESTS########################################
# FILE PATHS
frequency_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMATED_PROPORTIONS/Log2/Pottier/TDP/Log_Cell_state_proportions.csv"
metadata_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/NEW_BULK/METADATA/Sample_info.txt"
output_path <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMED_RESULTS/Pottier/TDP/Log2/"
################################################################################

if (!file.exists(output_path)) {
  dir.create(output_path, recursive = TRUE)
}
if (!file.exists(file.path(output_path,"Significative"))) {
  dir.create(file.path(output_path,"Significative"), recursive = TRUE)
}

data <- read.delim(metadata_file)
data$group.ID <- data$GROUP
data$GROUP <- NULL
data <- data[!data$group.ID == "FTLD-TDP-C",]
data$group.ID[data$group.ID == "Control"] <- "Healthy"
data$group.ID[!data$group.ID == "Healthy"] <- "TDP"

freq_cell_types <- read.csv(frequency_file)
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("\\.", "-", x))

merged_data <- merge(data, freq_cell_types, by.x = "FCX_ID", by.y = "X")
merged_data[merged_data == 0] <- 1e-10

################################################################################
# Generate needed objects

m_conditions <- unique(merged_data$group.ID)
m_conditions_nh <- m_conditions[m_conditions != "Healthy"]
files_to_iterate <- colnames(merged_data)[4:length(colnames(merged_data))]
m_cond <- m_conditions_nh[1]
counter = 0

significatives <- data.frame(matrix(nrow = length(files_to_iterate), ncol = 3))
colnames(significatives)<- c("cell", "group+sv", "group")


for (column in colnames(freq_cell_types)[2:length(colnames(freq_cell_types))]){
  counter <- counter + 1
  filename <- paste0("Kruskal_", column, "_", m_cond, ".txt")
  
  subset_data <- merged_data[merged_data$group.ID %in% c("Healthy", m_cond), 
                             c("group.ID", column)]
  
  # Ensure group.ID is treated as a factor
  subset_data$group.ID <- factor(subset_data$group.ID, levels = c("Healthy", m_cond))
  
  # Calculate group means
  mean_healthy <- mean(subset_data[[column]][subset_data$group.ID == "Healthy"], na.rm = TRUE)
  mean_condition <- mean(subset_data[[column]][subset_data$group.ID == m_cond], na.rm = TRUE)
  
  # Calculate fold change
  fold_change <- ifelse(mean_healthy == 0, NA, mean_condition / mean_healthy)  # Avoid division by zero
  
  # Log-transform the fold change (optional)
  log2_fold_change <- ifelse(is.na(fold_change), NA, log2(fold_change))
  
  # Check if both groups (Healthy and m_cond) have at least 2 observations
  save = TRUE
  tryCatch({
    if (save == TRUE){sink(paste0(output_path, filename))}
    
    print(filename)
    
    # Model A: Kruskal-Wallis Test (without covariates)
    kruskal_A <- kruskal.test(subset_data[[column]], subset_data$group.ID)
    print("Kruskal-Wallis Test (General model)")
    print(kruskal_A)
    if (save == TRUE){sink()}
    
  }, error = function(e) {
    message("Error in processing column ", column, ": ", e$message)
    next
  })
  
  # Store the p-values, fold change, and means in the significatives data frame
  significatives[counter, 1] <- column
  significatives[counter, 3] <- kruskal_A$p.value  # Group (from Kruskal-Wallis test)
  significatives[counter, 4] <- fold_change  # Fold change
  significatives[counter, 5] <- log2_fold_change  # Log2 fold change
  significatives[counter, 6] <- mean_healthy  # Mean of the Healthy group
  significatives[counter, 7] <- mean_condition  # Mean of the specific condition group
}

# Update column names of the significatives data frame
colnames(significatives) <- c("cell", "group+sv", "group", "fold_change", 
                              "log2_fold_change", "mean_healthy", "mean_condition")

# Save the significatives data frame as a TSV file
tsv_output_path <- file.path(output_path, "significatives_nonparametric_with_means_cs.tsv")
write.table(significatives, 
            file = tsv_output_path, 
            sep = "\t",          
            row.names = FALSE,   
            col.names = TRUE,    
            quote = FALSE)



# POTTIER TDP

#### LogIT

library("ggplot2")
library("openxlsx")
library("dplyr")
library("coin")  

#################################T.TESTS########################################
# FILE PATHS
frequency_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMATED_PROPORTIONS/Logit/Pottier/TDP/Log_Cell_state_proportions.csv"
metadata_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/NEW_BULK/METADATA/Sample_info.txt"
output_path <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMED_RESULTS/Pottier/TDP/Logit/"
################################################################################

if (!file.exists(output_path)) {
  dir.create(output_path, recursive = TRUE)
}
if (!file.exists(file.path(output_path,"Significative"))) {
  dir.create(file.path(output_path,"Significative"), recursive = TRUE)
}

data <- read.delim(metadata_file)
data$group.ID <- data$GROUP
data$GROUP <- NULL
data <- data[!data$group.ID == "FTLD-TDP-C",]
data$group.ID[data$group.ID == "Control"] <- "Healthy"
data$group.ID[!data$group.ID == "Healthy"] <- "TDP"

freq_cell_types <- read.csv(frequency_file)
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("\\.", "-", x))

merged_data <- merge(data, freq_cell_types, by.x = "FCX_ID", by.y = "X")
merged_data[merged_data == 0] <- 1e-10

################################################################################
# Generate needed objects

m_conditions <- unique(merged_data$group.ID)
m_conditions_nh <- m_conditions[m_conditions != "Healthy"]
files_to_iterate <- colnames(merged_data)[4:length(colnames(merged_data))]
m_cond <- m_conditions_nh[1]
counter = 0

significatives <- data.frame(matrix(nrow = length(files_to_iterate), ncol = 3))
colnames(significatives)<- c("cell", "group+sv", "group")


for (column in colnames(freq_cell_types)[2:length(colnames(freq_cell_types))]){
  counter <- counter + 1
  filename <- paste0("Kruskal_", column, "_", m_cond, ".txt")
  
  subset_data <- merged_data[merged_data$group.ID %in% c("Healthy", m_cond), 
                             c("group.ID", column)]
  
  # Ensure group.ID is treated as a factor
  subset_data$group.ID <- factor(subset_data$group.ID, levels = c("Healthy", m_cond))
  
  # Calculate group means
  mean_healthy <- mean(subset_data[[column]][subset_data$group.ID == "Healthy"], na.rm = TRUE)
  mean_condition <- mean(subset_data[[column]][subset_data$group.ID == m_cond], na.rm = TRUE)
  
  # Calculate fold change
  fold_change <- ifelse(mean_healthy == 0, NA, mean_condition / mean_healthy)  # Avoid division by zero
  
  # Log-transform the fold change (optional)
  log2_fold_change <- ifelse(is.na(fold_change), NA, log2(fold_change))
  
  # Check if both groups (Healthy and m_cond) have at least 2 observations
  save = TRUE
  tryCatch({
    if (save == TRUE){sink(paste0(output_path, filename))}
    
    print(filename)
    
    # Model A: Kruskal-Wallis Test (without covariates)
    kruskal_A <- kruskal.test(subset_data[[column]], subset_data$group.ID)
    print("Kruskal-Wallis Test (General model)")
    print(kruskal_A)
    if (save == TRUE){sink()}
    
  }, error = function(e) {
    message("Error in processing column ", column, ": ", e$message)
    next
  })
  
  # Store the p-values, fold change, and means in the significatives data frame
  significatives[counter, 1] <- column
  significatives[counter, 3] <- kruskal_A$p.value  # Group (from Kruskal-Wallis test)
  significatives[counter, 4] <- fold_change  # Fold change
  significatives[counter, 5] <- log2_fold_change  # Log2 fold change
  significatives[counter, 6] <- mean_healthy  # Mean of the Healthy group
  significatives[counter, 7] <- mean_condition  # Mean of the specific condition group
}

# Update column names of the significatives data frame
colnames(significatives) <- c("cell", "group+sv", "group", "fold_change", 
                              "log2_fold_change", "mean_healthy", "mean_condition")

# Save the significatives data frame as a TSV file
tsv_output_path <- file.path(output_path, "significatives_nonparametric_with_means_cs.tsv")
write.table(significatives, 
            file = tsv_output_path, 
            sep = "\t",          
            row.names = FALSE,   
            col.names = TRUE,    
            quote = FALSE)



#### ArcSin

library("ggplot2")
library("openxlsx")
library("dplyr")
library("coin")  

#################################T.TESTS########################################
# FILE PATHS
frequency_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMATED_PROPORTIONS/ArcSin/Pottier/TDP/Log_Cell_state_proportions.csv"
metadata_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/NEW_BULK/METADATA/Sample_info.txt"
output_path <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMED_RESULTS/Pottier/TDP/ArcSin/"
################################################################################

if (!file.exists(output_path)) {
  dir.create(output_path, recursive = TRUE)
}
if (!file.exists(file.path(output_path,"Significative"))) {
  dir.create(file.path(output_path,"Significative"), recursive = TRUE)
}

data <- read.delim(metadata_file)
data$group.ID <- data$GROUP
data$GROUP <- NULL
data <- data[!data$group.ID == "FTLD-TDP-C",]
data$group.ID[data$group.ID == "Control"] <- "Healthy"
data$group.ID[!data$group.ID == "Healthy"] <- "TDP"

freq_cell_types <- read.csv(frequency_file)
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("\\.", "-", x))

merged_data <- merge(data, freq_cell_types, by.x = "FCX_ID", by.y = "X")
merged_data[merged_data == 0] <- 1e-10

################################################################################
# Generate needed objects

m_conditions <- unique(merged_data$group.ID)
m_conditions_nh <- m_conditions[m_conditions != "Healthy"]
files_to_iterate <- colnames(merged_data)[4:length(colnames(merged_data))]
m_cond <- m_conditions_nh[1]
counter = 0

significatives <- data.frame(matrix(nrow = length(files_to_iterate), ncol = 3))
colnames(significatives)<- c("cell", "group+sv", "group")


for (column in colnames(freq_cell_types)[2:length(colnames(freq_cell_types))]){
  counter <- counter + 1
  filename <- paste0("Kruskal_", column, "_", m_cond, ".txt")
  
  subset_data <- merged_data[merged_data$group.ID %in% c("Healthy", m_cond), 
                             c("group.ID", column)]
  
  # Ensure group.ID is treated as a factor
  subset_data$group.ID <- factor(subset_data$group.ID, levels = c("Healthy", m_cond))
  
  # Calculate group means
  mean_healthy <- mean(subset_data[[column]][subset_data$group.ID == "Healthy"], na.rm = TRUE)
  mean_condition <- mean(subset_data[[column]][subset_data$group.ID == m_cond], na.rm = TRUE)
  
  # Calculate fold change
  fold_change <- ifelse(mean_healthy == 0, NA, mean_condition / mean_healthy)  # Avoid division by zero
  
  # Log-transform the fold change (optional)
  log2_fold_change <- ifelse(is.na(fold_change), NA, log2(fold_change))
  
  # Check if both groups (Healthy and m_cond) have at least 2 observations
  save = TRUE
  tryCatch({
    if (save == TRUE){sink(paste0(output_path, filename))}
    
    print(filename)
    
    # Model A: Kruskal-Wallis Test (without covariates)
    kruskal_A <- kruskal.test(subset_data[[column]], subset_data$group.ID)
    print("Kruskal-Wallis Test (General model)")
    print(kruskal_A)
    if (save == TRUE){sink()}
    
  }, error = function(e) {
    message("Error in processing column ", column, ": ", e$message)
    next
  })
  
  # Store the p-values, fold change, and means in the significatives data frame
  significatives[counter, 1] <- column
  significatives[counter, 3] <- kruskal_A$p.value  # Group (from Kruskal-Wallis test)
  significatives[counter, 4] <- fold_change  # Fold change
  significatives[counter, 5] <- log2_fold_change  # Log2 fold change
  significatives[counter, 6] <- mean_healthy  # Mean of the Healthy group
  significatives[counter, 7] <- mean_condition  # Mean of the specific condition group
}

# Update column names of the significatives data frame
colnames(significatives) <- c("cell", "group+sv", "group", "fold_change", 
                              "log2_fold_change", "mean_healthy", "mean_condition")

# Save the significatives data frame as a TSV file
tsv_output_path <- file.path(output_path, "significatives_nonparametric_with_means_cs.tsv")
write.table(significatives, 
            file = tsv_output_path, 
            sep = "\t",          
            row.names = FALSE,   
            col.names = TRUE,    
            quote = FALSE)


# RIMMOD C9
#### Log

library("ggplot2")
library("openxlsx")
library("dplyr")
library("coin")  

#################################T.TESTS########################################
# FILE PATHS
frequency_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMATED_PROPORTIONS/Log/Rimod/C9/Log_Cell_state_proportions.csv"
metadata_file <- "/media/jaumatell/datos/URI/RiMod/Data/rimod_ftd_dataset_table_v3.txt"
output_path <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMED_RESULTS/Rimod/C9/Log/"
################################################################################

if (!file.exists(output_path)) {
  dir.create(output_path, recursive = TRUE)
}
if (!file.exists(file.path(output_path,"Significative"))) {
  dir.create(file.path(output_path,"Significative"), recursive = TRUE)
}

data <- read.delim(metadata_file, row.names = 1)
data$group.ID <- data$DiseaseCode
data$DiseaseCode <- NULL
data <- data[!data$group.ID == "FTD-GRN",]
data <- data[!data$group.ID == "FTD-MAPT",]
data$group.ID[data$group.ID == "control"] <- "Healthy"
data$group.ID[data$group.ID == "FTD-C9"] <- "C9orf72"
data$sample.ID <- rownames(data)

freq_cell_types <- read.csv(frequency_file)
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("long", "", x))
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("X", "", x))

merged_data <- merge(data, freq_cell_types, by.x = "sample.ID", by.y = "X")
merged_data[merged_data == 0] <- 1e-10

################################################################################
# Generate needed objects

m_conditions <- unique(merged_data$group.ID)
m_conditions_nh <- m_conditions[m_conditions != "Healthy"]
files_to_iterate <- colnames(merged_data)[4:length(colnames(merged_data))]
m_cond <- m_conditions_nh[1]
counter = 0

significatives <- data.frame(matrix(nrow = length(files_to_iterate), ncol = 3))
colnames(significatives)<- c("cell", "group+sv", "group")


for (column in colnames(freq_cell_types)[2:length(colnames(freq_cell_types))]){
  counter <- counter + 1
  filename <- paste0("Kruskal_", column, "_", m_cond, ".txt")
  
  subset_data <- merged_data[merged_data$group.ID %in% c("Healthy", m_cond), 
                             c("group.ID", column)]
  
  # Ensure group.ID is treated as a factor
  subset_data$group.ID <- factor(subset_data$group.ID, levels = c("Healthy", m_cond))
  
  # Calculate group means
  mean_healthy <- mean(subset_data[[column]][subset_data$group.ID == "Healthy"], na.rm = TRUE)
  mean_condition <- mean(subset_data[[column]][subset_data$group.ID == m_cond], na.rm = TRUE)
  
  # Calculate fold change
  fold_change <- ifelse(mean_healthy == 0, NA, mean_condition / mean_healthy)  # Avoid division by zero
  
  # Log-transform the fold change (optional)
  log2_fold_change <- ifelse(is.na(fold_change), NA, log2(fold_change))
  
  # Check if both groups (Healthy and m_cond) have at least 2 observations
  save = TRUE
  tryCatch({
    if (save == TRUE){sink(paste0(output_path, filename))}
    
    print(filename)
    
    # Model A: Kruskal-Wallis Test (without covariates)
    kruskal_A <- kruskal.test(subset_data[[column]], subset_data$group.ID)
    print("Kruskal-Wallis Test (General model)")
    print(kruskal_A)
    if (save == TRUE){sink()}
    
  }, error = function(e) {
    message("Error in processing column ", column, ": ", e$message)
    next
  })
  
  # Store the p-values, fold change, and means in the significatives data frame
  significatives[counter, 1] <- column
  significatives[counter, 3] <- kruskal_A$p.value  # Group (from Kruskal-Wallis test)
  significatives[counter, 4] <- fold_change  # Fold change
  significatives[counter, 5] <- log2_fold_change  # Log2 fold change
  significatives[counter, 6] <- mean_healthy  # Mean of the Healthy group
  significatives[counter, 7] <- mean_condition  # Mean of the specific condition group
}

# Update column names of the significatives data frame
colnames(significatives) <- c("cell", "group+sv", "group", "fold_change", 
                              "log2_fold_change", "mean_healthy", "mean_condition")

# Save the significatives data frame as a TSV file
tsv_output_path <- file.path(output_path, "significatives_nonparametric_with_means_cs.tsv")
write.table(significatives, 
            file = tsv_output_path, 
            sep = "\t",          
            row.names = FALSE,   
            col.names = TRUE,    
            quote = FALSE)


#### Log2

library("ggplot2")
library("openxlsx")
library("dplyr")
library("coin")  

#################################T.TESTS########################################
# FILE PATHS
frequency_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMATED_PROPORTIONS/Log2/Rimod/C9/Log2_Cell_state_proportions.csv"
metadata_file <- "/media/jaumatell/datos/URI/RiMod/Data/rimod_ftd_dataset_table_v3.txt"
output_path <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMED_RESULTS/Rimod/C9/Log2/"
################################################################################

if (!file.exists(output_path)) {
  dir.create(output_path, recursive = TRUE)
}
if (!file.exists(file.path(output_path,"Significative"))) {
  dir.create(file.path(output_path,"Significative"), recursive = TRUE)
}

data <- read.delim(metadata_file, row.names = 1)
data$group.ID <- data$DiseaseCode
data$DiseaseCode <- NULL
data <- data[!data$group.ID == "FTD-GRN",]
data <- data[!data$group.ID == "FTD-MAPT",]
data$group.ID[data$group.ID == "control"] <- "Healthy"
data$group.ID[data$group.ID == "FTD-C9"] <- "C9orf72"
data$sample.ID <- rownames(data)

freq_cell_types <- read.csv(frequency_file)
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("long", "", x))
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("X", "", x))

merged_data <- merge(data, freq_cell_types, by.x = "sample.ID", by.y = "X")
merged_data[merged_data == 0] <- 1e-10

################################################################################
# Generate needed objects

m_conditions <- unique(merged_data$group.ID)
m_conditions_nh <- m_conditions[m_conditions != "Healthy"]
files_to_iterate <- colnames(merged_data)[4:length(colnames(merged_data))]
m_cond <- m_conditions_nh[1]
counter = 0

significatives <- data.frame(matrix(nrow = length(files_to_iterate), ncol = 3))
colnames(significatives)<- c("cell", "group+sv", "group")


for (column in colnames(freq_cell_types)[2:length(colnames(freq_cell_types))]){
  counter <- counter + 1
  filename <- paste0("Kruskal_", column, "_", m_cond, ".txt")
  
  subset_data <- merged_data[merged_data$group.ID %in% c("Healthy", m_cond), 
                             c("group.ID", column)]
  
  # Ensure group.ID is treated as a factor
  subset_data$group.ID <- factor(subset_data$group.ID, levels = c("Healthy", m_cond))
  
  # Calculate group means
  mean_healthy <- mean(subset_data[[column]][subset_data$group.ID == "Healthy"], na.rm = TRUE)
  mean_condition <- mean(subset_data[[column]][subset_data$group.ID == m_cond], na.rm = TRUE)
  
  # Calculate fold change
  fold_change <- ifelse(mean_healthy == 0, NA, mean_condition / mean_healthy)  # Avoid division by zero
  
  # Log-transform the fold change (optional)
  log2_fold_change <- ifelse(is.na(fold_change), NA, log2(fold_change))
  
  # Check if both groups (Healthy and m_cond) have at least 2 observations
  save = TRUE
  tryCatch({
    if (save == TRUE){sink(paste0(output_path, filename))}
    
    print(filename)
    
    # Model A: Kruskal-Wallis Test (without covariates)
    kruskal_A <- kruskal.test(subset_data[[column]], subset_data$group.ID)
    print("Kruskal-Wallis Test (General model)")
    print(kruskal_A)
    if (save == TRUE){sink()}
    
  }, error = function(e) {
    message("Error in processing column ", column, ": ", e$message)
    next
  })
  
  # Store the p-values, fold change, and means in the significatives data frame
  significatives[counter, 1] <- column
  significatives[counter, 3] <- kruskal_A$p.value  # Group (from Kruskal-Wallis test)
  significatives[counter, 4] <- fold_change  # Fold change
  significatives[counter, 5] <- log2_fold_change  # Log2 fold change
  significatives[counter, 6] <- mean_healthy  # Mean of the Healthy group
  significatives[counter, 7] <- mean_condition  # Mean of the specific condition group
}

# Update column names of the significatives data frame
colnames(significatives) <- c("cell", "group+sv", "group", "fold_change", 
                              "log2_fold_change", "mean_healthy", "mean_condition")

# Save the significatives data frame as a TSV file
tsv_output_path <- file.path(output_path, "significatives_nonparametric_with_means_cs.tsv")
write.table(significatives, 
            file = tsv_output_path, 
            sep = "\t",          
            row.names = FALSE,   
            col.names = TRUE,    
            quote = FALSE)



#### Logit

library("ggplot2")
library("openxlsx")
library("dplyr")
library("coin")  

#################################T.TESTS########################################
# FILE PATHS
frequency_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMATED_PROPORTIONS/Logit/Rimod/C9/Logit_Cell_state_proportions.csv"
metadata_file <- "/media/jaumatell/datos/URI/RiMod/Data/rimod_ftd_dataset_table_v3.txt"
output_path <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMED_RESULTS/Rimod/C9/Logit/"
################################################################################

if (!file.exists(output_path)) {
  dir.create(output_path, recursive = TRUE)
}
if (!file.exists(file.path(output_path,"Significative"))) {
  dir.create(file.path(output_path,"Significative"), recursive = TRUE)
}

data <- read.delim(metadata_file, row.names = 1)
data$group.ID <- data$DiseaseCode
data$DiseaseCode <- NULL
data <- data[!data$group.ID == "FTD-GRN",]
data <- data[!data$group.ID == "FTD-MAPT",]
data$group.ID[data$group.ID == "control"] <- "Healthy"
data$group.ID[data$group.ID == "FTD-C9"] <- "C9orf72"
data$sample.ID <- rownames(data)

freq_cell_types <- read.csv(frequency_file)
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("long", "", x))
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("X", "", x))

merged_data <- merge(data, freq_cell_types, by.x = "sample.ID", by.y = "X")
merged_data[merged_data == 0] <- 1e-10

################################################################################
# Generate needed objects

m_conditions <- unique(merged_data$group.ID)
m_conditions_nh <- m_conditions[m_conditions != "Healthy"]
files_to_iterate <- colnames(merged_data)[4:length(colnames(merged_data))]
m_cond <- m_conditions_nh[1]
counter = 0

significatives <- data.frame(matrix(nrow = length(files_to_iterate), ncol = 3))
colnames(significatives)<- c("cell", "group+sv", "group")


for (column in colnames(freq_cell_types)[2:length(colnames(freq_cell_types))]){
  counter <- counter + 1
  filename <- paste0("Kruskal_", column, "_", m_cond, ".txt")
  
  subset_data <- merged_data[merged_data$group.ID %in% c("Healthy", m_cond), 
                             c("group.ID", column)]
  
  # Ensure group.ID is treated as a factor
  subset_data$group.ID <- factor(subset_data$group.ID, levels = c("Healthy", m_cond))
  
  # Calculate group means
  mean_healthy <- mean(subset_data[[column]][subset_data$group.ID == "Healthy"], na.rm = TRUE)
  mean_condition <- mean(subset_data[[column]][subset_data$group.ID == m_cond], na.rm = TRUE)
  
  # Calculate fold change
  fold_change <- ifelse(mean_healthy == 0, NA, mean_condition / mean_healthy)  # Avoid division by zero
  
  # Log-transform the fold change (optional)
  log2_fold_change <- ifelse(is.na(fold_change), NA, log2(fold_change))
  
  # Check if both groups (Healthy and m_cond) have at least 2 observations
  save = TRUE
  tryCatch({
    if (save == TRUE){sink(paste0(output_path, filename))}
    
    print(filename)
    
    # Model A: Kruskal-Wallis Test (without covariates)
    kruskal_A <- kruskal.test(subset_data[[column]], subset_data$group.ID)
    print("Kruskal-Wallis Test (General model)")
    print(kruskal_A)
    if (save == TRUE){sink()}
    
  }, error = function(e) {
    message("Error in processing column ", column, ": ", e$message)
    next
  })
  
  # Store the p-values, fold change, and means in the significatives data frame
  significatives[counter, 1] <- column
  significatives[counter, 3] <- kruskal_A$p.value  # Group (from Kruskal-Wallis test)
  significatives[counter, 4] <- fold_change  # Fold change
  significatives[counter, 5] <- log2_fold_change  # Log2 fold change
  significatives[counter, 6] <- mean_healthy  # Mean of the Healthy group
  significatives[counter, 7] <- mean_condition  # Mean of the specific condition group
}

# Update column names of the significatives data frame
colnames(significatives) <- c("cell", "group+sv", "group", "fold_change", 
                              "log2_fold_change", "mean_healthy", "mean_condition")

# Save the significatives data frame as a TSV file
tsv_output_path <- file.path(output_path, "significatives_nonparametric_with_means_cs.tsv")
write.table(significatives, 
            file = tsv_output_path, 
            sep = "\t",          
            row.names = FALSE,   
            col.names = TRUE,    
            quote = FALSE)



#### ArcSin

library("ggplot2")
library("openxlsx")
library("dplyr")
library("coin")  

#################################T.TESTS########################################
# FILE PATHS
frequency_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMATED_PROPORTIONS/ArcSin/Rimod/C9/Arcsin_Cell_state_proportions.csv"
metadata_file <- "/media/jaumatell/datos/URI/RiMod/Data/rimod_ftd_dataset_table_v3.txt"
output_path <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMED_RESULTS/Rimod/C9/ArcSin/"
################################################################################

if (!file.exists(output_path)) {
  dir.create(output_path, recursive = TRUE)
}
if (!file.exists(file.path(output_path,"Significative"))) {
  dir.create(file.path(output_path,"Significative"), recursive = TRUE)
}

data <- read.delim(metadata_file, row.names = 1)
data$group.ID <- data$DiseaseCode
data$DiseaseCode <- NULL
data <- data[!data$group.ID == "FTD-GRN",]
data <- data[!data$group.ID == "FTD-MAPT",]
data$group.ID[data$group.ID == "control"] <- "Healthy"
data$group.ID[data$group.ID == "FTD-C9"] <- "C9orf72"
data$sample.ID <- rownames(data)

freq_cell_types <- read.csv(frequency_file)
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("long", "", x))
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("X", "", x))

merged_data <- merge(data, freq_cell_types, by.x = "sample.ID", by.y = "X")
merged_data[merged_data == 0] <- 1e-10

################################################################################
# Generate needed objects

m_conditions <- unique(merged_data$group.ID)
m_conditions_nh <- m_conditions[m_conditions != "Healthy"]
files_to_iterate <- colnames(merged_data)[4:length(colnames(merged_data))]
m_cond <- m_conditions_nh[1]
counter = 0

significatives <- data.frame(matrix(nrow = length(files_to_iterate), ncol = 3))
colnames(significatives)<- c("cell", "group+sv", "group")


for (column in colnames(freq_cell_types)[2:length(colnames(freq_cell_types))]){
  counter <- counter + 1
  filename <- paste0("Kruskal_", column, "_", m_cond, ".txt")
  
  subset_data <- merged_data[merged_data$group.ID %in% c("Healthy", m_cond), 
                             c("group.ID", column)]
  
  # Ensure group.ID is treated as a factor
  subset_data$group.ID <- factor(subset_data$group.ID, levels = c("Healthy", m_cond))
  
  # Calculate group means
  mean_healthy <- mean(subset_data[[column]][subset_data$group.ID == "Healthy"], na.rm = TRUE)
  mean_condition <- mean(subset_data[[column]][subset_data$group.ID == m_cond], na.rm = TRUE)
  
  # Calculate fold change
  fold_change <- ifelse(mean_healthy == 0, NA, mean_condition / mean_healthy)  # Avoid division by zero
  
  # Log-transform the fold change (optional)
  log2_fold_change <- ifelse(is.na(fold_change), NA, log2(fold_change))
  
  # Check if both groups (Healthy and m_cond) have at least 2 observations
  save = TRUE
  tryCatch({
    if (save == TRUE){sink(paste0(output_path, filename))}
    
    print(filename)
    
    # Model A: Kruskal-Wallis Test (without covariates)
    kruskal_A <- kruskal.test(subset_data[[column]], subset_data$group.ID)
    print("Kruskal-Wallis Test (General model)")
    print(kruskal_A)
    if (save == TRUE){sink()}
    
  }, error = function(e) {
    message("Error in processing column ", column, ": ", e$message)
    next
  })
  
  # Store the p-values, fold change, and means in the significatives data frame
  significatives[counter, 1] <- column
  significatives[counter, 3] <- kruskal_A$p.value  # Group (from Kruskal-Wallis test)
  significatives[counter, 4] <- fold_change  # Fold change
  significatives[counter, 5] <- log2_fold_change  # Log2 fold change
  significatives[counter, 6] <- mean_healthy  # Mean of the Healthy group
  significatives[counter, 7] <- mean_condition  # Mean of the specific condition group
}

# Update column names of the significatives data frame
colnames(significatives) <- c("cell", "group+sv", "group", "fold_change", 
                              "log2_fold_change", "mean_healthy", "mean_condition")

# Save the significatives data frame as a TSV file
tsv_output_path <- file.path(output_path, "significatives_nonparametric_with_means_cs.tsv")
write.table(significatives, 
            file = tsv_output_path, 
            sep = "\t",          
            row.names = FALSE,   
            col.names = TRUE,    
            quote = FALSE)
```

```{r code_3_cell_prop_differences_ftld_c9_cell_prop_differences_r, eval=FALSE}
library("ggplot2")
library("openxlsx")
library("dplyr")
library("coin")  

#################################T.TESTS########################################
# FILE PATHS
frequency_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/C9/theta.state_cellstate.csv"
metadata_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx"
output_path <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/FTLD/c9/"
################################################################################

if (!file.exists(output_path)) {
  dir.create(output_path, recursive = TRUE)
}
if (!file.exists(file.path(output_path,"Significative"))) {
  dir.create(file.path(output_path,"Significative"), recursive = TRUE)
}

data <- read.xlsx(metadata_file)

freq_cell_types <- read.csv(frequency_file)
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("long", "", x))
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("X", "", x))

merged_data <- merge(data, freq_cell_types, by.x = "sample.ID", by.y = "X")
merged_data[merged_data == 0] <- 1e-10

################################################################################
# Generate needed objects

m_conditions <- unique(merged_data$group.ID)
m_conditions_nh <- m_conditions[m_conditions != "Healthy"]
files_to_iterate <- colnames(merged_data)[4:length(colnames(merged_data))]
m_cond <- m_conditions_nh[1]
counter = 0

significatives <- data.frame(matrix(nrow = length(files_to_iterate), ncol = 3))
colnames(significatives)<- c("cell", "group+sv", "group")


for (column in colnames(freq_cell_types)[2:length(colnames(freq_cell_types))]){
  counter <- counter + 1
  filename <- paste0("Kruskal_", column, "_", m_cond, ".txt")
  
  subset_data <- merged_data[merged_data$group.ID %in% c("Healthy", m_cond), 
                             c("group.ID", column)]
  
  # Ensure group.ID is treated as a factor
  subset_data$group.ID <- factor(subset_data$group.ID, levels = c("Healthy", m_cond))
  
  # Calculate group means
  mean_healthy <- mean(subset_data[[column]][subset_data$group.ID == "Healthy"], na.rm = TRUE)
  mean_condition <- mean(subset_data[[column]][subset_data$group.ID == m_cond], na.rm = TRUE)
  
  # Calculate fold change
  fold_change <- ifelse(mean_healthy == 0, NA, mean_condition / mean_healthy)  # Avoid division by zero
  
  # Log-transform the fold change (optional)
  log2_fold_change <- ifelse(is.na(fold_change), NA, log2(fold_change))
  
  # Check if both groups (Healthy and m_cond) have at least 2 observations
  save = TRUE
  tryCatch({
    if (save == TRUE){sink(paste0(output_path, filename))}
    
    print(filename)
    
    # Model A: Kruskal-Wallis Test (without covariates)
    kruskal_A <- kruskal.test(subset_data[[column]], subset_data$group.ID)
    print("Kruskal-Wallis Test (General model)")
    print(kruskal_A)
    if (save == TRUE){sink()}
    
  }, error = function(e) {
    message("Error in processing column ", column, ": ", e$message)
    next
  })
  
  # Store the p-values, fold change, and means in the significatives data frame
  significatives[counter, 1] <- column
  significatives[counter, 3] <- kruskal_A$p.value  # Group (from Kruskal-Wallis test)
  significatives[counter, 4] <- fold_change  # Fold change
  significatives[counter, 5] <- log2_fold_change  # Log2 fold change
  significatives[counter, 6] <- mean_healthy  # Mean of the Healthy group
  significatives[counter, 7] <- mean_condition  # Mean of the specific condition group
}

# Update column names of the significatives data frame
colnames(significatives) <- c("cell", "group+sv", "group", "fold_change", 
                              "log2_fold_change", "mean_healthy", "mean_condition")

# Save the significatives data frame as a TSV file
tsv_output_path <- file.path(output_path, "significatives_nonparametric_with_means_cs.tsv")
write.table(significatives, 
            file = tsv_output_path, 
            sep = "\t",          
            row.names = FALSE,   
            col.names = TRUE,    
            quote = FALSE)
```

```{r code_3_cell_prop_differences_ftld_tdp_cell_prop_differences_r, eval=FALSE}
library("ggplot2")
library("openxlsx")
library("dplyr")
library("coin")  

#################################T.TESTS########################################
# FILE PATHS
frequency_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/TDP/theta.state_original.csv"
metadata_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx"
output_path <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/FTLD/TDP/"
################################################################################

if (!file.exists(output_path)) {
  dir.create(output_path, recursive = TRUE)
}
if (!file.exists(file.path(output_path,"Significative"))) {
  dir.create(file.path(output_path,"Significative"), recursive = TRUE)
}

data <- read.xlsx(metadata_file)

freq_cell_types <- read.csv(frequency_file)
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("long", "", x))
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("X", "", x))

merged_data <- merge(data, freq_cell_types, by.x = "sample.ID", by.y = "X")
merged_data[merged_data == 0] <- 1e-10

################################################################################
# Generate needed objects

m_conditions <- unique(merged_data$group.ID)
m_conditions_nh <- m_conditions[m_conditions != "Healthy"]
files_to_iterate <- colnames(merged_data)[4:length(colnames(merged_data))]
m_cond <- m_conditions_nh[1]
counter = 0

significatives <- data.frame(matrix(nrow = length(files_to_iterate), ncol = 3))
colnames(significatives)<- c("cell", "group+sv", "group")


for (column in colnames(freq_cell_types)[2:length(colnames(freq_cell_types))]){
  counter <- counter + 1
  filename <- paste0("Kruskal_", column, "_", m_cond, ".txt")
  
  subset_data <- merged_data[merged_data$group.ID %in% c("Healthy", m_cond), 
                             c("group.ID", column)]
  
  # Ensure group.ID is treated as a factor
  subset_data$group.ID <- factor(subset_data$group.ID, levels = c("Healthy", m_cond))
  
  # Calculate group means
  mean_healthy <- mean(subset_data[[column]][subset_data$group.ID == "Healthy"], na.rm = TRUE)
  mean_condition <- mean(subset_data[[column]][subset_data$group.ID == m_cond], na.rm = TRUE)
  
  # Calculate fold change
  fold_change <- ifelse(mean_healthy == 0, NA, mean_condition / mean_healthy)  # Avoid division by zero
  
  # Log-transform the fold change (optional)
  log2_fold_change <- ifelse(is.na(fold_change), NA, log2(fold_change))
  
  # Check if both groups (Healthy and m_cond) have at least 2 observations
  save = TRUE
  tryCatch({
    if (save == TRUE){sink(paste0(output_path, filename))}
    
    print(filename)
    
    # Model A: Kruskal-Wallis Test (without covariates)
    kruskal_A <- kruskal.test(subset_data[[column]], subset_data$group.ID)
    print("Kruskal-Wallis Test (General model)")
    print(kruskal_A)
    if (save == TRUE){sink()}
    
  }, error = function(e) {
    message("Error in processing column ", column, ": ", e$message)
    next
  })
  
  # Store the p-values, fold change, and means in the significatives data frame
  significatives[counter, 1] <- column
  significatives[counter, 3] <- kruskal_A$p.value  # Group (from Kruskal-Wallis test)
  significatives[counter, 4] <- fold_change  # Fold change
  significatives[counter, 5] <- log2_fold_change  # Log2 fold change
  significatives[counter, 6] <- mean_healthy  # Mean of the Healthy group
  significatives[counter, 7] <- mean_condition  # Mean of the specific condition group
}

# Update column names of the significatives data frame
colnames(significatives) <- c("cell", "group+sv", "group", "fold_change", 
                              "log2_fold_change", "mean_healthy", "mean_condition")

# Save the significatives data frame as a TSV file
tsv_output_path <- file.path(output_path, "significatives_nonparametric_with_means_cs.tsv")
write.table(significatives, 
            file = tsv_output_path, 
            sep = "\t",          
            row.names = FALSE,   
            col.names = TRUE,    
            quote = FALSE)
```

```{r code_3_cell_prop_differences_pottier_cell_prop_differences_r, eval=FALSE}
library("ggplot2")
library("openxlsx")
library("dplyr")
library("coin")  

#################################T.TESTS########################################
# FILE PATHS
frequency_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/NEW/theta.state_cellstate.csv"
metadata_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/NEW_BULK/METADATA/Sample_info.txt"
output_path <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/NEW/"
################################################################################

if (!file.exists(output_path)) {
  dir.create(output_path, recursive = TRUE)
}
if (!file.exists(file.path(output_path,"Significative"))) {
  dir.create(file.path(output_path,"Significative"), recursive = TRUE)
}

data <- read.delim(metadata_file)

freq_cell_types <- read.csv(frequency_file)
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("\\.", "_", x))
data$FCX_ID <- sapply(data$FCX_ID, function(x) gsub("-", "_", x))

merged_data <- merge(data, freq_cell_types, by.x = "FCX_ID", by.y = "X")
merged_data[merged_data == 0] <- 1e-10

merged_data <- merged_data[merged_data$GROUP != "FTLD-TDP-C",]
merged_data$GROUP[merged_data$GROUP != "Control"]<-"FTLD"
################################################################################
# Generate needed objects

m_conditions <- unique(merged_data$GROUP)
m_conditions_nh <- m_conditions[m_conditions != "Control"]
files_to_iterate <- colnames(merged_data)[4:length(colnames(merged_data))]
m_cond <- m_conditions_nh[1]
counter = 0

significatives <- data.frame(matrix(nrow = length(files_to_iterate), ncol = 3))
colnames(significatives)<- c("cell", "group+sv", "group")


for (column in colnames(freq_cell_types)[2:length(colnames(freq_cell_types))]){
  counter <- counter + 1
  filename <- paste0("Kruskal_", column, "_", m_cond, ".txt")
  
  subset_data <- merged_data[merged_data$GROUP %in% c("Control", m_cond), 
                             c("GROUP", column)]
  
  # Ensure group.ID is treated as a factor
  subset_data$group.ID <- factor(subset_data$GROUP, levels = c("Control", m_cond))
  
  # Calculate group means
  mean_healthy <- mean(subset_data[[column]][subset_data$GROUP == "Control"], na.rm = TRUE)
  mean_condition <- mean(subset_data[[column]][subset_data$GROUP == m_cond], na.rm = TRUE)
  
  # Calculate fold change
  fold_change <- ifelse(mean_healthy == 0, NA, mean_condition / mean_healthy)  # Avoid division by zero
  
  # Log-transform the fold change (optional)
  log2_fold_change <- ifelse(is.na(fold_change), NA, log2(fold_change))
  
  # Check if both groups (Healthy and m_cond) have at least 2 observations
  save = TRUE
  tryCatch({
    if (save == TRUE){sink(paste0(output_path, filename))}
    
    print(filename)
    
    # Model A: Kruskal-Wallis Test (without covariates)
    kruskal_A <- kruskal.test(subset_data[[column]], subset_data$GROUP)
    print("Kruskal-Wallis Test (General model)")
    print(kruskal_A)
    if (save == TRUE){sink()}
    
  }, error = function(e) {
    message("Error in processing column ", column, ": ", e$message)
    next
  })
  
  # Store the p-values, fold change, and means in the significatives data frame
  significatives[counter, 1] <- column
  significatives[counter, 3] <- kruskal_A$p.value  # Group (from Kruskal-Wallis test)
  significatives[counter, 4] <- fold_change  # Fold change
  significatives[counter, 5] <- log2_fold_change  # Log2 fold change
  significatives[counter, 6] <- mean_healthy  # Mean of the Healthy group
  significatives[counter, 7] <- mean_condition  # Mean of the specific condition group
}

# Update column names of the significatives data frame
colnames(significatives) <- c("cell", "group+sv", "group", "fold_change", 
                              "log2_fold_change", "mean_healthy", "mean_condition")

# Save the significatives data frame as a TSV file
tsv_output_path <- file.path(output_path, "significatives_nonparametric_with_means_cs.tsv")
write.table(significatives, 
            file = tsv_output_path, 
            sep = "\t",          
            row.names = FALSE,   
            col.names = TRUE,    
            quote = FALSE)
```

```{r code_3_cell_prop_differences_rimod_cell_prop_differences_r, eval=FALSE}
library("ggplot2")
library("openxlsx")
library("dplyr")
library("coin")  

#################################T.TESTS########################################
# FILE PATHS
frequency_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/RIMOD/theta.state_cellstate.csv"
metadata_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/RIMOD_BULK/DATA/rimod_ftd_dataset_table_v3.txt"
output_path <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/Rimod/"
################################################################################

if (!file.exists(output_path)) {
  dir.create(output_path, recursive = TRUE)
}
if (!file.exists(file.path(output_path,"Significative"))) {
  dir.create(file.path(output_path,"Significative"), recursive = TRUE)
}

data <- read.delim(metadata_file)

freq_cell_types <- read.csv(frequency_file)

merged_data <- merge(data, freq_cell_types, by.x = "RimodID", by.y = "X")
merged_data[merged_data == 0] <- 1e-10

################################################################################
# Generate needed objects

m_conditions <- unique(merged_data$DiseaseCode)
m_conditions_nh <- m_conditions[m_conditions != "control"]
files_to_iterate <- colnames(merged_data)[4:length(colnames(merged_data))]
m_cond <- m_conditions_nh[1]
counter = 0

significatives <- data.frame(matrix(nrow = length(files_to_iterate), ncol = 3))
colnames(significatives)<- c("cell", "group+sv", "group")


for (column in colnames(freq_cell_types)[2:length(colnames(freq_cell_types))]){
  counter <- counter + 1
  filename <- paste0("Kruskal_", column, "_", m_cond, ".txt")
  
  subset_data <- merged_data[merged_data$DiseaseCode %in% c("control", m_cond), 
                             c("DiseaseCode", column)]
  
  # Ensure DiseaseCode is treated as a factor
  subset_data$DiseaseCode <- factor(subset_data$DiseaseCode, levels = c("control", m_cond))
  
  # Calculate group means
  mean_healthy <- mean(subset_data[[column]][subset_data$DiseaseCode == "control"], na.rm = TRUE)
  mean_condition <- mean(subset_data[[column]][subset_data$DiseaseCode == m_cond], na.rm = TRUE)
  
  # Calculate fold change
  fold_change <- ifelse(mean_healthy == 0, NA, mean_condition / mean_healthy)  # Avoid division by zero
  
  # Log-transform the fold change (optional)
  log2_fold_change <- ifelse(is.na(fold_change), NA, log2(fold_change))
  
  # Check if both groups (Healthy and m_cond) have at least 2 observations
  save = TRUE
  tryCatch({
    if (save == TRUE){sink(paste0(output_path, filename))}
    
    print(filename)
    
    # Model A: Kruskal-Wallis Test (without covariates)
    kruskal_A <- kruskal.test(subset_data[[column]], subset_data$DiseaseCode)
    print("Kruskal-Wallis Test (General model)")
    print(kruskal_A)
    if (save == TRUE){sink()}
    
  }, error = function(e) {
    message("Error in processing column ", column, ": ", e$message)
    next
  })
  
  # Store the p-values, fold change, and means in the significatives data frame
  significatives[counter, 1] <- column
  significatives[counter, 3] <- kruskal_A$p.value  # Group (from Kruskal-Wallis test)
  significatives[counter, 4] <- fold_change  # Fold change
  significatives[counter, 5] <- log2_fold_change  # Log2 fold change
  significatives[counter, 6] <- mean_healthy  # Mean of the Healthy group
  significatives[counter, 7] <- mean_condition  # Mean of the specific condition group
}

# Update column names of the significatives data frame
colnames(significatives) <- c("cell", "group+sv", "group", "fold_change", 
                              "log2_fold_change", "mean_healthy", "mean_condition")

# Save the significatives data frame as a TSV file
tsv_output_path <- file.path(output_path, "significatives_nonparametric_with_means_cs.tsv")
write.table(significatives, 
            file = tsv_output_path, 
            sep = "\t",          
            row.names = FALSE,   
            col.names = TRUE,    
            quote = FALSE)
```

```{r code_3_cell_prop_differences_tdp_cell_prop_differences_r, eval=FALSE}
library("ggplot2")
library("openxlsx")
library("dplyr")
library("coin")  

#################################T.TESTS########################################
# FILE PATHS
frequency_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/TDP/theta.state_original.csv"
metadata_file <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx"
output_path <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/FTLD/TDP/"
################################################################################

if (!file.exists(output_path)) {
  dir.create(output_path, recursive = TRUE)
}
if (!file.exists(file.path(output_path,"Significative"))) {
  dir.create(file.path(output_path,"Significative"), recursive = TRUE)
}

data <- read.xlsx(metadata_file)

freq_cell_types <- read.csv(frequency_file)
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("long", "", x))
freq_cell_types$X <- sapply(freq_cell_types$X, function(x) gsub("X", "", x))

merged_data <- merge(data, freq_cell_types, by.x = "sample.ID", by.y = "X")
merged_data[merged_data == 0] <- 1e-10

################################################################################
# Generate needed objects

m_conditions <- unique(merged_data$group.ID)
m_conditions_nh <- m_conditions[m_conditions != "Healthy"]
files_to_iterate <- colnames(merged_data)[4:length(colnames(merged_data))]
m_cond <- m_conditions_nh[1]
counter = 0

significatives <- data.frame(matrix(nrow = length(files_to_iterate), ncol = 3))
colnames(significatives)<- c("cell", "group+sv", "group")


for (column in colnames(freq_cell_types)[2:length(colnames(freq_cell_types))]){
  counter <- counter + 1
  filename <- paste0("Kruskal_", column, "_", m_cond, ".txt")
  
  subset_data <- merged_data[merged_data$group.ID %in% c("Healthy", m_cond), 
                             c("group.ID", column)]
  
  # Ensure group.ID is treated as a factor
  subset_data$group.ID <- factor(subset_data$group.ID, levels = c("Healthy", m_cond))
  
  # Calculate group means
  mean_healthy <- mean(subset_data[[column]][subset_data$group.ID == "Healthy"], na.rm = TRUE)
  mean_condition <- mean(subset_data[[column]][subset_data$group.ID == m_cond], na.rm = TRUE)
  
  # Calculate fold change
  fold_change <- ifelse(mean_healthy == 0, NA, mean_condition / mean_healthy)  # Avoid division by zero
  
  # Log-transform the fold change (optional)
  log2_fold_change <- ifelse(is.na(fold_change), NA, log2(fold_change))
  
  # Check if both groups (Healthy and m_cond) have at least 2 observations
  save = TRUE
  tryCatch({
    if (save == TRUE){sink(paste0(output_path, filename))}
    
    print(filename)
    
    # Model A: Kruskal-Wallis Test (without covariates)
    kruskal_A <- kruskal.test(subset_data[[column]], subset_data$group.ID)
    print("Kruskal-Wallis Test (General model)")
    print(kruskal_A)
    if (save == TRUE){sink()}
    
  }, error = function(e) {
    message("Error in processing column ", column, ": ", e$message)
    next
  })
  
  # Store the p-values, fold change, and means in the significatives data frame
  significatives[counter, 1] <- column
  significatives[counter, 3] <- kruskal_A$p.value  # Group (from Kruskal-Wallis test)
  significatives[counter, 4] <- fold_change  # Fold change
  significatives[counter, 5] <- log2_fold_change  # Log2 fold change
  significatives[counter, 6] <- mean_healthy  # Mean of the Healthy group
  significatives[counter, 7] <- mean_condition  # Mean of the specific condition group
}

# Update column names of the significatives data frame
colnames(significatives) <- c("cell", "group+sv", "group", "fold_change", 
                              "log2_fold_change", "mean_healthy", "mean_condition")

# Save the significatives data frame as a TSV file
tsv_output_path <- file.path(output_path, "significatives_nonparametric_with_means_cs.tsv")
write.table(significatives, 
            file = tsv_output_path, 
            sep = "\t",          
            row.names = FALSE,   
            col.names = TRUE,    
            quote = FALSE)

library(ggplot2)
library(dplyr)

# Seleccionem només els tipus cel·lulars que t’interessen
cell_types_to_plot <- c("GFAP.pos", "PVALB_PTHLH", "LAMP5_PMEPA1", "PVALB_CEMIP")

plot_data <- merged_data %>%
  select(sample.ID, group.ID, all_of(cell_types_to_plot)) %>%
  tidyr::pivot_longer(cols = all_of(cell_types_to_plot),
                      names_to = "CellType",
                      values_to = "Proportion")

# Creem el boxplot amb facet_wrap
p <- ggplot(plot_data, aes(x = group.ID, y = Proportion, fill = group.ID)) +
  geom_boxplot(alpha = 0.6, outlier.shape = NA) +
  geom_jitter(width = 0.2, alpha = 0.7, size = 2) +
  facet_wrap(~CellType, scales = "free_y", ncol = 2) +   # 2 columnes, 4 plots
  theme_minimal(base_size = 14) +
  scale_fill_brewer(palette = "Set2") +
  ylab("Cell proportion") +
  xlab("") +
  theme(legend.position = "none",
        strip.text = element_text(size = 14, face = "bold"))

# Mostrar
print(p)

# Opcional: guardar com a PDF/PNG
ggsave(file.path(output_path, "Boxplots_selected_celltypes.pdf"), p,
       width = 10, height = 8)
```

```{r fig_3_cell_prop_differences_1, echo=FALSE, eval=FALSE}
# knitr::include_graphics("figures/fig_3_cell_prop_differences_1.png")
```

```{r fig_3_cell_prop_differences_2, echo=FALSE, eval=FALSE}
# knitr::include_graphics("figures/fig_3_cell_prop_differences_2.png")
```

## 4. CELL PROP CORRELATIONS

Correlate cell-type proportions (raw and transformed) with clinical and pathological variables for FTLD cohorts.

Scripts included in this step:

-   `4. CELL PROP CORRELATIONS/4. C9 CELL PROP CORRELATIONS.R`
-   `4. CELL PROP CORRELATIONS/4. CELL PROP TRANSFORMED CORRELATIONS.R`
-   `4. CELL PROP CORRELATIONS/4. TDP CELL PROP CORRELATIONS.R`

```{r code_4_cell_prop_correlations_4_c9_cell_prop_correlations_r, eval=FALSE}

library("Seurat")
library("dplyr")
library("RColorBrewer")
library("unikn")
library("cluster")
library("tidyverse")
library("readxl")  # Asegurar que readxl está cargado

# Load Metadata
metadata <- read_xlsx("/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx")
colnames(metadata)[1] <- "X"
samples <- metadata$X[metadata$group.ID == "C9orf72"]
metadata <- metadata[metadata$group.ID == "C9orf72",]

CRscores <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/FTD_C9_neuropath_SOM.csv")
CRscores$X <- gsub(pattern = "X", replacement = "", x = CRscores$X)
CRscores <- CRscores[CRscores$X %in% samples,]

proportions_directory <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/C9/theta.state_cellstate.csv"
proportions_data <- read.csv(proportions_directory, row.names = 1)
rownames(proportions_data) <- gsub("^X", "", rownames(proportions_data))

################################################################################
common_samples <- intersect(rownames(proportions_data), CRscores$X)
proportions_data <- proportions_data[common_samples, , drop = FALSE]
covariables <- CRscores %>% filter(X %in% common_samples) %>% column_to_rownames("X")

if (nrow(proportions_data) > 2 && nrow(covariables) > 2) {
  
  results <- expand.grid(Cell_State = colnames(proportions_data), 
                         Covariate = colnames(covariables), 
                         stringsAsFactors = FALSE)
  
  compute_spearman <- function(cell_state, covariate) {
    test_result <- cor.test(proportions_data[, cell_state], covariables[, covariate], 
                            method = "spearman", exact = TRUE)
    return(c(test_result$estimate, test_result$p.value))
  }
  
  cor_pvals <- mapply(compute_spearman, results$Cell_State, results$Covariate)
  
  results$Spearman_Correlation <- cor_pvals[1, ]
  results$p_value <- cor_pvals[2, ]
}

write.csv(results, "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/C9_spearman_results_true.csv", row.names = FALSE)
```

```{r code_4_cell_prop_correlations_4_cell_prop_transformed_correlations_r, eval=FALSE}
library("Seurat")
library("dplyr")
library("RColorBrewer")
library("unikn")
library("cluster")
library("tidyverse")
library("readxl")  
library("car")

# Function to calculate correlation
compute_spearman <- function(cell_state, covariate, props, covars) {
  test_result <- cor.test(props[, cell_state], covars[, covariate],
                          method = "spearman", exact = TRUE)
  return(data.frame(Cell_State = cell_state,
                    Covariate = covariate,
                    Spearman_Correlation = test_result$estimate,
                    p_value = test_result$p.value))
}


# Load Metadata
metadata <- read_xlsx("/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx")
colnames(metadata)[1] <- "X"
samples <- metadata$X[metadata$group.ID == "TDP"]
metadata <- metadata[metadata$group.ID == "TDP",]

# LOG
outdir <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/TRANSFORMED_CELL_PROPORTION_CORRELATIONS/"

CRscores <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/TRANSFORMED_COVARIABLES/Log/TDP/Log_FTD_TDP_neuropath_SOM.csv")
CRscores$X <- gsub(pattern = "long", replacement = "", x = CRscores$X)
CRscores <- CRscores[CRscores$X %in% samples,]

proportions_directory <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMATED_PROPORTIONS/Log/FTLD/TDP/Log_Cell_state_proportions.csv"
proportions_data <- read.csv(proportions_directory, row.names = 1)
rownames(proportions_data) <- gsub("^X", "", rownames(proportions_data))

################################################################################
common_samples <- intersect(rownames(proportions_data), CRscores$X)
proportions_data <- proportions_data[common_samples, , drop = FALSE]
covariables <- CRscores %>% dplyr::filter(X %in% common_samples) %>% column_to_rownames("X")

# Separate STMN2 to remove outlier
cov_stmn2 <- covariables[rownames(covariables) != "7BLACK", "STMN2", drop = FALSE]
proportions_data_STMN2 <- proportions_data[rownames(proportions_data) != "7BLACK", ]


cov_tdp43b <- covariables[, "TDP43b", drop = FALSE]

# Results dataframe 
results <- expand.grid(Cell_State = colnames(proportions_data), 
                       Covariate = colnames(covariables), 
                       stringsAsFactors = FALSE)

# --- Correlations with TDP43b ---
res_tdp43b <- do.call(rbind, lapply(colnames(proportions_data), function(cs) {
  compute_spearman(cs, "TDP43b", proportions_data, cov_tdp43b)
}))


# --- Correlations with STMN2 (without outlier) ---
res_stmn2 <- do.call(rbind, lapply(colnames(proportions_data_STMN2), function(cs) {
  compute_spearman(cs, "STMN2", proportions_data_STMN2, cov_stmn2)
}))

# Combine results
results <- rbind(res_tdp43b, res_stmn2)

write.csv(results, paste0(outdir, "Log_TDP_spearman_results.csv"), row.names = FALSE)


# LOG2

CRscores <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/TRANSFORMED_COVARIABLES/Log2/TDP/Log2_FTD_TDP_neuropath_SOM")
CRscores$X <- gsub(pattern = "long", replacement = "", x = CRscores$X)
CRscores <- CRscores[CRscores$X %in% samples,]

proportions_directory <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMATED_PROPORTIONS/Log2/FTLD/TDP/Log2_Cell_state_proportions.csv"
proportions_data <- read.csv(proportions_directory, row.names = 1)
rownames(proportions_data) <- gsub("^X", "", rownames(proportions_data))

################################################################################
common_samples <- intersect(rownames(proportions_data), CRscores$X)
proportions_data <- proportions_data[common_samples, , drop = FALSE]
covariables <- CRscores %>% dplyr::filter(X %in% common_samples) %>% column_to_rownames("X")

# ULL AMB AQUEST CANVI DE VALOR
y <- covariables[, "STMN2"]
y[is.infinite(y)] <- min(y[is.finite(y)]) - 1e-2
covariables[, "STMN2"] <- y

# Separate STMN2 to remove outlier
cov_stmn2 <- covariables[rownames(covariables) != "7BLACK", "STMN2", drop = FALSE]
proportions_data_STMN2 <- proportions_data[rownames(proportions_data) != "7BLACK", ]


cov_tdp43b <- covariables[, "TDP43b", drop = FALSE]

# Results dataframe 
results <- expand.grid(Cell_State = colnames(proportions_data), 
                       Covariate = colnames(covariables), 
                       stringsAsFactors = FALSE)

# --- Correlations with TDP43b ---
res_tdp43b <- do.call(rbind, lapply(colnames(proportions_data), function(cs) {
  compute_spearman(cs, "TDP43b", proportions_data, cov_tdp43b)
}))


# --- Correlations with STMN2 (without outlier) ---
res_stmn2 <- do.call(rbind, lapply(colnames(proportions_data_STMN2), function(cs) {
  compute_spearman(cs, "STMN2", proportions_data_STMN2, cov_stmn2)
}))

# Combine results
results <- rbind(res_tdp43b, res_stmn2)

write.csv(results, paste0(outdir, "Log2_TDP_spearman_results.csv"), row.names = FALSE)


# LOGIT

CRscores <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/TRANSFORMED_COVARIABLES/Logit/TDP/Logit_FTD_TDP_neuropath_SOM.csv")
CRscores$X <- gsub(pattern = "long", replacement = "", x = CRscores$X)
CRscores <- CRscores[CRscores$X %in% samples,]

proportions_directory <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMATED_PROPORTIONS/Logit/FTLD/TDP/Logit_Cell_state_proportions.csv"
proportions_data <- read.csv(proportions_directory, row.names = 1)
rownames(proportions_data) <- gsub("^X", "", rownames(proportions_data))

################################################################################
common_samples <- intersect(rownames(proportions_data), CRscores$X)
proportions_data <- proportions_data[common_samples, , drop = FALSE]
covariables <- CRscores %>% dplyr::filter(X %in% common_samples) %>% column_to_rownames("X")

# ULL AMB AQUEST CANVI DE VALOR
y <- covariables[, "STMN2"]
y[is.infinite(y)] <- min(y[is.finite(y)]) - 1e-2
covariables[, "STMN2"] <- y

# Separate STMN2 to remove outlier
cov_stmn2 <- covariables[rownames(covariables) != "7BLACK", "STMN2", drop = FALSE]
proportions_data_STMN2 <- proportions_data[rownames(proportions_data) != "7BLACK", ]


cov_tdp43b <- covariables[, "TDP43b", drop = FALSE]

# Results dataframe 
results <- expand.grid(Cell_State = colnames(proportions_data), 
                       Covariate = colnames(covariables), 
                       stringsAsFactors = FALSE)

# --- Correlations with TDP43b ---
res_tdp43b <- do.call(rbind, lapply(colnames(proportions_data), function(cs) {
  compute_spearman(cs, "TDP43b", proportions_data, cov_tdp43b)
}))


# --- Correlations with STMN2 (without outlier) ---
res_stmn2 <- do.call(rbind, lapply(colnames(proportions_data_STMN2), function(cs) {
  compute_spearman(cs, "STMN2", proportions_data_STMN2, cov_stmn2)
}))

# Combine results
results <- rbind(res_tdp43b, res_stmn2)


write.csv(results, paste0(outdir, "Logit_TDP_spearman_results.csv"), row.names = FALSE)



# ARCSIN

CRscores <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/TRANSFORMED_COVARIABLES/ArcSin/TDP/ArcSin_FTD_TDP_neuropath_SOM")
CRscores$X <- gsub(pattern = "long", replacement = "", x = CRscores$X)
CRscores <- CRscores[CRscores$X %in% samples,]

proportions_directory <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMATED_PROPORTIONS/ArcSin/FTLD/TDP/Arcsin_Cell_state_proportions.csv"
proportions_data <- read.csv(proportions_directory, row.names = 1)
rownames(proportions_data) <- gsub("^X", "", rownames(proportions_data))

################################################################################
common_samples <- intersect(rownames(proportions_data), CRscores$X)
proportions_data <- proportions_data[common_samples, , drop = FALSE]
covariables <- CRscores %>% dplyr::filter(X %in% common_samples) %>% column_to_rownames("X")

# ULL AMB AQUEST CANVI DE VALOR
y <- covariables[, "STMN2"]
y[is.infinite(y)] <- min(y[is.finite(y)]) - 1e-2
covariables[, "STMN2"] <- y

# Separate STMN2 to remove outlier
cov_stmn2 <- covariables[rownames(covariables) != "7BLACK", "STMN2", drop = FALSE]
proportions_data_STMN2 <- proportions_data[rownames(proportions_data) != "7BLACK", ]


cov_tdp43b <- covariables[, "TDP43b", drop = FALSE]

# Results dataframe 
results <- expand.grid(Cell_State = colnames(proportions_data), 
                       Covariate = colnames(covariables), 
                       stringsAsFactors = FALSE)

# --- Correlations with TDP43b ---
res_tdp43b <- do.call(rbind, lapply(colnames(proportions_data), function(cs) {
  compute_spearman(cs, "TDP43b", proportions_data, cov_tdp43b)
}))


# --- Correlations with STMN2 (without outlier) ---
res_stmn2 <- do.call(rbind, lapply(colnames(proportions_data_STMN2), function(cs) {
  compute_spearman(cs, "STMN2", proportions_data_STMN2, cov_stmn2)
}))

# Combine results
results <- rbind(res_tdp43b, res_stmn2)

write.csv(results, paste0(outdir, "ArcSin_TDP_spearman_results.csv"), row.names = FALSE)



# C9


library("Seurat")
library("dplyr")
library("RColorBrewer")
library("unikn")
library("cluster")
library("tidyverse")
library("readxl")  # Asegurar que readxl está cargado

# Load Metadata
metadata <- read_xlsx("/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx")
colnames(metadata)[1] <- "X"
samples <- metadata$X[metadata$group.ID == "C9orf72"]
metadata <- metadata[metadata$group.ID == "C9orf72",]

# LOG
outdir <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/TRANSFORMED_CELL_PROPORTION_CORRELATIONS/"

CRscores <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/TRANSFORMED_COVARIABLES/Log/C9/Log_FTD_C9_neuropath_SOM.csv", row.names = "X")
rownames(CRscores) <- gsub(pattern = "X", replacement = "", x = rownames(CRscores))
CRscores <- CRscores[rownames(CRscores) %in% samples,]

proportions_directory <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMATED_PROPORTIONS/Log/FTLD/C9/Log_Cell_state_proportions.csv"
proportions_data <- read.csv(proportions_directory, row.names = 1)
rownames(proportions_data) <- gsub("^X", "", rownames(proportions_data))

################################################################################
common_samples <- intersect(rownames(proportions_data), rownames(CRscores))
proportions_data <- proportions_data[common_samples, , drop = FALSE]
covariables <- CRscores %>% dplyr::filter(rownames(CRscores) %in% common_samples) 


if (nrow(proportions_data) > 2 && nrow(covariables) > 2) {
  
  results <- expand.grid(Cell_State = colnames(proportions_data), 
                         Covariate = colnames(covariables), 
                         stringsAsFactors = FALSE)
  
  compute_spearman <- function(cell_state, covariate) {
    test_result <- cor.test(proportions_data[, cell_state], covariables[, covariate], 
                            method = "spearman", exact = TRUE) 
    return(c(test_result$estimate, test_result$p.value))
  }
  
  cor_pvals <- apply(results, 1, function(row) {
    compute_spearman(row["Cell_State"], row["Covariate"])
  })
  
  results$Spearman_Correlation <- cor_pvals[1, ]
  results$p_value <- cor_pvals[2, ]
}
write.csv(results, paste0(outdir, "Log_C9_spearman_results.csv"), row.names = FALSE)


# LOG2

CRscores <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/TRANSFORMED_COVARIABLES/Log2/C9/Log2_FTD_C9_neuropath_SOM.csv", row.names = "X")
rownames(CRscores) <- gsub(pattern = "X", replacement = "", x = rownames(CRscores))
CRscores <- CRscores[rownames(CRscores) %in% samples,]

proportions_directory <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMATED_PROPORTIONS/Log2/FTLD/C9/Log2_Cell_state_proportions.csv"
proportions_data <- read.csv(proportions_directory, row.names = 1)
rownames(proportions_data) <- gsub("^X", "", rownames(proportions_data))

################################################################################
common_samples <- intersect(rownames(proportions_data), rownames(CRscores))
proportions_data <- proportions_data[common_samples, , drop = FALSE]
covariables <- CRscores %>% dplyr::filter(rownames(CRscores) %in% common_samples) 
if (nrow(proportions_data) > 2 && nrow(covariables) > 2) {
  
  results <- expand.grid(Cell_State = colnames(proportions_data), 
                         Covariate = colnames(covariables), 
                         stringsAsFactors = FALSE)
  
  compute_spearman <- function(cell_state, covariate) {
    test_result <- cor.test(proportions_data[, cell_state], covariables[, covariate], 
                            method = "spearman", exact = TRUE) 
    return(c(test_result$estimate, test_result$p.value))
  }
  
  cor_pvals <- apply(results, 1, function(row) {
    compute_spearman(row["Cell_State"], row["Covariate"])
  })
  
  results$Spearman_Correlation <- cor_pvals[1, ]
  results$p_value <- cor_pvals[2, ]
}

write.csv(results, paste0(outdir, "Log2_C9_spearman_results.csv"), row.names = FALSE)


# LOGIT

CRscores <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/TRANSFORMED_COVARIABLES/Logit/C9/Logit_FTD_C9_neuropath_SOM.csv", row.names = "X")
rownames(CRscores) <- gsub(pattern = "X", replacement = "", x = rownames(CRscores))
CRscores <- CRscores[rownames(CRscores) %in% samples,]

proportions_directory <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMATED_PROPORTIONS/Logit/FTLD/C9/Logit_Cell_state_proportions.csv"
proportions_data <- read.csv(proportions_directory, row.names = 1)
rownames(proportions_data) <- gsub("^X", "", rownames(proportions_data))

################################################################################
common_samples <- intersect(rownames(proportions_data), rownames(CRscores))
proportions_data <- proportions_data[common_samples, , drop = FALSE]
covariables <- CRscores %>% dplyr::filter(rownames(CRscores) %in% common_samples) 
if (nrow(proportions_data) > 2 && nrow(covariables) > 2) {
  
  results <- expand.grid(Cell_State = colnames(proportions_data), 
                         Covariate = colnames(covariables), 
                         stringsAsFactors = FALSE)
  
  compute_spearman <- function(cell_state, covariate) {
    test_result <- cor.test(proportions_data[, cell_state], covariables[, covariate], 
                            method = "spearman", exact = TRUE) 
    return(c(test_result$estimate, test_result$p.value))
  }
  
  cor_pvals <- apply(results, 1, function(row) {
    compute_spearman(row["Cell_State"], row["Covariate"])
  })
  
  results$Spearman_Correlation <- cor_pvals[1, ]
  results$p_value <- cor_pvals[2, ]
}
write.csv(results, paste0(outdir, "Logit_C9_spearman_results.csv"), row.names = FALSE)



# ARCSIN

CRscores <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/TRANSFORMED_COVARIABLES/ArcSin/C9/ArcSin_FTD_C9_neuropath_SOM.csv", row.names = "X")
rownames(CRscores) <- gsub(pattern = "X", replacement = "", x = rownames(CRscores))
CRscores <- CRscores[rownames(CRscores) %in% samples,]

proportions_directory <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/TRANSFORMATED_PROPORTIONS/ArcSin/FTLD/C9/Arcsin_Cell_state_proportions.csv"
proportions_data <- read.csv(proportions_directory, row.names = 1)
rownames(proportions_data) <- gsub("^X", "", rownames(proportions_data))

################################################################################
common_samples <- intersect(rownames(proportions_data), rownames(CRscores))
proportions_data <- proportions_data[common_samples, , drop = FALSE]
covariables <- CRscores %>% dplyr::filter(rownames(CRscores) %in% common_samples) 
if (nrow(proportions_data) > 2 && nrow(covariables) > 2) {
  
  results <- expand.grid(Cell_State = colnames(proportions_data), 
                         Covariate = colnames(covariables), 
                         stringsAsFactors = FALSE)
  
  compute_spearman <- function(cell_state, covariate) {
    test_result <- cor.test(proportions_data[, cell_state], covariables[, covariate], 
                            method = "spearman", exact = TRUE) 
    return(c(test_result$estimate, test_result$p.value))
  }
  
  cor_pvals <- apply(results, 1, function(row) {
    compute_spearman(row["Cell_State"], row["Covariate"])
  })
  
  results$Spearman_Correlation <- cor_pvals[1, ]
  results$p_value <- cor_pvals[2, ]
}

write.csv(results, paste0(outdir, "ArcSin_C9_spearman_results.csv"), row.names = FALSE)
```

```{r code_4_cell_prop_correlations_4_tdp_cell_prop_correlations_r, eval=FALSE}
library("Seurat")
library("dplyr")
library("RColorBrewer")
library("unikn")
library("cluster")
library("tidyverse")
library("readxl")  # Asegurar que readxl está cargado

# Load Metadata
metadata <- read_xlsx("/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx")
colnames(metadata)[1] <- "X"
samples <- metadata$X[metadata$group.ID == "TDP"]
metadata <- metadata[metadata$group.ID == "TDP",]

CRscores <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/FTD_TDP_neuropath_SOM.csv")
CRscores$X <- gsub(pattern = "long", replacement = "", x = CRscores$X)
CRscores <- CRscores[CRscores$X %in% samples,]

proportions_directory <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/TDP/theta.state_original.csv"
proportions_data <- read.csv(proportions_directory, row.names = 1)
rownames(proportions_data) <- gsub("^X", "", rownames(proportions_data))

################################################################################
common_samples <- intersect(rownames(proportions_data), CRscores$X)
common_samples <- setdiff(common_samples, "7BLACK")  # Remove outlier 
proportions_data <- proportions_data[common_samples, , drop = FALSE]
covariables <- CRscores %>% dplyr::filter(X %in% common_samples) %>% column_to_rownames("X")

if (nrow(proportions_data) > 2 && nrow(covariables) > 2) {
  
  results <- expand.grid(Cell_State = colnames(proportions_data), 
                         Covariate = colnames(covariables), 
                         stringsAsFactors = FALSE)
  
  compute_spearman <- function(cell_state, covariate) {
    test_result <- cor.test(proportions_data[, cell_state], covariables[, covariate], 
                            method = "spearman", exact = TRUE) # TRUE 
    return(c(test_result$estimate, test_result$p.value))
  }
  
  cor_pvals <- mapply(compute_spearman, results$Cell_State, results$Covariate)
  
  results$Spearman_Correlation <- cor_pvals[1, ]
  results$p_value <- cor_pvals[2, ]
}

write.csv(results, "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/TDP_spearman_results_true_no_out.csv", row.names = FALSE)
```

```{r fig_4_cell_prop_correlations_1, echo=FALSE, eval=FALSE}
# knitr::include_graphics("figures/fig_4_cell_prop_correlations_1.png")
```

```{r fig_4_cell_prop_correlations_2, echo=FALSE, eval=FALSE}
# knitr::include_graphics("figures/fig_4_cell_prop_correlations_2.png")
```

## 5. CELL TYPE DEA

Detect differential expression within single-cell-derived cell-type profiles using edgeR-based workflows across cohorts.

Scripts included in this step:

-   `5. CELL TYPE DEA/5. DEA_FTLD-C9.R`
-   `5. CELL TYPE DEA/5. DEA_FTLD-TDP.R`
-   `5. CELL TYPE DEA/5. DEA_Rimmod.R`
-   `5. CELL TYPE DEA/5.EDGER_SV_Pottier.R`
-   `5. CELL TYPE DEA/5.Extract_pvals_for_genes_uri.R`

```{r code_5_cell_type_dea_5_dea_ftld_c9_r, eval=FALSE}
library("edgeR")
library("dplyr")
library("GO.db")

# c9
#CT
CSV_DECONVOLDED_PATH <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/C9/CELL STATE ORIGINAL"
CASE_LEGEND <- "/media/jaumatell/datos/URI/BayesPrism/FTD/DATASETS/FTD_QUIM/decoder_DeSeq2_FTD_FINAL.xlsx"
#SV_COVARIATE <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/SURROGATED_VARIABLES/groupsTAU_sv1_sv2_QUIM.csv"
SV_COVARIATE <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/SURROGATED_VARIABLES/SV1_C9_HC_QUIM.csv"
OUTPUT_DIRECTORY <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/EDGER/FTLD/C9/CS_SV"

REFERENCE_GROUP <- "Healthy"

covariate_data <- read.csv(SV_COVARIATE)
#covariate_data <- read.delim(SV_COVARIATE, col.names = c("sample.ID", "X" ,"SV1", "SV2"))
covariate_data$sample.ID <- sub("^long", "", covariate_data$sample.ID)


csv_files <- list.files(CSV_DECONVOLDED_PATH, pattern = "\\.csv$", full.names = TRUE)

if (endsWith(CASE_LEGEND, ".csv")) {
  case_legend <- read.csv(CASE_LEGEND)
  case_legend$group_ID <- as.factor(case_legend$group.ID)
  case_legend$group.ID <- NULL
} else if (endsWith(CASE_LEGEND, ".xlsx")) {
  case_legend <- readxl::read_xlsx(CASE_LEGEND)
  case_legend$group_ID <- as.factor(case_legend$group.ID)
  case_legend$group2_ID <- as.factor(case_legend$group2.ID)
  case_legend$group2.ID <- NULL
  case_legend$group.ID <- NULL
} else {
  # Handle other cases or file types
  print("File type not recognized.")
}

case_legend$group2_ID <- droplevels(case_legend$group2_ID)
case_legend$group_ID <- as.character(case_legend$group_ID)
case_legend$group_ID <- as.factor(case_legend$group_ID)
case_legend$group_ID <- droplevels(case_legend$group_ID)

conditions <- levels(case_legend$group_ID)
if (REFERENCE_GROUP %in% conditions) {
  conditions <- conditions[conditions != REFERENCE_GROUP]
}
if (!file.exists(OUTPUT_DIRECTORY)) {
  dir.create(OUTPUT_DIRECTORY, recursive = TRUE)
}

matrix_data <- matrix(1:length(conditions)*length(csv_files), nrow = length(conditions), ncol = length(csv_files))

# Create a DataFrame with the matrix data, specifying column and row names
df <- data.frame(matrix_data, row.names = conditions)
colnames(df) <- lapply(csv_files, function(file) tools::file_path_sans_ext(basename(file)))


for (file in csv_files){
  filename <- tools::file_path_sans_ext(basename(file))
  print(filename)
  
  data <- read.csv(file, row.names=1)
  rownames(data) <- sub("^long", "", rownames(data))
  rownames(data) <- sub("X", "", rownames(data))
  celltype_folder <- file.path(OUTPUT_DIRECTORY, filename)

  if (!file.exists(celltype_folder)) {
    dir.create(celltype_folder, recursive = TRUE)
  }
  
  conditions <- "C9orf72"
  for (condition in conditions){
    
    print(condition)
    condition_folder <- file.path(celltype_folder, condition)
    if (!file.exists(condition_folder)) {
      dir.create(condition_folder, recursive = TRUE)
    }
    
    tryCatch({
      results_table <- NULL
      res <- NULL
      comparison_data <- case_legend[case_legend$group_ID %in% c(REFERENCE_GROUP, condition), ]
      comparison_data$group_ID <- factor(comparison_data$group_ID)
      
      comparison_data$SV1 <- covariate_data$SV1[match(comparison_data$sample.ID, covariate_data$sample.ID)]
      #comparison_data$SV2 <- covariate_data$SV2[match(comparison_data$sample.ID, covariate_data$sample.ID)]
      
      comparison_data$group_ID <- factor(comparison_data$group_ID, levels = c(REFERENCE_GROUP, condition))
      comparison_data <- comparison_data[order(comparison_data$group_ID), ]
      
      common_ids <- intersect(comparison_data$sample.ID, rownames(data))
      data_subset <- data[rownames(data) %in% common_ids, ]
      data_ordered <- data_subset[match(comparison_data$sample.ID, rownames(data_subset)), ]
      # CLEAN NA
      data_ordered[!is.finite(as.matrix(data_ordered))] <- 0
      data_ordered <- data_ordered[complete.cases(data_ordered), ]
      comparison_data <- comparison_data[match(rownames(data_ordered), comparison_data$sample.ID), ]
      
      
      
#     group <- relevel(group, ref = REFERENCE_GROUP)
      group <- factor(comparison_data$group_ID[comparison_data$group_ID %in% c(REFERENCE_GROUP, condition)])
      y <- DGEList(counts=t(data_ordered),group=group)
      y <- y[, colSums(y$counts) > 0]
      # Keep only samples in comparison_data that are in y
      comparison_data <- comparison_data[match(colnames(y), comparison_data$sample.ID), ]
      
      # Average Log CPM histogram
      AveLogCPM <- aveLogCPM(y)
      y <- normLibSizes(y)
      
      # MD plot
      plot_filename <- file.path(condition_folder, "MD_plot_h.png")
      png(file = plot_filename)
      MD_plot <- plotMD(y, column=1) +
        abline(h=0, col="red", lty=2, lwd=2)
      dev.off()
      
      # DESIGN MATRIX
      group <- factor(comparison_data$group_ID, levels = c(REFERENCE_GROUP, condition))
      comparison_data$group_ID <- relevel(comparison_data$group_ID, ref = REFERENCE_GROUP)
      design <- model.matrix(~ 0 + comparison_data$group_ID + comparison_data$SV1, data = comparison_data)
      colnames(design) <- c(REFERENCE_GROUP, condition, "SV1")
      nrow(design) == ncol(y)
      
      # DISPERSION ESTIMATION
      y <- estimateDisp(y,design)
      fit <- glmFit(y,design)
      
      # Diferential expression analysis
      B.LvsP <- makeContrasts(paste0(condition, " - ", REFERENCE_GROUP), levels=design)
      res <- glmLRT(fit, contrast=B.LvsP)
      is.de <- decideTests(res, adjust.method = "fdr", p.value = 0.05, lfc= 0)
      results_table <- res$table
      results_table$adj_pval <- p.adjust(results_table$PValue, method = "fdr", n = length(results_table$PValue))
      results_table <- cbind(results_table, data.frame(is.de))
      # SAVING CSV RESULTS
      write.csv(res$table, file = file.path(condition_folder, "res_h.csv"))
      write.csv(results_table, file = file.path(condition_folder, "results_adj_h.csv"))
      ## Visualizations
      # "Volcano like" plot
      plot_filename <- file.path(condition_folder, "MD_res_plot_h.png")
      png(file = plot_filename)
      plotMD(res, status=is.de)
      dev.off()
      
      # Heatmap clustering 
      logCPM <- cpm(y, prior.count=2, log=TRUE)
      rownames(logCPM) <- y$genes$Symbol
      colnames(logCPM) <- paste(y$samples$group, 1:2, sep="-")
      tr <- glmTreat(fit, contrast=B.LvsP, lfc=log2(1.5))
      o <- order(tr$table$PValue)
      logCPM <- logCPM[o[1:30],]
      
      plot_filename <- file.path(condition_folder, "Heatmap_h.png")
      png(file = plot_filename)
      coolmap(logCPM, margins=c(7,7), lhei=c(1,6), lwid=c(1,3))
      dev.off()
      
      df[condition, tools::file_path_sans_ext(basename(file))] <- nrow(results_table[results_table$adj_pval<0.05,])
      
    }, error = function(e){
      df[condition, tools::file_path_sans_ext(basename(file))] <- 0
    })
  }
}

write.csv(df, file = file.path(OUTPUT_DIRECTORY, "summary_h.csv"))
# https://bioconductor.org/packages/release/workflows/vignettes/RnaSeqGeneEdgeRQL/inst/doc/edgeRQL.html#preliminary-analysis
```

```{r code_5_cell_type_dea_5_dea_ftld_tdp_r, eval=FALSE}
library(edgeR, lib.loc = "/home/jaumatell/R/x86_64-pc-linux-gnu-library/4.4/edgeR_4")
library("dplyr")
library("GO.db")
library("xlsx")
################################################################################
# Paths and parameters
CSV_DECONVOLDED_PATH <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/TDP/CELL STATE/"
CASE_LEGEND <- "/media/jaumatell/datos/URI/BayesPrism/FTD/DATASETS/FTD_QUIM/decoder_DeSeq2_FTD_FINAL.xlsx"
OUTPUT_DIRECTORY <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/EDGER/FTLD/TDP/DEG"
REFERENCE_GROUP <- "Healthy"
################################################################################

csv_files <- list.files(CSV_DECONVOLDED_PATH, pattern = "\\.csv$", full.names = TRUE)

# Read case legend and prepare group IDs
case_legend <- read.xlsx(CASE_LEGEND,sheetIndex = 1)
case_legend$group_ID <- factor(case_legend$group.ID)
case_legend$group.ID <- NULL

# Ensure levels are consistent and drop unused levels
conditions <- levels(as.factor(case_legend$group_ID))
conditions <- "TDP"

# Create output directory if it doesn't exist
if (!file.exists(OUTPUT_DIRECTORY)) {
  dir.create(OUTPUT_DIRECTORY, recursive = TRUE)
}

# Initialize summary matrix
matrix_data <- matrix(1:length(conditions)*length(csv_files), nrow = length(conditions), ncol = length(csv_files))
df <- data.frame(matrix_data, row.names = conditions)
colnames(df) <- sapply(csv_files, function(file) tools::file_path_sans_ext(basename(file)))

# Process each CSV file
for (file in csv_files) {
  filename <- tools::file_path_sans_ext(basename(file))
  print(filename)
  
  data <- read.csv(file, row.names = 1)
  rownames(data) <-gsub("X", "", rownames(data))
  celltype_folder <- file.path(OUTPUT_DIRECTORY, filename)
  if (!file.exists(celltype_folder)) {
    dir.create(celltype_folder, recursive = TRUE)
  }
  
  for (condition in conditions) {
    condition_folder <- file.path(celltype_folder, condition)
    if (!file.exists(condition_folder)) {
      dir.create(condition_folder, recursive = TRUE)
    }
    
    tryCatch({
      results_table <- NULL
      res <- NULL
      
      comparison_data <- case_legend[case_legend$group_ID %in% c(REFERENCE_GROUP, condition), ]
      comparison_data$group_ID <- relevel(factor(comparison_data$group_ID, levels = c(REFERENCE_GROUP, condition)), ref = condition)
      comparison_data <- comparison_data[order(comparison_data$group_ID), ]
      
      common_ids <- intersect(comparison_data$sample.ID, rownames(data))
      data_subset <- data[rownames(data) %in% common_ids, ]
      data_ordered <- data_subset[match(comparison_data$sample.ID, rownames(data_subset)), ]
      data_ordered[is.na(data_ordered)] <- 10e-8
      #data_ordered <- data_ordered[row_sums > 0, ]
      
      group <- factor(comparison_data$group_ID)
      y <- DGEList(counts = t(data_ordered), group = group)
      
      # Plot average log CPM
      AveLogCPM <- aveLogCPM(y)
      y <- normLibSizes(y)
      #y <- y[row_sums > 0, ]
      
      plot_filename <- file.path(condition_folder, "MD_plot_h.png")
      png(file = plot_filename)
      plotMD(y, column = 1)
      abline(h = 0, col = "red", lty = 2, lwd = 2)
      dev.off()
      
      # Create design matrix
      design <- model.matrix(~ 0 + group)
      colnames(design) <- levels(group)
      
      # Estimate dispersion
      y <- estimateDisp(y, design)
      #y <- EdgeR::fillterByExpr(y, group=group)
      fit <- glmQLFit(y, design)
      
      #Differential expression analysis
      contrast <- makeContrasts(contrasts = paste0(make.names(condition), " - ", make.names(REFERENCE_GROUP)), levels = design)
      res <- glmLRT(fit, contrast = contrast)
      is.de <- decideTests(res, adjust.method = "fdr", p.value = 0.05, lfc = 0)
      results_table <- res$table
      results_table$adj_pval <- p.adjust(results_table$PValue, method = "fdr")
      results_table <- cbind(results_table, data.frame(is.de))
      
      # Save results
      write.csv(res$table, file = file.path(condition_folder, "res_h.csv"))
      write.csv(results_table, file = file.path(condition_folder, "results_adj_h.csv"))
      
      # Histogram
      plot_filename <- file.path(condition_folder, "histogram_plot_h.png")
      png(file = plot_filename)
      hist(AveLogCPM)
      dev.off()
      
      # BCV plot
      plot_filename <- file.path(condition_folder, "BCV_plot_h.png")
      png(file = plot_filename)
      plotBCV(y)
      dev.off()
      
      # "Volcano like" plot
      plot_filename <- file.path(condition_folder, "MD_res_plot_h.png")
      png(file = plot_filename)
      plotMD(res, status = is.de)
      dev.off()
      
      # Heatmap clustering
      logCPM <- cpm(y, prior.count = 2, log = TRUE)
      colnames(logCPM) <- paste(y$samples$group, 1:2, sep = "-")
      tr <- glmTreat(fit, contrast = contrast, lfc = log2(1.5))
      o <- order(tr$table$PValue)
      logCPM <- logCPM[o[1:30], ]
      
      plot_filename <- file.path(condition_folder, "Heatmap_h.png")
      png(file = plot_filename)
      coolmap(logCPM, margins = c(7, 7), lhei = c(1, 6), lwid = c(1, 3))
      dev.off()
      
      # Update summary DataFrame
      df[condition, filename] <- nrow(results_table[results_table$adj_pval < 0.05, ])
      
    }, error = function(e) {
      print(e)
      df[condition, filename] <- 0
    })
  }
}

# Save summary DataFrame
write.csv(df, file = file.path(OUTPUT_DIRECTORY, "summary_h.csv"))
```

```{r code_5_cell_type_dea_5_dea_rimmod_r, eval=FALSE}
library("edgeR")
library("dplyr")
library("GO.db")
library("xlsx")
################################################################################
# Paths and parameters
CSV_DECONVOLDED_PATH <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/RIMOD/CELL STATE ORIGINAL/"
CASE_LEGEND <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/RIMOD_BULK/DATA/rimod_ftd_dataset_table_v3.txt"
OUTPUT_DIRECTORY <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/EDGER/RIMOD/CS_SV"
SV_COVARIATE <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/RIMOD_BULK/METADATA/SVA.csv"

REFERENCE_GROUP <- "Healthy"
################################################################################

covariate_data <- read.csv(SV_COVARIATE, sep = "\t")
covariate_data$sample.ID <- sub("^long", "", covariate_data$ID)

csv_files <- list.files(CSV_DECONVOLDED_PATH, pattern = "\\.csv$", full.names = TRUE)

# Read case legend and prepare group IDs
case_legend <- read.delim(CASE_LEGEND)
case_legend <- case_legend[case_legend$DiseaseCode %in% c("control", "FTD-C9"), ]

# 2. Renombrar valores dentro de DiseaseCode
case_legend$DiseaseCode[case_legend$DiseaseCode == "control"] <- "Healthy"
case_legend$DiseaseCode[case_legend$DiseaseCode == "FTD-C9"] <- "C9orf72"

case_legend$group_ID <- factor(case_legend$DiseaseCode)
case_legend$group.ID <- NULL

# Ensure levels are consistent and drop unused levels
conditions <- levels(as.factor(case_legend$group_ID))
conditions <- "C9orf72"

# Create output directory if it doesn't exist
if (!file.exists(OUTPUT_DIRECTORY)) {
  dir.create(OUTPUT_DIRECTORY, recursive = TRUE)
}

# Initialize summary matrix
matrix_data <- matrix(1:length(conditions)*length(csv_files), nrow = length(conditions), ncol = length(csv_files))
df <- data.frame(matrix_data, row.names = conditions)
colnames(df) <- sapply(csv_files, function(file) tools::file_path_sans_ext(basename(file)))

# Process each CSV file
for (file in csv_files) {
  filename <- tools::file_path_sans_ext(basename(file))
  print(filename)
  
  data <- read.csv(file, row.names = 1)
  celltype_folder <- file.path(OUTPUT_DIRECTORY, filename)
  if (!file.exists(celltype_folder)) {
    dir.create(celltype_folder, recursive = TRUE)
  }
  
  for (condition in conditions) {
    condition_folder <- file.path(celltype_folder, condition)
    if (!file.exists(condition_folder)) {
      dir.create(condition_folder, recursive = TRUE)
    }
    
    tryCatch({
      results_table <- NULL
      res <- NULL
      comparison_data <- case_legend[case_legend$group_ID %in% c(REFERENCE_GROUP, condition), ]
      comparison_data$group_ID <- factor(comparison_data$group_ID)
      
      comparison_data$SV1 <- covariate_data$SV1[match(comparison_data$RimodID, covariate_data$ID)]

      comparison_data$group_ID <- factor(comparison_data$group_ID, levels = c(REFERENCE_GROUP, condition))
      comparison_data <- comparison_data[order(comparison_data$group_ID), ]
      common_ids <- intersect(comparison_data$RimodID, rownames(data))
      data_subset <- data[rownames(data) %in% common_ids, ]
      data_ordered <- data_subset[match(comparison_data$RimodID, rownames(data_subset)), ]
      # CLEAN NA
      data_ordered[!is.finite(as.matrix(data_ordered))] <- 0
      data_ordered <- data_ordered[complete.cases(data_ordered), ]
      comparison_data <- comparison_data[match(rownames(data_ordered), comparison_data$RimodID), ]
      
      group <- factor(comparison_data$group_ID[comparison_data$group_ID %in% c(REFERENCE_GROUP, condition)])
      y <- DGEList(counts=t(data_ordered),group=group)
      y <- y[, colSums(y$counts) > 0]
      # Keep only samples in comparison_data that are in y
      comparison_data <- comparison_data[match(colnames(y), comparison_data$RimodID), ]
      
      # Average Log CPM histogram
      AveLogCPM <- aveLogCPM(y)
      y <- normLibSizes(y)
      
      # MD plot
      plot_filename <- file.path(condition_folder, "MD_plot_h.png")
      png(file = plot_filename)
      MD_plot <- plotMD(y, column=1) +
        abline(h=0, col="red", lty=2, lwd=2)
      dev.off()
      
      # DESIGN MATRIX
      group <- factor(comparison_data$group_ID, levels = c(REFERENCE_GROUP, condition))
      comparison_data$group_ID <- relevel(comparison_data$group_ID, ref = REFERENCE_GROUP)
      design <- model.matrix(~ 0 + comparison_data$group_ID + comparison_data$SV1, data = comparison_data)
      colnames(design) <- c(REFERENCE_GROUP, condition, "SV1")
      nrow(design) == ncol(y)
      
      # DISPERSION ESTIMATION
      y <- estimateDisp(y,design)
      fit <- glmFit(y,design)
      
      # Diferential expression analysis
      B.LvsP <- makeContrasts(paste0(condition, " - ", REFERENCE_GROUP), levels=design)
      res <- glmLRT(fit, contrast=B.LvsP)
      is.de <- decideTests(res, adjust.method = "fdr", p.value = 0.05, lfc= 0)
      results_table <- res$table
      results_table$adj_pval <- p.adjust(results_table$PValue, method = "fdr", n = length(results_table$PValue))
      results_table <- cbind(results_table, data.frame(is.de))
      # SAVING CSV RESULTS
      write.csv(res$table, file = file.path(condition_folder, "res_h.csv"))
      write.csv(results_table, file = file.path(condition_folder, "results_adj_h.csv"))
      ## Visualizations
      # "Volcano like" plot
      plot_filename <- file.path(condition_folder, "MD_res_plot_h.png")
      png(file = plot_filename)
      plotMD(res, status=is.de)
      dev.off()
      
      # Heatmap clustering 
      logCPM <- cpm(y, prior.count=2, log=TRUE)
      rownames(logCPM) <- y$genes$Symbol
      colnames(logCPM) <- paste(y$samples$group, 1:2, sep="-")
      tr <- glmTreat(fit, contrast=B.LvsP, lfc=log2(1.5))
      o <- order(tr$table$PValue)
      logCPM <- logCPM[o[1:30],]
      
      plot_filename <- file.path(condition_folder, "Heatmap_h.png")
      png(file = plot_filename)
      coolmap(logCPM, margins=c(7,7), lhei=c(1,6), lwid=c(1,3))
      dev.off()
      
      df[condition, tools::file_path_sans_ext(basename(file))] <- nrow(results_table[results_table$adj_pval<0.05,])
      
    }, error = function(e){
      df[condition, tools::file_path_sans_ext(basename(file))] <- 0
    })
  }
}

# Save summary DataFrame
write.csv(df, file = file.path(OUTPUT_DIRECTORY, "summary_h.csv"))
```

```{r code_5_cell_type_dea_5_edger_sv_pottier_r, eval=FALSE}

library("edgeR")
library("dplyr")
library("GO.db")

# FTD
#CT
CSV_DECONVOLDED_PATH <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/NEW/CELL STATE ORIGINAL"
CASE_LEGEND <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/NEW_BULK/METADATA/Sample_info.txt"
#SV_COVARIATE <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/SURROGATED_VARIABLES/groupsTAU_sv1_sv2_QUIM.csv"
SV_COVARIATE <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/NEW_BULK/METADATA/SVA_correcte.csv"
OUTPUT_DIRECTORY <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/EDGER/NEW/CS_SVcorrect"

REFERENCE_GROUP <- "Control"

covariate_data <- read.delim(SV_COVARIATE)
#covariate_data <- read.delim(SV_COVARIATE, col.names = c("sample.ID", "X" ,"SV1", "SV2"))
covariate_data$sample.ID <- sub("^long", "", covariate_data$ID)


csv_files <- list.files(CSV_DECONVOLDED_PATH, pattern = "\\.csv$", full.names = TRUE)


case_legend <- read.delim(CASE_LEGEND)
case_legend <- case_legend[case_legend$GROUP != "FTLD-TDP-C",]
case_legend$GROUP[case_legend$GROUP != "Control"] <- "TDP"
case_legend$group_ID <- as.factor(case_legend$GROUP)


conditions <- levels(case_legend$group_ID)
if (REFERENCE_GROUP %in% conditions) {
  conditions <- conditions[conditions != REFERENCE_GROUP]
}
if (!file.exists(OUTPUT_DIRECTORY)) {
  dir.create(OUTPUT_DIRECTORY, recursive = TRUE)
}

matrix_data <- matrix(1:length(conditions)*length(csv_files), nrow = length(conditions), ncol = length(csv_files))

# Create a DataFrame with the matrix data, specifying column and row names
df <- data.frame(matrix_data, row.names = conditions)
colnames(df) <- lapply(csv_files, function(file) tools::file_path_sans_ext(basename(file)))


for (file in csv_files){
  filename <- tools::file_path_sans_ext(basename(file))
  print(filename)
  
  data <- read.csv(file, row.names=1)
  rownames(data) <- sub("^long", "", rownames(data))
  rownames(data) <- sub("X", "", rownames(data))
  celltype_folder <- file.path(OUTPUT_DIRECTORY, filename)
  
  if (!file.exists(celltype_folder)) {
    dir.create(celltype_folder, recursive = TRUE)
  }
  
  for (condition in conditions){
    condition <- "TDP"
    print(condition)
    condition_folder <- file.path(celltype_folder, condition)
    if (!file.exists(condition_folder)) {
      dir.create(condition_folder, recursive = TRUE)
    }
    
    tryCatch({
      results_table <- NULL
      res <- NULL
      comparison_data <- case_legend[case_legend$group_ID %in% c(REFERENCE_GROUP, condition), ]
      comparison_data$group_ID <- factor(comparison_data$group_ID)
      
      comparison_data$SV1 <- covariate_data$SV1[match(comparison_data$FCX_ID, covariate_data$ID)]
      #comparison_data$SV2 <- covariate_data$SV2[match(comparison_data$sample.ID, covariate_data$sample.ID)]
      
      comparison_data$group_ID <- factor(comparison_data$group_ID, levels = c(REFERENCE_GROUP, condition))
      comparison_data <- comparison_data[order(comparison_data$group_ID), ]
      comparison_data$FCX_ID <- gsub("-", ".", comparison_data$FCX_ID)
      common_ids <- intersect(comparison_data$FCX_ID, rownames(data))
      data_subset <- data[rownames(data) %in% common_ids, ]
      data_ordered <- data_subset[match(comparison_data$FCX_ID, rownames(data_subset)), ]
      # CLEAN NA
      data_ordered[!is.finite(as.matrix(data_ordered))] <- 0
      data_ordered <- data_ordered[complete.cases(data_ordered), ]
      comparison_data <- comparison_data[match(rownames(data_ordered), comparison_data$FCX_ID), ]
      
      
      
      #     group <- relevel(group, ref = REFERENCE_GROUP)
      group <- factor(comparison_data$group_ID[comparison_data$group_ID %in% c(REFERENCE_GROUP, condition)])
      y <- DGEList(counts=t(data_ordered),group=group)
      y <- y[, colSums(y$counts) > 0]
      # Keep only samples in comparison_data that are in y
      comparison_data <- comparison_data[match(colnames(y), comparison_data$FCX_ID), ]
      
      # Average Log CPM histogram
      AveLogCPM <- aveLogCPM(y)
      y <- normLibSizes(y)
      
      # MD plot
      plot_filename <- file.path(condition_folder, "MD_plot_h.png")
      png(file = plot_filename)
      MD_plot <- plotMD(y, column=1) +
        abline(h=0, col="red", lty=2, lwd=2)
      dev.off()
      
      # DESIGN MATRIX
      group <- factor(comparison_data$group_ID, levels = c(REFERENCE_GROUP, condition))
      comparison_data$group_ID <- relevel(comparison_data$group_ID, ref = REFERENCE_GROUP)
      design <- model.matrix(~ 0 + comparison_data$group_ID + comparison_data$SV1, data = comparison_data)
      colnames(design) <- c(REFERENCE_GROUP, condition, "SV1")
      nrow(design) == ncol(y)
      
      # DISPERSION ESTIMATION
      y <- estimateDisp(y,design)
      fit <- glmFit(y,design)
      
      # Diferential expression analysis
      B.LvsP <- makeContrasts(paste0(condition, " - ", REFERENCE_GROUP), levels=design)
      res <- glmLRT(fit, contrast=B.LvsP)
      is.de <- decideTests(res, adjust.method = "fdr", p.value = 0.05, lfc= 0)
      results_table <- res$table
      results_table$adj_pval <- p.adjust(results_table$PValue, method = "fdr", n = length(results_table$PValue))
      results_table <- cbind(results_table, data.frame(is.de))
      # SAVING CSV RESULTS
      write.csv(res$table, file = file.path(condition_folder, "res_h.csv"))
      write.csv(results_table, file = file.path(condition_folder, "results_adj_h.csv"))
      ## Visualizations
      # "Volcano like" plot
      plot_filename <- file.path(condition_folder, "MD_res_plot_h.png")
      png(file = plot_filename)
      plotMD(res, status=is.de)
      dev.off()
      
      # Heatmap clustering 
      logCPM <- cpm(y, prior.count=2, log=TRUE)
      rownames(logCPM) <- y$genes$Symbol
      colnames(logCPM) <- paste(y$samples$group, 1:2, sep="-")
      tr <- glmTreat(fit, contrast=B.LvsP, lfc=log2(1.5))
      o <- order(tr$table$PValue)
      logCPM <- logCPM[o[1:30],]
      
      plot_filename <- file.path(condition_folder, "Heatmap_h.png")
      png(file = plot_filename)
      coolmap(logCPM, margins=c(7,7), lhei=c(1,6), lwid=c(1,3))
      dev.off()
      
      df[condition, tools::file_path_sans_ext(basename(file))] <- nrow(results_table[results_table$adj_pval<0.05,])
      
    }, error = function(e){
      df[condition, tools::file_path_sans_ext(basename(file))] <- 0
    })
  }
}

write.csv(df, file = file.path(OUTPUT_DIRECTORY, "summary_h.csv"))
# https://bioconductor.org/packages/release/workflows/vignettes/RnaSeqGeneEdgeRQL/inst/doc/edgeRQL.html#preliminary-analysis
```

```{r code_5_cell_type_dea_5_extract_pvals_for_genes_uri_r, eval=FALSE}
# GENES P-VAl

Gene_list <- c("TUBA4A","NEFL","UBQLN2","OPTN","CHCHD10","MATR3","TBK1",
               "C9orf72","VCP","CHMP2B","SQSTM1","TARDBP","HNRNPA1",
               "FUS","MAPT","DPP6","TMEM106B","GRN","ARPP21","UNC13A",
               "C19orf52","FARP2","TINAG","MZT1","TNIP1","RCL1",
               "PDS5B","C3AR1","SMG8","VIPR1","L3MBTL1","RBPJL",
               "ANO9","HNRNPL", "NPTX2")

directory_C9 <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/EDGER/FTLD/C9/CS_LRT"
directory_TDP <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/EDGER/FTLD/TDP/CS_LRT"

# Function to extract folder name (last folder before filename)
extract_foldername <- function(path) {
  parts <- strsplit(path, "/")[[1]]
  # Second to last element is folder
  folder <- parts[length(parts)-2]
  return(folder)
  }  
  
# C9
list_files <- list.files(directory_C9, pattern = "results_adj_h", full.names = TRUE, recursive = TRUE)

# Initialize results with gene column
results <- data.frame(gene = Gene_list, stringsAsFactors = FALSE)



# Loop over files
for (file in list_files) {
  celltypename <- extract_foldername(file)
  data <- read.csv(file, row.names = 1)
  
  # Match gene list to rownames of data
  subset <- data[match(Gene_list, rownames(data)), "PValue"]
  
  # Add to results
  results[[celltypename]] <- subset
}

results$Count_below_0.05 <- apply(results[,-1], 1, function(x) sum(x < 0.05, na.rm = TRUE))


write.csv(results, file = "/media/jaumatell/datos/URI/BAYESPRISM_12_3/EDGER/C9_Pval_gens_URI.csv")

# TDP
list_files <- list.files(directory_TDP, pattern = "results_adj_h", full.names = TRUE, recursive = TRUE)

# Initialize results with gene column
results <- data.frame(gene = Gene_list, stringsAsFactors = FALSE)

# Function to extract folder name (last folder before filename)
extract_foldername <- function(path) {
  parts <- strsplit(path, "/")[[1]]
  # Second to last element is folder
  folder <- parts[length(parts)-2]
  return(folder)
}

# Loop over files
for (file in list_files) {
  celltypename <- extract_foldername(file)
  data <- read.csv(file, row.names = 1)
  
  # Match gene list to rownames of data
  subset <- data[match(Gene_list, rownames(data)), "PValue"]
  
  # Add to results
  results[[celltypename]] <- subset
}
results$Count_below_0.05 <- apply(results[,-1], 1, function(x) sum(x < 0.05, na.rm = TRUE))


write.csv(results, file = "/media/jaumatell/datos/URI/BAYESPRISM_12_3/EDGER/TDP_Pval_gens_URI.csv")
```

```{r fig_5_cell_type_dea_1, echo=FALSE, eval=FALSE}
# knitr::include_graphics("figures/fig_5_cell_type_dea_1.png")
```

```{r fig_5_cell_type_dea_2, echo=FALSE, eval=FALSE}
# knitr::include_graphics("figures/fig_5_cell_type_dea_2.png")
```

## 6. GENES OF INTERST CORRELATION

Evaluate correlations between selected genes of interest and transformed cell-type proportions across FTLD cohorts.

Scripts included in this step:

-   `6. GENES OF INTERST CORRELATION/6.C9_Correlation_genes_with_transformations.R`
-   `6. GENES OF INTERST CORRELATION/6.Correlation_genes_in_non-neur_and_ex-neur_with_transformations.R`
-   `6. GENES OF INTERST CORRELATION/6.TDP_Correlation_genes_with_transformations.R`

```{r code_6_genes_of_interst_correlation_6_c9_correlation_genes_with_transformations_r, eval=FALSE}
library(car)
library(Seurat)
library(dplyr)
library(RColorBrewer)
library(unikn)
library(cluster)
library(tidyverse)
library(readxl)

safe_cor <- function(x, y){
  tryCatch({
    if(all(is.na(x)) | all(is.na(y))) return(list(estimate = NA, p.value = NA))
    res <- cor.test(x, y, method = "spearman")
    list(estimate = res$estimate, p.value = res$p.value)
  }, error = function(e) list(estimate = NA, p.value = NA))
}


# C9
Expression_per_cell_directory <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/C9/CELL STATE ORIGINAL/"

OG_Covariables <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/FTD_C9_neuropath_SOM.csv")
OG_Covariables_log    <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/TRANSFORMED_COVARIABLES/Log/C9/Log_FTD_C9_neuropath_SOM.csv")
OG_Covariables_log2   <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/TRANSFORMED_COVARIABLES/Log2/C9/Log2_FTD_C9_neuropath_SOM.csv")
OG_Covariables_logit  <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/TRANSFORMED_COVARIABLES/Logit/C9/Logit_FTD_C9_neuropath_SOM.csv")
OG_Covariables_arcsin <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/TRANSFORMED_COVARIABLES/ArcSin/C9/ArcSin_FTD_C9_neuropath_SOM.csv")

# Excitatory neurons
cells <- c("CUX2_RASGRF2", "CUX2_RORB", "SCN4B_NEFH", "RORB_FOXO1", 
           "RORB_POU3F2", "RORB_ADGRL4", "RORB_LRRK1", "PCP4_NXPH2", 
           "VAT1L_EYA4", "THEMIS_NR4A2", "THEMIS_TMEM233", 
           "TLE4_CCBE1", "TLE4_MEGF11", "TLE4_SEMA3D", "GFAP-neg", 
           "GFAP-pos", "Micro", "Oligo", "OPC")

genes <- c("STMN2", "NPTX2", "C9orf72", "CXCL10", "SPP1", "CX3CR1") 
covariables <- c("STMN2", "pTDP43")

results <- data.frame(Cell = character(),
                      Gene = character(),
                      Covariable = character(),
                      Gene_transformation = character(),
                      Cov_transformation = character(),
                      Spearman = numeric(),
                      p_value = numeric(),
                      stringsAsFactors = FALSE)

for (cell in cells){
  data <- read.csv(paste0(Expression_per_cell_directory, cell, ".csv"), row.names = "X")
  
  for (gene in genes){
    common_ids <- intersect(rownames(data), OG_Covariables_log$X)
    subset_gene_subset <- data[common_ids, gene]
    subset_Covariables  <- OG_Covariables[match(common_ids, OG_Covariables$X), ]
    subset_Covariables_log  <- OG_Covariables_log[match(common_ids, OG_Covariables_log$X),]
    subset_Covariables_log2  <- OG_Covariables_log2[match(common_ids, OG_Covariables_log2$X), ]
    subset_Covariables_logit  <- OG_Covariables_logit[match(common_ids, OG_Covariables_logit$X), ]
    subset_Covariables_arcsin  <- OG_Covariables_arcsin[match(common_ids, OG_Covariables_arcsin$X), ]
    
    
    # gene transformations
    subset_log_data    <- log1p(subset_gene_subset)
    subset_log2_data   <- log(subset_gene_subset, base = 2)
    # protect logit and arcsin
    subset_logit_data <- tryCatch({
      logit(gene_subset, percents = FALSE, adjust = TRUE)
    }, error = function(e) rep(NA, length(subset_gene_subset)))
    
    subset_norm_logit_data <- tryCatch({
      logit(subset_gene_subset/max(subset_gene_subset), percents = FALSE, adjust = TRUE)
    }, error = function(e) rep(NA, length(subset_gene_subset)))
    
    subset_arcsin_data <- tryCatch({
      asin(sqrt(subset_gene_subset))
    }, error = function(e) rep(NA, length(subset_gene_subset)))
    
    subset_norm_arcsin_data <- tryCatch({
      asin(sqrt(subset_gene_subset/max(subset_gene_subset)))
    }, error = function(e) rep(NA, length(subset_gene_subset)))
    
        
    for (covariable in covariables){
      
      if (covariable == "AAA"){
        
        outlier <- "7BLACK"
        no_outlier_ids <- common_ids[common_ids != "7BLACK"] 
        
        gene_subset <- subset_gene_subset[no_outlier_ids,]
        Covariables  <- subset_Covariables[match(no_outlier_ids, subset_Covariables$X), ]
        Covariables_log  <- subset_Covariables_log[match(no_outlier_ids, subset_Covariables_log$X),]
        Covariables_log2  <- subset_Covariables_log2[match(no_outlier_ids, subset_Covariables_log2$X), ]
        Covariables_logit  <- subset_Covariables_logit[match(no_outlier_ids, subset_Covariables_logit$X), ]
        Covariables_arcsin  <- subset_Covariables_arcsin[match(no_outlier_ids, subset_Covariables_arcsin$X), ]
        
        # gene transformations
        log_data    <- subset_log_data
        log2_data   <- subset_log2_data
        logit_data <- subset_logit_data
        norm_logit_data <- subset_norm_logit_data
        arcsin_data <- subset_arcsin_data
        norm_arcsin_data <- subset_norm_arcsin_data
        
      } else {
        gene_subset <- subset_gene_subset
        Covariables  <- subset_Covariables
        Covariables_log  <- subset_Covariables_log
        Covariables_log2  <- subset_Covariables_log2
        Covariables_logit  <- subset_Covariables_logit
        Covariables_arcsin  <- subset_Covariables_arcsin
        
        # gene transformations
        log_data    <- subset_log_data
        log2_data   <- subset_log2_data
        logit_data <- subset_logit_data
        norm_logit_data <- subset_norm_logit_data
        arcsin_data <- subset_arcsin_data
        norm_arcsin_data <- subset_norm_arcsin_data
      }
      
      result_corr <- safe_cor(gene_subset, Covariables[, covariable])
      
      result_log_corr <- safe_cor(log_data, Covariables[, covariable])
      result_log_log  <- safe_cor(log_data, Covariables_log[,covariable])
      result_gene_log <- safe_cor(gene_subset, Covariables_log[,covariable])
      
      result_log2_corr <- safe_cor(log2_data, Covariables[, covariable])
      result_log2_log2 <- safe_cor(log2_data, Covariables_log2[,covariable])
      result_gene_log2 <- safe_cor(gene_subset, Covariables_log2[,covariable])
      
      result_logit_corr <- safe_cor(logit_data, Covariables[, covariable])
      result_logit_logit <- safe_cor(logit_data, Covariables_logit[,covariable])
      result_gene_logit <- safe_cor(gene_subset, Covariables_logit[, covariable])
      
      result_norm_logit_corr <- safe_cor(norm_logit_data, Covariables[, covariable])
      result_norm_logit_logit <- safe_cor(norm_logit_data,  Covariables_logit[,covariable])
      
      result_arcsin_corr <- safe_cor(arcsin_data, Covariables[, covariable])
      result_arcsin_arcsin <- safe_cor(arcsin_data, Covariables_arcsin[,covariable])
      result_gene_arcsin <- safe_cor(gene_subset, Covariables_arcsin[,covariable])
      
      result_norm_arcsin_corr <- safe_cor(norm_arcsin_data, Covariables[, covariable])
      result_norm_arcsin_arcsin <- safe_cor(norm_arcsin_data, Covariables_arcsin[,covariable])
            
      results <- rbind(results,
                       #Cor - Cor
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "",
                                  Cov_transformation = "", 
                                  Spearman = result_corr$estimate, 
                                  p_value = result_corr$p.value),
                       #Log - Cor
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Log",
                                  Cov_transformation = "", 
                                  Spearman = result_log_corr$estimate, 
                                  p_value = result_log_corr$p.value),
                       #Log - Log
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Log",
                                  Cov_transformation = "Log", 
                                  Spearman = result_log_log$estimate, 
                                  p_value = result_log_log$p.value),
                       #Gene - Log
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "",
                                  Cov_transformation = "Log", 
                                  Spearman = result_gene_log$estimate, 
                                  p_value = result_gene_log$p.value),
                       # Log2 - Corr
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Log2",
                                  Cov_transformation = "", 
                                  Spearman = result_log2_corr$estimate, 
                                  p_value = result_log2_corr$p.value),
                       # Log2 - Log2
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Log2",
                                  Cov_transformation = "Log2", 
                                  Spearman = result_log2_log2$estimate, 
                                  p_value = result_log2_log2$p.value),
                       # Gene - Log2
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "",
                                  Cov_transformation = "Log2", 
                                  Spearman = result_gene_log2$estimate, 
                                  p_value = result_gene_log2$p.value),
                       # Logit - Corr
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Logit",
                                  Cov_transformation = "",  
                                  Spearman = result_logit_corr$estimate, 
                                  p_value = result_logit_corr$p.value),
                       # Logit - Logit
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Logit",
                                  Cov_transformation = "Logit",  
                                  Spearman = result_logit_logit$estimate, 
                                  p_value = result_logit_logit$p.value),
                       # Gene - Logit
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "",
                                  Cov_transformation = "Logit",  
                                  Spearman = result_gene_logit$estimate, 
                                  p_value = result_gene_logit$p.value),
                       # Norm+Logit - Corr
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Norm + Logit",
                                  Cov_transformation = "",  
                                  Spearman = result_norm_logit_corr$estimate, 
                                  p_value = result_norm_logit_corr$p.value),
                       # Norm+Logit - Logit
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Norm + Logit",
                                  Cov_transformation = "Logit",  
                                  Spearman = result_norm_logit_logit$estimate, 
                                  p_value = result_norm_logit_logit$p.value),
                       # Arcsin - Corr
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Arcsin",
                                  Cov_transformation = "",  
                                  Spearman = result_arcsin_corr$estimate, 
                                  p_value = result_arcsin_corr$p.value),
                       # Arcsin - Arcsin
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Arcsin",
                                  Cov_transformation = "Arcsin",  
                                  Spearman = result_arcsin_arcsin$estimate, 
                                  p_value = result_arcsin_arcsin$p.value),
                       # Gene - Arcsin
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "",
                                  Cov_transformation = "Arcsin",  
                                  Spearman = result_gene_arcsin$estimate, 
                                  p_value = result_gene_arcsin$p.value),
                       # Norm+Arcsin - Corr
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Norm + Arcsin",
                                  Cov_transformation = "",  
                                  Spearman = result_norm_arcsin_corr$estimate, 
                                  p_value = result_norm_arcsin_corr$p.value),
                       # Norm+Arcsin - Arcsin
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Norm + Arcsin",
                                  Cov_transformation = "Arcsin",  
                                  Spearman = result_norm_arcsin_arcsin$estimate, 
                                  p_value = result_norm_arcsin_arcsin$p.value))
      
      result_log_corr <-NULL
      result_log_log  <- NULL
      result_gene_log <- NULL
      result_log2_corr <- NULL
      result_log2_log2 <- NULL
      result_gene_log2 <- NULL
      result_logit_corr <- NULL
      result_logit_logit <- NULL
      result_gene_logit <- NULL
      result_norm_logit_corr <- NULL
      result_norm_logit_logit <- NULL
      result_arcsin_corr <- NULL
      result_arcsin_arcsin <- NULL
      result_gene_arcsin <- NULL
      result_norm_arcsin_corr <- NULL
      result_norm_arcsin_arcsin <- NULL
    }
  }
}

results
write.csv(results, file = "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/GENES_CORR/C9_genes_correlation.csv")
```

```{r code_6_genes_of_interst_correlation_6_correlation_genes_in_non_neur_and_ex_neur_with_transformations_r, eval=FALSE}
library(car)
library(Seurat)
library(dplyr)
library(RColorBrewer)
library(unikn)
library(cluster)
library(tidyverse)
library(readxl)

safe_cor <- function(x, y){
  tryCatch({
    if(all(is.na(x)) | all(is.na(y))) return(list(estimate = NA, p.value = NA))
    res <- cor.test(x, y, method = "spearman")
    list(estimate = res$estimate, p.value = res$p.value)
  }, error = function(e) list(estimate = NA, p.value = NA))
}


# C9
Expression_per_cell_directory <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/C9/CELL STATE ORIGINAL/"

OG_Covariables <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/FTD_C9_neuropath_SOM.csv")
OG_Covariables_log    <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/TRANSFORMED_COVARIABLES/Log/C9/Log_FTD_C9_neuropath_SOM.csv")
OG_Covariables_log2   <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/TRANSFORMED_COVARIABLES/Log2/C9/Log2_FTD_C9_neuropath_SOM.csv")
OG_Covariables_logit  <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/TRANSFORMED_COVARIABLES/Logit/C9/Logit_FTD_C9_neuropath_SOM.csv")
OG_Covariables_arcsin <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/TRANSFORMED_COVARIABLES/ArcSin/C9/ArcSin_FTD_C9_neuropath_SOM.csv")

# Excitatory neurons
cells <- c("CUX2_RASGRF2", "CUX2_RORB", "SCN4B_NEFH", "RORB_FOXO1", 
           "RORB_POU3F2", "RORB_ADGRL4", "RORB_LRRK1", "PCP4_NXPH2", 
           "VAT1L_EYA4", "VAT1L_THSD4", "THEMIS_NR4A2", "THEMIS_TMEM233", 
           "TLE4_CCBE1", "TLE4_MEGF11", "TLE4_SEMA3D")

genes <- c("STMN2", "NPTX2", "C9orf72", "CXCL10", "SPP1", "CX3CR1") 
covariables <- c("STMN2", "pTDP43")

results <- data.frame(Cell = character(),
                      Gene = character(),
                      Covariable = character(),
                      Gene_transformation = character(),
                      Cov_transformation = character(),
                      Spearman = numeric(),
                      p_value = numeric(),
                      stringsAsFactors = FALSE)

for (cell in cells){
  data <- read.csv(paste0(Expression_per_cell_directory, cell, ".csv"), row.names = "X")
  
  for (gene in genes){
    common_ids <- intersect(rownames(data), OG_Covariables_log$X)
    subset_gene_subset <- data[common_ids, gene]
    subset_Covariables  <- OG_Covariables[match(common_ids, OG_Covariables$X), ]
    subset_Covariables_log  <- OG_Covariables_log[match(common_ids, OG_Covariables_log$X),]
    subset_Covariables_log2  <- OG_Covariables_log2[match(common_ids, OG_Covariables_log2$X), ]
    subset_Covariables_logit  <- OG_Covariables_logit[match(common_ids, OG_Covariables_logit$X), ]
    subset_Covariables_arcsin  <- OG_Covariables_arcsin[match(common_ids, OG_Covariables_arcsin$X), ]
    
    
    # gene transformations
    subset_log_data    <- log1p(gene_subset)
    subset_log2_data   <- log(gene_subset, base = 2)
    # protect logit and arcsin
    subset_logit_data <- tryCatch({
      logit(gene_subset, percents = FALSE, adjust = TRUE)
    }, error = function(e) rep(NA, length(gene_subset)))
    
    subset_norm_logit_data <- tryCatch({
      logit(gene_subset/max(gene_subset), percents = FALSE, adjust = TRUE)
    }, error = function(e) rep(NA, length(gene_subset)))
    
    subset_arcsin_data <- tryCatch({
      asin(sqrt(gene_subset))
    }, error = function(e) rep(NA, length(gene_subset)))
    
    subset_norm_arcsin_data <- tryCatch({
      asin(sqrt(gene_subset/max(gene_subset)))
    }, error = function(e) rep(NA, length(gene_subset)))
    
        
    for (covariable in covariables){
      
      if (covariable == "AAA"){
        
        outlier <- "7BLACK"
        no_outlier_ids <- common_ids[common_ids != "7BLACK"] 
        
        gene_subset <- subset_gene_subset[no_outlier_ids,]
        Covariables  <- subset_Covariables[match(no_outlier_ids, subset_Covariables$X), ]
        Covariables_log  <- subset_Covariables_log[match(no_outlier_ids, subset_Covariables_log$X),]
        Covariables_log2  <- subset_Covariables_log2[match(no_outlier_ids, subset_Covariables_log2$X), ]
        Covariables_logit  <- subset_Covariables_logit[match(no_outlier_ids, subset_Covariables_logit$X), ]
        Covariables_arcsin  <- subset_Covariables_arcsin[match(no_outlier_ids, subset_Covariables_arcsin$X), ]
        
        # gene transformations
        log_data    <- subset_log_data
        log2_data   <- subset_log2_data
        logit_data <- subset_logit_data
        norm_logit_data <- subset_norm_logit_data
        arcsin_data <- subset_arcsin_data
        norm_arcsin_data <- subset_norm_arcsin_data
        
      } else {
        gene_subset <- subset_gene_subset
        Covariables  <- subset_Covariables
        Covariables_log  <- subset_Covariables_log
        Covariables_log2  <- subset_Covariables_log2
        Covariables_logit  <- subset_Covariables_logit
        Covariables_arcsin  <- subset_Covariables_arcsin
        
        # gene transformations
        log_data    <- subset_log_data
        log2_data   <- subset_log2_data
        logit_data <- subset_logit_data
        norm_logit_data <- subset_norm_logit_data
        arcsin_data <- subset_arcsin_data
        norm_arcsin_data <- subset_norm_arcsin_data
      }
      
      result_corr <- safe_cor(gene_subset, Covariables[, covariable])
      
      result_log_corr <- safe_cor(log_data, Covariables[, covariable])
      result_log_log  <- safe_cor(log_data, Covariables_log[,covariable])
      result_gene_log <- safe_cor(gene_subset, Covariables_log[,covariable])
      
      result_log2_corr <- safe_cor(log2_data, Covariables[, covariable])
      result_log2_log2 <- safe_cor(log2_data, Covariables_log2[,covariable])
      result_gene_log2 <- safe_cor(gene_subset, Covariables_log2[,covariable])
      
      result_logit_corr <- safe_cor(logit_data, Covariables[, covariable])
      result_logit_logit <- safe_cor(logit_data, Covariables_logit[,covariable])
      result_gene_logit <- safe_cor(gene_subset, Covariables_logit[, covariable])
      
      result_norm_logit_corr <- safe_cor(norm_logit_data, Covariables[, covariable])
      result_norm_logit_logit <- safe_cor(norm_logit_data,  Covariables_logit[,covariable])
      
      result_arcsin_corr <- safe_cor(arcsin_data, Covariables[, covariable])
      result_arcsin_arcsin <- safe_cor(arcsin_data, Covariables_arcsin[,covariable])
      result_gene_arcsin <- safe_cor(gene_subset, Covariables_arcsin[,covariable])
      
      result_norm_arcsin_corr <- safe_cor(norm_arcsin_data, Covariables[, covariable])
      result_norm_arcsin_arcsin <- safe_cor(norm_arcsin_data, Covariables_arcsin[,covariable])
            
      results <- rbind(results,
                       #Cor - Cor
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "",
                                  Cov_transformation = "", 
                                  Spearman = result_corr$estimate, 
                                  p_value = result_corr$p.value),
                       #Log - Cor
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Log",
                                  Cov_transformation = "", 
                                  Spearman = result_log_corr$estimate, 
                                  p_value = result_log_corr$p.value),
                       #Log - Log
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Log",
                                  Cov_transformation = "Log", 
                                  Spearman = result_log_log$estimate, 
                                  p_value = result_log_log$p.value),
                       #Gene - Log
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "",
                                  Cov_transformation = "Log", 
                                  Spearman = result_gene_log$estimate, 
                                  p_value = result_gene_log$p.value),
                       # Log2 - Corr
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Log2",
                                  Cov_transformation = "", 
                                  Spearman = result_log2_corr$estimate, 
                                  p_value = result_log2_corr$p.value),
                       # Log2 - Log2
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Log2",
                                  Cov_transformation = "Log2", 
                                  Spearman = result_log2_log2$estimate, 
                                  p_value = result_log2_log2$p.value),
                       # Gene - Log2
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "",
                                  Cov_transformation = "Log2", 
                                  Spearman = result_gene_log2$estimate, 
                                  p_value = result_gene_log2$p.value),
                       # Logit - Corr
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Logit",
                                  Cov_transformation = "",  
                                  Spearman = result_logit_corr$estimate, 
                                  p_value = result_logit_corr$p.value),
                       # Logit - Logit
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Logit",
                                  Cov_transformation = "Logit",  
                                  Spearman = result_logit_logit$estimate, 
                                  p_value = result_logit_logit$p.value),
                       # Gene - Logit
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "",
                                  Cov_transformation = "Logit",  
                                  Spearman = result_gene_logit$estimate, 
                                  p_value = result_gene_logit$p.value),
                       # Norm+Logit - Corr
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Norm + Logit",
                                  Cov_transformation = "",  
                                  Spearman = result_norm_logit_corr$estimate, 
                                  p_value = result_norm_logit_corr$p.value),
                       # Norm+Logit - Logit
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Norm + Logit",
                                  Cov_transformation = "Logit",  
                                  Spearman = result_norm_logit_logit$estimate, 
                                  p_value = result_norm_logit_logit$p.value),
                       # Arcsin - Corr
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Arcsin",
                                  Cov_transformation = "",  
                                  Spearman = result_arcsin_corr$estimate, 
                                  p_value = result_arcsin_corr$p.value),
                       # Arcsin - Arcsin
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Arcsin",
                                  Cov_transformation = "Arcsin",  
                                  Spearman = result_arcsin_arcsin$estimate, 
                                  p_value = result_arcsin_arcsin$p.value),
                       # Gene - Arcsin
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "",
                                  Cov_transformation = "Arcsin",  
                                  Spearman = result_gene_arcsin$estimate, 
                                  p_value = result_gene_arcsin$p.value),
                       # Norm+Arcsin - Corr
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Norm + Arcsin",
                                  Cov_transformation = "",  
                                  Spearman = result_norm_arcsin_corr$estimate, 
                                  p_value = result_norm_arcsin_corr$p.value),
                       # Norm+Arcsin - Arcsin
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Norm + Arcsin",
                                  Cov_transformation = "Arcsin",  
                                  Spearman = result_norm_arcsin_arcsin$estimate, 
                                  p_value = result_norm_arcsin_arcsin$p.value))
      
      result_log_corr <-NULL
      result_log_log  <- NULL
      result_gene_log <- NULL
      result_log2_corr <- NULL
      result_log2_log2 <- NULL
      result_gene_log2 <- NULL
      result_logit_corr <- NULL
      result_logit_logit <- NULL
      result_gene_logit <- NULL
      result_norm_logit_corr <- NULL
      result_norm_logit_logit <- NULL
      result_arcsin_corr <- NULL
      result_arcsin_arcsin <- NULL
      result_gene_arcsin <- NULL
      result_norm_arcsin_corr <- NULL
      result_norm_arcsin_arcsin <- NULL
    }
  }
}

results


Covariables <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/FTD_C9_neuropath_SOM.csv")
Covariables_log    <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/TRANSFORMED_COVARIABLES/Log/C9/Log_FTD_C9_neuropath_SOM.csv")
Covariables_log2   <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/TRANSFORMED_COVARIABLES/Log2/C9/Log2_FTD_C9_neuropath_SOM.csv")
Covariables_logit  <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/TRANSFORMED_COVARIABLES/Logit/C9/Logit_FTD_C9_neuropath_SOM.csv")
Covariables_arcsin <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/TRANSFORMED_COVARIABLES/ArcSin/C9/ArcSin_FTD_C9_neuropath_SOM.csv")

# Non-Neuronal
cells <- c("GFAP-neg", "GFAP-pos", "Micro", "Oligo", "OPC")
genes <- c("STMN2", "NPTX2", "C9orf72", "CXCL10", "SPP1", "CX3CR1")  
covariables <- c("STMN2", "pTDP43")


results <- data.frame(Cell = character(),
                      Gene = character(),
                      Covariable = character(),
                      Gene_transformation = character(),
                      Cov_transformation = character(),
                      Spearman = numeric(),
                      p_value = numeric(),
                      stringsAsFactors = FALSE)

for (cell in cells){
  data <- read.csv(paste0(Expression_per_cell_directory, cell, ".csv"), row.names = "X")
  
  for (gene in genes){
    common_ids <- intersect(rownames(data), Covariables_log$X)
    gene_subset <- data[common_ids, gene]
    Covariables  <- Covariables[match(common_ids, Covariables$X), ]
    Covariables_log  <- Covariables_log[match(common_ids, Covariables_log$X),]
    Covariables_log2  <- Covariables_log2[match(common_ids, Covariables_log2$X), ]
    Covariables_logit  <- Covariables_logit[match(common_ids, Covariables_logit$X), ]
    Covariables_arcsin  <- Covariables_arcsin[match(common_ids, Covariables_arcsin$X), ]
    
    # Gene transformations
    
    # Log
    log_data    <- log1p(gene_subset)
    # Log2
    log2_data   <- log(gene_subset, base = 2)
    # Logit
    logit_data <- tryCatch({
      logit(gene_subset, percents = FALSE, adjust = TRUE)
    }, error = function(e) rep(NA, length(gene_subset)))
    # Norm+Logit
    norm_logit_data <- tryCatch({
      logit(gene_subset/max(gene_subset), percents = FALSE, adjust = TRUE)
    }, error = function(e) rep(NA, length(gene_subset)))
    # Arcsin
    arcsin_data <- tryCatch({
      asin(sqrt(gene_subset))
    }, error = function(e) rep(NA, length(gene_subset)))
    # Norm+Arcsin
    norm_arcsin_data <- tryCatch({
      asin(sqrt(gene_subset/max(gene_subset)))
    }, error = function(e) rep(NA, length(gene_subset)))
    
    for (covariable in covariables){
          common_ids <- intersect(rownames(data), OG_Covariables_log$X)
    subset_gene_subset <- data[common_ids, gene]
    subset_Covariables  <- OG_Covariables[match(common_ids, OG_Covariables$X), ]
    subset_Covariables_log  <- OG_Covariables_log[match(common_ids, OG_Covariables_log$X),]
    subset_Covariables_log2  <- OG_Covariables_log2[match(common_ids, OG_Covariables_log2$X), ]
    subset_Covariables_logit  <- OG_Covariables_logit[match(common_ids, OG_Covariables_logit$X), ]
    subset_Covariables_arcsin  <- OG_Covariables_arcsin[match(common_ids, OG_Covariables_arcsin$X), ]
    
    
    # gene transformations
    subset_log_data    <- log1p(gene_subset)
    subset_log2_data   <- log(gene_subset, base = 2)
    # protect logit and arcsin
    subset_logit_data <- tryCatch({
      logit(gene_subset, percents = FALSE, adjust = TRUE)
    }, error = function(e) rep(NA, length(gene_subset)))
    
    subset_norm_logit_data <- tryCatch({
      logit(gene_subset/max(gene_subset), percents = FALSE, adjust = TRUE)
    }, error = function(e) rep(NA, length(gene_subset)))
    
    subset_arcsin_data <- tryCatch({
      asin(sqrt(gene_subset))
    }, error = function(e) rep(NA, length(gene_subset)))
    
    subset_norm_arcsin_data <- tryCatch({
      asin(sqrt(gene_subset/max(gene_subset)))
    }, error = function(e) rep(NA, length(gene_subset)))
    
        
    for (covariable in covariables){
      
      if (covariable == "AAA"){
        
        outlier <- "7BLACK"
        no_outlier_ids <- common_ids[common_ids != "7BLACK"] 
        
        gene_subset <- subset_gene_subset[no_outlier_ids,]
        Covariables  <- subset_Covariables[match(no_outlier_ids, subset_Covariables$X), ]
        Covariables_log  <- subset_Covariables_log[match(no_outlier_ids, subset_Covariables_log$X),]
        Covariables_log2  <- subset_Covariables_log2[match(no_outlier_ids, subset_Covariables_log2$X), ]
        Covariables_logit  <- subset_Covariables_logit[match(no_outlier_ids, subset_Covariables_logit$X), ]
        Covariables_arcsin  <- subset_Covariables_arcsin[match(no_outlier_ids, subset_Covariables_arcsin$X), ]
        
        # gene transformations
        log_data    <- subset_log_data
        log2_data   <- subset_log2_data
        logit_data <- subset_logit_data
        norm_logit_data <- subset_norm_logit_data
        arcsin_data <- subset_arcsin_data
        norm_arcsin_data <- subset_norm_arcsin_data
        
      } else {
        gene_subset <- subset_gene_subset
        Covariables  <- subset_Covariables
        Covariables_log  <- subset_Covariables_log
        Covariables_log2  <- subset_Covariables_log2
        Covariables_logit  <- subset_Covariables_logit
        Covariables_arcsin  <- subset_Covariables_arcsin
        
        # gene transformations
        log_data    <- subset_log_data
        log2_data   <- subset_log2_data
        logit_data <- subset_logit_data
        norm_logit_data <- subset_norm_logit_data
        arcsin_data <- subset_arcsin_data
        norm_arcsin_data <- subset_norm_arcsin_data
      }
      
      result_corr <- safe_cor(gene_subset, Covariables[, covariable])
      
      result_log_corr <- safe_cor(log_data, Covariables[, covariable])
      result_log_log  <- safe_cor(log_data, Covariables_log[,covariable])
      result_gene_log <- safe_cor(gene_subset, Covariables_log[,covariable])
      
      result_log2_corr <- safe_cor(log2_data, Covariables[, covariable])
      result_log2_log2 <- safe_cor(log2_data, Covariables_log2[,covariable])
      result_gene_log2 <- safe_cor(gene_subset, Covariables_log2[,covariable])
      
      result_logit_corr <- safe_cor(logit_data, Covariables[, covariable])
      result_logit_logit <- safe_cor(logit_data, Covariables_logit[,covariable])
      result_gene_logit <- safe_cor(gene_subset, Covariables_logit[, covariable])
      
      result_norm_logit_corr <- safe_cor(norm_logit_data, Covariables[, covariable])
      result_norm_logit_logit <- safe_cor(norm_logit_data,  Covariables_logit[,covariable])
      
      result_arcsin_corr <- safe_cor(arcsin_data, Covariables[, covariable])
      result_arcsin_arcsin <- safe_cor(arcsin_data, Covariables_arcsin[,covariable])
      result_gene_arcsin <- safe_cor(gene_subset, Covariables_arcsin[,covariable])
      
      result_norm_arcsin_corr <- safe_cor(norm_arcsin_data, Covariables[, covariable])
      result_norm_arcsin_arcsin <- safe_cor(norm_arcsin_data, Covariables_arcsin[,covariable])
      
      results <- rbind(results,
                       #Cor - Cor
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "",
                                  Cov_transformation = "", 
                                  Spearman = result_corr$estimate, 
                                  p_value = result_corr$p.value),
                       #Log - Cor
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Log",
                                  Cov_transformation = "", 
                                  Spearman = result_log_corr$estimate, 
                                  p_value = result_log_corr$p.value),
                       #Log - Log
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Log",
                                  Cov_transformation = "Log", 
                                  Spearman = result_log_log$estimate, 
                                  p_value = result_log_log$p.value),
                       #Gene - Log
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "",
                                  Cov_transformation = "Log", 
                                  Spearman = result_gene_log$estimate, 
                                  p_value = result_gene_log$p.value),
                       # Log2 - Corr
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Log2",
                                  Cov_transformation = "", 
                                  Spearman = result_log2_corr$estimate, 
                                  p_value = result_log2_corr$p.value),
                       # Log2 - Log2
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Log2",
                                  Cov_transformation = "Log2", 
                                  Spearman = result_log2_log2$estimate, 
                                  p_value = result_log2_log2$p.value),
                       # Gene - Log2
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "",
                                  Cov_transformation = "Log2", 
                                  Spearman = result_gene_log2$estimate, 
                                  p_value = result_gene_log2$p.value),
                       # Logit - Corr
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Logit",
                                  Cov_transformation = "",  
                                  Spearman = result_logit_corr$estimate, 
                                  p_value = result_logit_corr$p.value),
                       # Logit - Logit
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Logit",
                                  Cov_transformation = "Logit",  
                                  Spearman = result_logit_logit$estimate, 
                                  p_value = result_logit_logit$p.value),
                       # Gene - Logit
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "",
                                  Cov_transformation = "Logit",  
                                  Spearman = result_gene_logit$estimate, 
                                  p_value = result_gene_logit$p.value),
                       # Norm+Logit - Corr
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Norm + Logit",
                                  Cov_transformation = "",  
                                  Spearman = result_norm_logit_corr$estimate, 
                                  p_value = result_norm_logit_corr$p.value),
                       # Norm+Logit - Logit
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Norm + Logit",
                                  Cov_transformation = "Logit",  
                                  Spearman = result_norm_logit_logit$estimate, 
                                  p_value = result_norm_logit_logit$p.value),
                       # Arcsin - Corr
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Arcsin",
                                  Cov_transformation = "",  
                                  Spearman = result_arcsin_corr$estimate, 
                                  p_value = result_arcsin_corr$p.value),
                       # Arcsin - Arcsin
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Arcsin",
                                  Cov_transformation = "Arcsin",  
                                  Spearman = result_arcsin_arcsin$estimate, 
                                  p_value = result_arcsin_arcsin$p.value),
                       # Gene - Arcsin
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "",
                                  Cov_transformation = "Arcsin",  
                                  Spearman = result_gene_arcsin$estimate, 
                                  p_value = result_gene_arcsin$p.value),
                       # Norm+Arcsin - Corr
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Norm + Arcsin",
                                  Cov_transformation = "",  
                                  Spearman = result_norm_arcsin_corr$estimate, 
                                  p_value = result_norm_arcsin_corr$p.value),
                       # Norm+Arcsin - Arcsin
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Norm + Arcsin",
                                  Cov_transformation = "Arcsin",  
                                  Spearman = result_norm_arcsin_arcsin$estimate, 
                                  p_value = result_norm_arcsin_arcsin$p.value))
      
      result_log_corr <-NULL
      result_log_log  <- NULL
      result_gene_log <- NULL
      result_log2_corr <- NULL
      result_log2_log2 <- NULL
      result_gene_log2 <- NULL
      result_logit_corr <- NULL
      result_logit_logit <- NULL
      result_gene_logit <- NULL
      result_norm_logit_corr <- NULL
      result_norm_logit_logit <- NULL
      result_arcsin_corr <- NULL
      result_arcsin_arcsin <- NULL
      result_gene_arcsin <- NULL
      result_norm_arcsin_corr <- NULL
      result_norm_arcsin_arcsin <- NULL
      
    }
  }
  }
}
View(results)
results
```

```{r code_6_genes_of_interst_correlation_6_tdp_correlation_genes_with_transformations_r, eval=FALSE}
library(car)
library(Seurat)
library(dplyr)
library(RColorBrewer)
library(unikn)
library(cluster)
library(tidyverse)
library(readxl)

safe_cor <- function(x, y){
  tryCatch({
    if(all(is.na(x)) | all(is.na(y))) return(list(estimate = NA, p.value = NA))
    res <- cor.test(x, y, method = "spearman")
    list(estimate = res$estimate, p.value = res$p.value)
  }, error = function(e) list(estimate = NA, p.value = NA))
}


# TDP
Expression_per_cell_directory <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/TDP/CELL STATE ORIGINAL/"

OG_Covariables <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/FTD_TDP_neuropath_SOM.csv")
OG_Covariables_log    <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/TRANSFORMED_COVARIABLES/Log/TDP/Log_FTD_TDP_neuropath_SOM.csv")
OG_Covariables_log2   <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/TRANSFORMED_COVARIABLES/Log2/TDP/Log2_FTD_TDP_neuropath_SOM")
OG_Covariables_logit  <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/TRANSFORMED_COVARIABLES/Logit/TDP/Logit_FTD_TDP_neuropath_SOM.csv")
OG_Covariables_arcsin <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/TRANSFORMED_COVARIABLES/ArcSin/TDP/ArcSin_FTD_TDP_neuropath_SOM")

# Excitatory neurons
cells <- c("CUX2_RASGRF2", "CUX2_RORB", "SCN4B_NEFH", "RORB_FOXO1", 
           "RORB_POU3F2", "RORB_ADGRL4", "RORB_LRRK1", "PCP4_NXPH2", 
           "VAT1L_EYA4", "THEMIS_NR4A2", "THEMIS_TMEM233", 
           "TLE4_CCBE1", "TLE4_MEGF11", "TLE4_SEMA3D", "GFAP-neg", 
           "GFAP-pos", "Micro", "Oligo", "OPC")

genes <- c("STMN2", "NPTX2", "C9orf72", "CXCL10", "SPP1", "CX3CR1", "CHI3L1") 
covariables <- c("STMN2", "TDP43b")

results <- data.frame(Cell = character(),
                      Gene = character(),
                      Covariable = character(),
                      Gene_transformation = character(),
                      Cov_transformation = character(),
                      Spearman = numeric(),
                      p_value = numeric(),
                      stringsAsFactors = FALSE)

for (cell in cells){
  data <- read.csv(paste0(Expression_per_cell_directory, cell, ".csv"), row.names = "X")
  rownames(data) <- gsub( "X", "long",  rownames(data))
  for (gene in genes){
    common_ids <- intersect(rownames(data), OG_Covariables_log$X)
    subset_gene_subset <- data[common_ids, gene, drop = FALSE]
    
    subset_Covariables  <- OG_Covariables[match(common_ids, OG_Covariables$X), ]
    subset_Covariables_log  <- OG_Covariables_log[match(common_ids, OG_Covariables_log$X),]
    subset_Covariables_log2  <- OG_Covariables_log2[match(common_ids, OG_Covariables_log2$X), ]
    subset_Covariables_logit  <- OG_Covariables_logit[match(common_ids, OG_Covariables_logit$X), ]
    subset_Covariables_arcsin  <- OG_Covariables_arcsin[match(common_ids, OG_Covariables_arcsin$X), ]
    
    # Gene transformations
    # Log
    subset_log_data <- log1p(subset_gene_subset)
    # Log2
    subset_log2_data <- log(subset_gene_subset, base = 2)
    # Logit
    subset_logit_data <- tryCatch({
      logit(subset_gene_subset, percents = FALSE, adjust = TRUE)
    }, error = function(e) rep(NA, length(subset_gene_subset)))
    # Norm+Logit
    subset_norm_logit_data <- tryCatch({
      logit(subset_gene_subset/max(subset_gene_subset), percents = FALSE, adjust = TRUE)
    }, error = function(e) rep(NA, length(subset_gene_subset)))
    # Arcsin
    subset_arcsin_data <- tryCatch({
      asin(sqrt(subset_gene_subset))
    }, error = function(e) rep(NA, length(subset_gene_subset)))
    # Norm+Arcsin
    subset_norm_arcsin_data <- tryCatch({
      asin(sqrt(subset_gene_subset/max(subset_gene_subset)))
    }, error = function(e) rep(NA, length(subset_gene_subset)))
    
    for (covariable in covariables){
       if (covariable == "STMN2"){
        
        outlier <- "long7BLACK"
        no_outlier_ids <- common_ids[common_ids != outlier] 
        
        gene_subset <- subset_gene_subset[no_outlier_ids,, drop = FALSE]
        Covariables  <- subset_Covariables[match(no_outlier_ids, subset_Covariables$X), ]
        Covariables_log  <- subset_Covariables_log[match(no_outlier_ids, subset_Covariables_log$X),]
        Covariables_log2  <- subset_Covariables_log2[match(no_outlier_ids, subset_Covariables_log2$X), ]
        Covariables_logit  <- subset_Covariables_logit[match(no_outlier_ids, subset_Covariables_logit$X), ]
        Covariables_arcsin  <- subset_Covariables_arcsin[match(no_outlier_ids, subset_Covariables_arcsin$X), ]
        
        # gene transformations
        log_data    <- subset_log_data[no_outlier_ids,]
        log2_data   <- subset_log2_data[no_outlier_ids,]
        logit_data <- try(subset_logit_data[no_outlier_ids,])
        norm_logit_data <- subset_norm_logit_data[no_outlier_ids,]
        arcsin_data <- subset_arcsin_data[no_outlier_ids,]
        norm_arcsin_data <- subset_norm_arcsin_data[no_outlier_ids,]
        
       } else {
         gene_subset <- subset_gene_subset
         Covariables  <- subset_Covariables
         Covariables_log  <- subset_Covariables_log
         Covariables_log2  <- subset_Covariables_log2
         Covariables_logit  <- subset_Covariables_logit
         Covariables_arcsin  <- subset_Covariables_arcsin
         
         # gene transformations
         log_data    <- subset_log_data
         log2_data   <- subset_log2_data
         logit_data <- subset_logit_data
         norm_logit_data <- subset_norm_logit_data
         arcsin_data <- subset_arcsin_data
         norm_arcsin_data <- subset_norm_arcsin_data
       }
      
      result_corr <- safe_cor(gene_subset[, gene], Covariables[, covariable])
      
      result_log_corr <- safe_cor(log_data[, gene], Covariables[, covariable])
      result_log_log  <- safe_cor(log_data[, gene], Covariables_log[,covariable])
      result_gene_log <- safe_cor(gene_subset[, gene], Covariables_log[,covariable])
      
      result_log2_corr <- safe_cor(log2_data[, gene], Covariables[, covariable])
      result_log2_log2 <- safe_cor(log2_data[, gene], Covariables_log2[,covariable])
      result_gene_log2 <- safe_cor(gene_subset[, gene], Covariables_log2[,covariable])
      
      result_logit_corr <- safe_cor(logit_data[, gene], Covariables[, covariable])
      result_logit_logit <- safe_cor(logit_data[, gene], Covariables_logit[,covariable])
      result_gene_logit <- safe_cor(gene_subset[, gene], Covariables_logit[, covariable])
      
      result_norm_logit_corr <- safe_cor(norm_logit_data[, gene], Covariables[, covariable])
      result_norm_logit_logit <- safe_cor(norm_logit_data[, gene],  Covariables_logit[,covariable])
      
      result_arcsin_corr <- safe_cor(arcsin_data[, gene], Covariables[, covariable])
      result_arcsin_arcsin <- safe_cor(arcsin_data[, gene], Covariables_arcsin[,covariable])
      result_gene_arcsin <- safe_cor(gene_subset[, gene], Covariables_arcsin[,covariable])
      
      result_norm_arcsin_corr <- safe_cor(norm_arcsin_data[, gene], Covariables[, covariable])
      result_norm_arcsin_arcsin <- safe_cor(norm_arcsin_data[, gene], Covariables_arcsin[,covariable])
      
      results <- rbind(results,
                       #Cor - Cor
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "",
                                  Cov_transformation = "", 
                                  Spearman = result_corr$estimate, 
                                  p_value = result_corr$p.value),
                       #Log - Cor
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Log",
                                  Cov_transformation = "", 
                                  Spearman = result_log_corr$estimate, 
                                  p_value = result_log_corr$p.value),
                       #Log - Log
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Log",
                                  Cov_transformation = "Log", 
                                  Spearman = result_log_log$estimate, 
                                  p_value = result_log_log$p.value),
                       #Gene - Log
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "",
                                  Cov_transformation = "Log", 
                                  Spearman = result_gene_log$estimate, 
                                  p_value = result_gene_log$p.value),
                       # Log2 - Corr
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Log2",
                                  Cov_transformation = "", 
                                  Spearman = result_log2_corr$estimate, 
                                  p_value = result_log2_corr$p.value),
                       # Log2 - Log2
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Log2",
                                  Cov_transformation = "Log2", 
                                  Spearman = result_log2_log2$estimate, 
                                  p_value = result_log2_log2$p.value),
                       # Gene - Log2
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "",
                                  Cov_transformation = "Log2", 
                                  Spearman = result_gene_log2$estimate, 
                                  p_value = result_gene_log2$p.value),
                       # Logit - Corr
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Logit",
                                  Cov_transformation = "",  
                                  Spearman = result_logit_corr$estimate, 
                                  p_value = result_logit_corr$p.value),
                       # Logit - Logit
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Logit",
                                  Cov_transformation = "Logit",  
                                  Spearman = result_logit_logit$estimate, 
                                  p_value = result_logit_logit$p.value),
                       # Gene - Logit
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "",
                                  Cov_transformation = "Logit",  
                                  Spearman = result_gene_logit$estimate, 
                                  p_value = result_gene_logit$p.value),
                       # Norm+Logit - Corr
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Norm + Logit",
                                  Cov_transformation = "",  
                                  Spearman = result_norm_logit_corr$estimate, 
                                  p_value = result_norm_logit_corr$p.value),
                       # Norm+Logit - Logit
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Norm + Logit",
                                  Cov_transformation = "Logit",  
                                  Spearman = result_norm_logit_logit$estimate, 
                                  p_value = result_norm_logit_logit$p.value),
                       # Arcsin - Corr
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Arcsin",
                                  Cov_transformation = "",  
                                  Spearman = result_arcsin_corr$estimate, 
                                  p_value = result_arcsin_corr$p.value),
                       # Arcsin - Arcsin
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Arcsin",
                                  Cov_transformation = "Arcsin",  
                                  Spearman = result_arcsin_arcsin$estimate, 
                                  p_value = result_arcsin_arcsin$p.value),
                       # Gene - Arcsin
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "",
                                  Cov_transformation = "Arcsin",  
                                  Spearman = result_gene_arcsin$estimate, 
                                  p_value = result_gene_arcsin$p.value),
                       # Norm+Arcsin - Corr
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Norm + Arcsin",
                                  Cov_transformation = "",  
                                  Spearman = result_norm_arcsin_corr$estimate, 
                                  p_value = result_norm_arcsin_corr$p.value),
                       # Norm+Arcsin - Arcsin
                       data.frame(Cell = cell, Gene = gene, 
                                  Covariable = covariable,
                                  Gene_transformation = "Norm + Arcsin",
                                  Cov_transformation = "Arcsin",  
                                  Spearman = result_norm_arcsin_arcsin$estimate, 
                                  p_value = result_norm_arcsin_arcsin$p.value))
      
      result_log_corr <-NULL
      result_log_log  <- NULL
      result_gene_log <- NULL
      result_log2_corr <- NULL
      result_log2_log2 <- NULL
      result_gene_log2 <- NULL
      result_logit_corr <- NULL
      result_logit_logit <- NULL
      result_gene_logit <- NULL
      result_norm_logit_corr <- NULL
      result_norm_logit_logit <- NULL
      result_arcsin_corr <- NULL
      result_arcsin_arcsin <- NULL
      result_gene_arcsin <- NULL
      result_norm_arcsin_corr <- NULL
      result_norm_arcsin_arcsin <- NULL
      
    }
  }
}
View(results[results$Gene =="CHI3L1",])
results

write.csv(results, file = "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/GENES_CORR/TDP_genes_correlation_no_outlier.csv")
```

```{r fig_6_genes_of_interst_correlation_1, echo=FALSE, eval=FALSE}
# knitr::include_graphics("figures/fig_6_genes_of_interst_correlation_1.png")
```

```{r fig_6_genes_of_interst_correlation_2, echo=FALSE, eval=FALSE}
# knitr::include_graphics("figures/fig_6_genes_of_interst_correlation_2.png")
```

## 7 HDWGCNA

Build hdWGCNA modules from single-nucleus data to capture co-expression patterns across neuronal subtypes.

Scripts included in this step:

-   `7 HDWGCNA/hdWGCNA generate modules .R`

```{r code_7_hdwgcna_hdwgcna_generate_modules_r, eval=FALSE}
# single-cell analysis package
library(Seurat)

# plotting and data science packages
library(tidyverse)
library(cowplot)
library(patchwork)

# co-expression network analysis packages:
library(WGCNA)
library(hdWGCNA)

# paralel processing
library(fs)
library(future.apply)

# Configurar sessio
plan(multisession, workers = parallel::detectCores() - 1)
theme_set(theme_cowplot())
set.seed(12345)
enableWGCNAThreads(nThreads = 8)

# Directori d'entrada i sortida
input_dir <- "/media/jaumatell/datos/URI/PROJECTE_SEURAT_BP/25_09/FC/Rimod_C9/CELL STATE/"
output_dir <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/hdWGCNA/Rimod/CS/"

if (!dir_exists(output_dir)) dir_create(output_dir)
csv_files <- dir_ls(input_dir, glob = "*.csv")

WGCNA_pseudobulk <- function(file) {
  tryCatch({
    
    # Obtenir el nom base de l'arxiu sense extensió
    sample_name <- path_ext_remove(path_file(file))
    sample_output_dir <- file.path(output_dir, sample_name)
    
    if (!dir_exists(sample_output_dir)) dir_create(sample_output_dir)
    
    message("Processing sample: ", sample_name)
    
    # Carregar dades en format CSV
    sc_data <- read.csv(file, row.names = 1)
    
    # Convertir a objecte Seurat
    seurat_obj <- CreateSeuratObject(counts = t(sc_data))
    seurat_obj <- SeuratObject::UpdateSeuratObject(seurat_obj)
    
    seurat_obj@meta.data$Sample <- rownames(sc_data)
    seurat_obj@meta.data$cell_type <- sample_name
    
    seurat_obj <- SetupForWGCNA(
      seurat_obj,
      gene_select = "fraction",
      fraction = 0.05,
      wgcna_name = "pseudobulk"
    )
    
    message("Selected genes: ", length(GetWGCNAGenes(seurat_obj)))
    
    # log2CPM normalization
    cpm <- t(apply(sc_data, 1, function(x) {
      y <- x / sum(x) * 1e6
      log2(y + 1)
    }))
    
    seurat_obj <- SetDatExpr(seurat_obj, mat = cpm)
    seurat_obj@assays$RNA$data <- t(cpm)
    
    # Soft thresholding
    seurat_obj <- TestSoftPowers(seurat_obj)
    
    # Save power plot
    png(file.path(sample_output_dir, "soft_power.png"), width = 1000, height = 800)
    PlotSoftPowers(seurat_obj)
    dev.off()
    
    # Construct network
    seurat_obj <- ConstructNetwork(
      seurat_obj,
      tom_name = "pseudobulk",
      overwrite_tom = TRUE,
      mergeCutHeight = 0.25
    )
    
    # Dendrogram
    png(file.path(sample_output_dir, "dendrogram.png"), width = 1000, height = 800)
    PlotDendrogram(seurat_obj, main = "pseudobulk dendrogram")
    dev.off()
    
    # Eigengenes and connectivity
    seurat_obj <- ModuleEigengenes(seurat_obj, npcs = 2)
    seurat_obj <- ModuleConnectivity(seurat_obj)
    
    # DotPlot of MEs
    MEs <- GetMEs(seurat_obj)
    mods <- setdiff(colnames(MEs), "grey")
    meta <- seurat_obj@meta.data
    seurat_obj@meta.data <- cbind(meta, MEs)
    
    p_dot <- DotPlot(seurat_obj, features = mods, group.by = "cell_type") +
      RotatedAxis() +
      scale_color_gradient(high = "red", low = "grey95") +
      xlab("") + ylab("")
    
    png(file.path(sample_output_dir, "dotplot_MEs.png"), width = 1000, height = 800)
    print(p_dot)
    dev.off()
    
    # Reset metadata
    seurat_obj@meta.data <- meta
    
    # UMAP
    seurat_obj <- RunModuleUMAP(
      seurat_obj,
      n_hubs = 5,
      n_neighbors = 10,
      min_dist = 0.4,
      spread = 3,
      supervised = TRUE,
      target_weight = 0.3
    )
    
    umap_df <- GetModuleUMAP(seurat_obj)
    centroid_df <- umap_df %>%
      dplyr::group_by(module) %>%
      dplyr::summarise(UMAP1 = mean(UMAP1), UMAP2 = mean(UMAP2))
    
    p_umap <- ggplot(umap_df, aes(x = UMAP1, y = UMAP2)) +
      geom_point(color = umap_df$color, size = umap_df$kME * 2) +
      geom_label(data = centroid_df, label = as.character(centroid_df$module),
                 fontface = "bold", size = 2) +
      umap_theme() +
      theme(panel.background = element_rect(fill = "black"))
    
    png(file.path(sample_output_dir, "umap_modules.png"), width = 1000, height = 800)
    print(p_umap)
    dev.off()
    
    # Save the final Seurat object
    saveRDS(seurat_obj, file = file.path(sample_output_dir, paste0(sample_name, "_seurat.rds")))
    
    message("Finished processing: ", sample_name)
    
  }, error = function(e) {
    message("⚠️ Error in sample: ", file)
    message("Details: ", e$message)
  })
}




#future_lapply(csv_files, WGCNA_pseudobulk, future.seed = TRUE)
for (file in csv_files){
  WGCNA_pseudobulk(file)
}


library(dplyr)
library(hdWGCNA)
library(xlsx)

# Loop over directories
for (CS in list.dirs("/media/jaumatell/datos/URI/BAYESPRISM_12_3/hdWGCNA/FTLD/TDP/CS_0.25_bo/", full.names = FALSE, recursive = FALSE)) {
  try({
    
    # Load Seurat object
    A <- readRDS(paste0("/media/jaumatell/datos/URI/BAYESPRISM_12_3/hdWGCNA/FTLD/TDP/CS_0.25_bo/", CS, "/", CS, "_seurat.rds"))
    
    # Load and prepare metadata
    metadata <- xlsx::read.xlsx("/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx", 
                                row.names = 1, sheetIndex = 1)
    metadata_df <- as.data.frame(metadata)
    metadata_df$Sample_clean <- rownames(metadata_df)
    
    # Harmonize and merge metadata
    A$Sample_clean <- gsub("^X", "", A@meta.data$Sample)
    meta_joined <- A@meta.data %>%
      mutate(Sample_clean = gsub("^X", "", Sample)) %>%
      left_join(metadata_df, by = "Sample_clean")
    
    A@meta.data <- meta_joined
    
    # Get Module Eigengenes
    MEs <- hdWGCNA::GetMEs(A)
    
    # Correlation of MEs with group.ID
    cor_results <- apply(MEs, 2, function(module) {
      cor.test(module, as.numeric(as.factor(A@meta.data$group.ID)), 
               method = "spearman", exact = TRUE)
    })
    
    cor_df <- data.frame(
      module = names(cor_results),
      cor = sapply(cor_results, function(x) x$estimate),
      p.value = sapply(cor_results, function(x) x$p.value)
    )
    
    cor_df_sorted <- cor_df[order(cor_df$p.value), ]
    
    # Create output directory if not exists
    outdir <- paste0("/media/jaumatell/datos/URI/BAYESPRISM_12_3/hdWGCNA/FTLD/TDP/CS_0.25_bo/", CS, "/MODULES/")
    dir.create(outdir, showWarnings = FALSE, recursive = TRUE)
    
    # Write gene lists for significant modules
    module_colors <- A@misc$pseudobulk$wgcna_degrees
    
    sig_modules <- cor_df_sorted$module[cor_df_sorted$p.value < 0.05]
    
    for (mod in sig_modules) {
      genes <- module_colors$gene_name[module_colors$module == mod]
      write.csv(genes, file = paste0(outdir, mod, ".csv"), row.names = FALSE)
    }
    write.csv(cor_df_sorted, file = paste0(outdir, "/cor_summary.csv"), row.names = FALSE)
    print(paste0("Finished: ", CS))
    
  }) # end try
}
```

```{r fig_7_hdwgcna_1, echo=FALSE, eval=FALSE}
# knitr::include_graphics("figures/fig_7_hdwgcna_1.png")
```

```{r fig_7_hdwgcna_2, echo=FALSE, eval=FALSE}
# knitr::include_graphics("figures/fig_7_hdwgcna_2.png")
```

## 8. DIFFERENCES IN MODULES

Test for differential module eigengene expression between diagnostic groups for each hdWGCNA module.

Scripts included in this step:

-   `8. DIFFERENCES IN MODULES/8. hdWGCNA case_control differences.R`

```{r code_8_differences_in_modules_8_hdwgcna_case_control_differences_r, eval=FALSE}
library(dplyr)
library(hdWGCNA)
library(xlsx)

for (CS in list.dirs("/media/jaumatell/datos/URI/BAYESPRISM_12_3/hdWGCNA/FTLD/TDP/CS_bo_ambhubs/", full.names = FALSE, recursive = FALSE)) {
  try({
    
    # Load Seurat object
    A <- readRDS(paste0("/media/jaumatell/datos/URI/BAYESPRISM_12_3/hdWGCNA/FTLD/TDP/CS_bo_ambhubs/", CS, "/", CS, "_seurat.rds"))
    
    # Load metadata
    metadata <- xlsx::read.xlsx("/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx", 
                                row.names = 1, sheetIndex = 1)
    metadata_df <- as.data.frame(metadata)
    metadata_df$Sample_clean <- rownames(metadata_df)
    
    # Harmonize sample names
    A$Sample_clean <- gsub("^X", "", A@meta.data$Sample)
    meta_joined <- A@meta.data %>%
      mutate(Sample_clean = gsub("^X", "", Sample)) %>%
      left_join(metadata_df, by = "Sample_clean")
    A@meta.data <- meta_joined
    
    # Get Module Eigengenes
    MEs <- hdWGCNA::GetMEs(A)
    
    # Ensure sample order matches between MEs and metadata
    sample_order <- rownames(MEs)
    # Ensure consistent factor order: Healthy (control), TDP (case)
    group_vector <- factor(
      A@meta.data[match(sample_order, A@meta.data$Sample), "group.ID"],
      levels = c("Healthy", "TDP")
    )
    
    # Apply Wilcoxon test and calculate fold change
    test_results <- lapply(1:ncol(MEs), function(i) {
      vec <- MEs[, i]
      group1 <- vec[group_vector == "Healthy"]
      group2 <- vec[group_vector == "TDP"]
      fc <- mean(group2, na.rm = TRUE) - mean(group1, na.rm = TRUE)  # TDP - Healthy
      test <- wilcox.test(group1, group2)
      
      list(
        module = colnames(MEs)[i],
        fold_change = fc,
        p.value = test$p.value
      )
    })
    
    cor_df <- do.call(rbind, lapply(test_results, as.data.frame))
    cor_df_sorted <- cor_df[order(cor_df$p.value), ]
    
    # Create output directory
    outdir <- paste0("/media/jaumatell/datos/URI/BAYESPRISM_12_3/hdWGCNA/FTLD/TDP/CS_bo_ambhubs/", CS, "/MODULES/")
    dir.create(outdir, showWarnings = FALSE, recursive = TRUE)
    
    # Write gene lists for significant modules
    module_colors <- A@misc$pseudobulk$wgcna_degrees
    sig_modules <- cor_df_sorted$module[!is.na(cor_df_sorted$module)]
    
    for (mod in sig_modules) {
      genes <- module_colors$gene_name[module_colors$module == mod]
      write.csv(genes, file = paste0(outdir,mod, ".csv"), row.names = FALSE)
    }
    
    # Write summary and hub genes
    Hubs <- GetHubGenes(A, n_hubs = 10, mods = NULL, wgcna_name = NULL)
    write.csv(cor_df_sorted, file = paste0(outdir, "/cor_summary.csv"), row.names = FALSE)
    write.csv(as.data.frame(Hubs), file = paste0(outdir, "/hubs.csv"), row.names = FALSE)
    
    print(paste0("Finished: ", CS))
  })
}


library(Seurat)
library(dplyr)
library(hdWGCNA)

# Loop over directories
for (CS in list.dirs("/media/jaumatell/datos/URI/BAYESPRISM_12_3/hdWGCNA/NEW/CS_bo/", full.names = FALSE, recursive = FALSE)) {
  try({
    
    # Load Seurat object
    A <- readRDS(paste0("/media/jaumatell/datos/URI/BAYESPRISM_12_3/hdWGCNA/NEW/CS_bo/", CS, "/", CS, "_seurat.rds"))
    
    # Load metadata
    metadata <- read.delim("/media/jaumatell/datos/URI/BAYESPRISM_12_3/NEW_BULK/METADATA/Sample_info.txt", 
                           row.names = 1, sep = "\t")
    metadata_df <- as.data.frame(metadata)
    metadata_df$Sample_clean <- gsub("-", "\\.",rownames(metadata_df))
    rownames(metadata_df) <- metadata_df$Sample_clean 
    # Filter out FTLD-TDP-C and recode group labels
    metadata_df <- metadata_df[metadata_df$GROUP != "FTLD-TDP-C", ]
    metadata_df$GROUP <- ifelse(metadata_df$GROUP == "Control", "Healthy", "TDP")
    
    samples_to_keep <- intersect(rownames(A@meta.data), metadata_df$Sample_clean)
    A <- subset(A,cells= samples_to_keep)
                
    # Harmonize and merge metadata
    A@meta.data <- metadata_df
    
    # Get Module Eigengenes
    MEs <- hdWGCNA::GetMEs(A)
    samples_in_A <- rownames(A@meta.data)
    MEs <- MEs[rownames(MEs) %in% samples_in_A, ]
    sample_order <- rownames(MEs)
    
    # Ensure correct group assignment order
    group_vector <- factor(
      A@meta.data[match(sample_order, rownames(A@meta.data)), "GROUP"],
      levels = c("Healthy", "TDP")
    )
    
    # Apply Wilcoxon test and compute fold change
    test_results <- lapply(1:ncol(MEs), function(i) {
      vec <- MEs[, i]
      group1 <- vec[group_vector == "Healthy"]
      group2 <- vec[group_vector == "TDP"]
      fc <- mean(group2, na.rm = TRUE) - mean(group1, na.rm = TRUE)  # TDP - Healthy
      test <- wilcox.test(group1, group2)
      
      list(
        module = colnames(MEs)[i],
        fold_change = fc,
        p.value = test$p.value
      )
    })
    
    # Compile and sort results
    cor_df <- do.call(rbind, lapply(test_results, as.data.frame))
    cor_df_sorted <- cor_df[order(cor_df$p.value), ]
    
    # Create output directory
    outdir <- paste0("/media/jaumatell/datos/URI/BAYESPRISM_12_3/hdWGCNA/NEW/CS_bo/", CS, "/MODULES/")
    dir.create(outdir, showWarnings = FALSE, recursive = TRUE)
    
    # Write gene lists for significant modules
    module_colors <- A@misc$pseudobulk$wgcna_degrees
    sig_modules <- cor_df_sorted$module[!is.na(cor_df_sorted$module)]
    
    for (mod in sig_modules) {
      genes <- module_colors$gene_name[module_colors$module == mod]
      write.csv(genes, file = paste0(outdir, mod, ".csv"), row.names = FALSE)
    }
    
    # Write summary and hub genes
    Hubs <- GetHubGenes(A, n_hubs = 10, mods = NULL, wgcna_name = NULL)
    write.csv(cor_df_sorted, file = paste0(outdir, "/cor_summary.csv"), row.names = FALSE)
    write.csv(as.data.frame(Hubs), file = paste0(outdir, "/hubs.csv"), row.names = FALSE)
    
    print(paste0("Finished: ", CS))
  })
}
```

```{r fig_8_differences_in_modules_1, echo=FALSE, eval=FALSE}
# knitr::include_graphics("figures/fig_8_differences_in_modules_1.png")
```

```{r fig_8_differences_in_modules_2, echo=FALSE, eval=FALSE}
# knitr::include_graphics("figures/fig_8_differences_in_modules_2.png")
```

## 9. CORRELATION MODULES

Assess correlations between hdWGCNA modules and phenotypic traits, including historical correlation pipelines.

Scripts included in this step:

-   `9. CORRELATION MODULES/9. hdWGCNA_step3_Version2.R`
-   `9. CORRELATION MODULES/OLD 9. Correlations of modules c9 and TDP .R`
-   `9. CORRELATION MODULES/RESUM_CORRELACIONS_MODULS.R`

```{r code_9_correlation_modules_9_hdwgcna_step3_version2_r, eval=FALSE}

############################## Correlation MEs VS Covariables ###############################
library(hdWGCNA)
library(dplyr)
library(Seurat)
library(xlsx)

CS <- list.dirs("/media/jaumatell/datos/URI/BAYESPRISM_12_3/hdWGCNA/FTLD/TDP/CS_bo_ambhubs/", full.names = FALSE, recursive = FALSE)[1]

for (CS in list.dirs("/media/jaumatell/datos/URI/BAYESPRISM_12_3/hdWGCNA/FTLD/TDP/CS_bo_ambhubs/", 
                     full.names = FALSE, recursive = FALSE)) {
  if (file.exists(paste0("/media/jaumatell/datos/URI/BAYESPRISM_12_3/hdWGCNA/FTLD/TDP/CS_bo_ambhubs/", CS, "/", CS, "_seurat.rds"))) {
    
    tryCatch({
      
      message("Processing CS: ", CS)
#      sink(log_file, append = TRUE); cat(Sys.time(), " - Processing: ", CS, "\n"); sink()
      
      # Load Seurat object
      A <- readRDS(paste0("/media/jaumatell/datos/URI/BAYESPRISM_12_3/hdWGCNA/FTLD/TDP/CS_bo_ambhubs/", CS, "/", CS, "_seurat.rds"))
      
      # Load metadata
      metadata <- xlsx::read.xlsx("/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx", 
                                  row.names = 1, sheetIndex = 1)
      covariables <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/TRANSFORMED_COVARIABLES/ArcSin/TDP/ArcSin_FTD_TDP_neuropath_SOM")
      
      # Merge metadata
      covariables$X <- gsub("long", "", covariables$X)
      A$Sample_clean <- gsub("^X", "", A@meta.data$Sample)
      metadata_df <- as.data.frame(metadata)
      metadata_df$Sample_clean <- rownames(metadata_df)
      
      meta_joined <- A@meta.data %>%
        mutate(Sample_clean = gsub("^X", "", Sample)) %>%
        left_join(metadata_df, by = "Sample_clean") %>%
        left_join(covariables, by = c("Sample_clean" = "X"))
      
      rownames(meta_joined) <- colnames(A)
      A@meta.data <- meta_joined

      # Align rownames
      if (!all(rownames(A@meta.data) == colnames(A))) {
        rownames(A@meta.data) <- colnames(A)
      }
      
      # Ensure WGCNA results are present
      if (!"pseudobulk" %in% names(A@misc)) stop("WGCNA results not found in @misc$pseudobulk for ", CS)
      
      # Remove outlier
      outlier <- "7BLACK"
      if (outlier %in% colnames(A)) {
        A <- subset(A, cells = setdiff(colnames(A), outlier))
        rownames(A@meta.data) <- colnames(A)
      }
      
      # Ensure numeric trait
      A@meta.data$TDP43b <- as.numeric(as.character(A@meta.data$TDP43b))
      if (all(is.na(A@meta.data$TDP43b))) stop("TDP43b column is all NA for ", CS)
      
      # Calculate module eigengenes inside Seurat object
      MEs <- hdWGCNA::GetMEs(A, wgcna_name = "pseudobulk")
      A@misc$pseudobulk$MEs <- MEs
      
      # Check MEs exist
      if (is.null(A@misc$pseudobulk$MEs)) stop("No MEs found in object for ", CS)
      
      # Run Module-Trait correlation
      cor_results <- hdWGCNA::ModuleTraitCorrelation(
        seurat_obj = A,
        traits = "TDP43b",
        wgcna_name = "pseudobulk"
      )
      
      # Extract correlation dataframe safely
      cor_df <- GetModuleTraitCorrelation(cor_results)
      
      # Sort correlations
      # Extract correlations for 'all_cells'
      cor_vec <- cor_df$cor$all_cells
      pval_vec <- cor_df$pval$all_cells
      fdr_vec <- cor_df$fdr$all_cells
      
      # Convert to data frame
      cor_df_clean <- data.frame(
        module = names(cor_vec),
        cor = as.numeric(cor_vec),
        p.value = as.numeric(pval_vec),
        fdr = as.numeric(fdr_vec)
      )
      
      # Sort by absolute correlation and then p-value
      library(dplyr)
      cor_df_sorted <- cor_df_clean %>%
        arrange(desc(abs(cor)), p.value)
      
      # Save results
      outdir <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/EGG_VS_COV/FTLD/TDP/CS_asin_moduletraitcorrelation_tdp43b_tdp/"
      if (!dir.exists(outdir)) dir.create(outdir, recursive = TRUE)
      write.csv(cor_df_sorted, file = paste0(outdir, CS, ".csv"), row.names = FALSE)      
      # Cleanup
      rm(A, metadata, covariables, 
         cor_vec, pval_vec, fdr_vec,
         cor_df_sorted, cor_results, cor_df, cor_df_clean); gc()
      message("Finished processing CS: ", CS)
      
#      sink(log_file, append = TRUE); cat(Sys.time(), " - Finished: ", CS, "\n"); sink()
      
    }, error = function(e) {
#      sink(log_file, append = TRUE)
      cat(Sys.time(), "ERROR in ", CS, ": ", conditionMessage(e), "\n")
#      sink()
      message("Error in CS: ", CS, " → ", conditionMessage(e))
    })
  }
}



############################## Correlation MEs VS Covariables ###############################

# C9 

# Must change the covariable name for each case.

library(hdWGCNA)
library(dplyr)
library(Seurat)
library(xlsx)

CS <- list.dirs("/media/jaumatell/datos/URI/BAYESPRISM_12_3/hdWGCNA/FTLD/c9/CS_0.25_npcs2/", full.names = FALSE, recursive = FALSE)[1]

for (CS in list.dirs("/media/jaumatell/datos/URI/BAYESPRISM_12_3/hdWGCNA/FTLD/c9/CS_0.25_npcs2/", 
                     full.names = FALSE, recursive = FALSE)) {
  if (file.exists(paste0("/media/jaumatell/datos/URI/BAYESPRISM_12_3/hdWGCNA/FTLD/c9/CS_0.25_npcs2/", CS, "/", CS, "_seurat.rds"))) {
    
    tryCatch({
      
      message("Processing CS: ", CS)
      #      sink(log_file, append = TRUE); cat(Sys.time(), " - Processing: ", CS, "\n"); sink()
      
      # Load Seurat object
      A <- readRDS(paste0("/media/jaumatell/datos/URI/BAYESPRISM_12_3/hdWGCNA/FTLD/c9/CS_0.25_npcs2/", CS, "/", CS, "_seurat.rds"))
      
      # Load metadata
      metadata <- xlsx::read.xlsx("/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx", 
                                  row.names = 1, sheetIndex = 1)
      covariables <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/TRANSFORMED_COVARIABLES/ArcSin/C9/ArcSin_FTD_C9_neuropath_SOM.csv")
      
      # Merge metadata
      covariables$X <- gsub("X", "", covariables$X)
      A$Sample_clean <- gsub("^X", "", A@meta.data$Sample)
      metadata_df <- as.data.frame(metadata)
      metadata_df$Sample_clean <- rownames(metadata_df)
      
      meta_joined <- A@meta.data %>%
        mutate(Sample_clean = gsub("^X", "", Sample)) %>%
        left_join(metadata_df, by = "Sample_clean") %>%
        left_join(covariables, by = c("Sample_clean" = "X"))
      
      rownames(meta_joined) <- colnames(A)
      A@meta.data <- meta_joined
      
      # Align rownames
      if (!all(rownames(A@meta.data) == colnames(A))) {
        rownames(A@meta.data) <- colnames(A)
      }
      
      # Ensure WGCNA results are present
      if (!"pseudobulk" %in% names(A@misc)) stop("WGCNA results not found in @misc$pseudobulk for ", CS)
      
      # Remove outlier
      outlier <- ""
      if (outlier %in% colnames(A)) {
        A <- subset(A, cells = setdiff(colnames(A), outlier))
        rownames(A@meta.data) <- colnames(A)
      }
      
      # Ensure numeric trait
      # A@meta.data$TDP43b <- as.numeric(as.character(A@meta.data$TDP43b))
      # if (all(is.na(A@meta.data$TDP43b))) stop("TDP43b column is all NA for ", CS)
      
      # Calculate module eigengenes inside Seurat object
      MEs <- hdWGCNA::GetMEs(A, wgcna_name = "pseudobulk")
      A@misc$pseudobulk$MEs <- MEs
      
      # Check MEs exist
      if (is.null(A@misc$pseudobulk$MEs)) stop("No MEs found in object for ", CS)
      
      # Run Module-Trait correlation
      cor_results <- hdWGCNA::ModuleTraitCorrelation(
        seurat_obj = A,
        traits = "pTDP43",
        wgcna_name = "pseudobulk"
      )
      
      # Extract correlation dataframe safely
      cor_df <- GetModuleTraitCorrelation(cor_results)
      
      # Sort correlations
      # Extract correlations for 'all_cells'
      cor_vec <- cor_df$cor$all_cells
      pval_vec <- cor_df$pval$all_cells
      fdr_vec <- cor_df$fdr$all_cells
      
      # Convert to data frame
      cor_df_clean <- data.frame(
        module = names(cor_vec),
        cor = as.numeric(cor_vec),
        p.value = as.numeric(pval_vec),
        fdr = as.numeric(fdr_vec)
      )
      
      # Sort by absolute correlation and then p-value
      library(dplyr)
      cor_df_sorted <- cor_df_clean %>%
        arrange(desc(abs(cor)), p.value)
      
      # Save results
      outdir <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/EGG_VS_COV/FTLD/C9/CS_Moduletraitcorrelations_Asin_pTDP43/"
      if (!dir.exists(outdir)) dir.create(outdir, recursive = TRUE)
      write.csv(cor_df_sorted, file = paste0(outdir, CS, ".csv"), row.names = FALSE)      
      # Cleanup
      rm(A, metadata, covariables, 
         cor_vec, pval_vec, fdr_vec,
         cor_df_sorted, cor_results, cor_df, cor_df_clean); gc()
      message("Finished processing CS: ", CS)
      
      #      sink(log_file, append = TRUE); cat(Sys.time(), " - Finished: ", CS, "\n"); sink()
      
    }, error = function(e) {
      #      sink(log_file, append = TRUE)
      cat(Sys.time(), "ERROR in ", CS, ": ", conditionMessage(e), "\n")
      #      sink()
      message("Error in CS: ", CS, " → ", conditionMessage(e))
    })
  }
}
```

```{r code_9_correlation_modules_old_9_correlations_of_modules_c9_and_tdp_r, eval=FALSE}
library(dplyr)
library(xlsx)
library(Seurat)
library(hdWGCNA)
# TDP
all_correlations <- list()

# Recorrem els directoris
for (CS in list.dirs("/media/jaumatell/datos/URI/BAYESPRISM_12_3/hdWGCNA/FTLD/TDP/CS_bo_ambhubs/", 
                     full.names = FALSE, recursive = FALSE)) {
  try({
    message("Processant: ", CS)
    
    # Carreguem objecte Seurat
    A <- readRDS(paste0("/media/jaumatell/datos/URI/BAYESPRISM_12_3/hdWGCNA/FTLD/TDP/CS_bo_ambhubs/", 
                        CS, "/", CS, "_seurat.rds"))
    
    # Metadata bulk i covariables
    metadata <- xlsx::read.xlsx("/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx", 
                                sheetIndex = 1)
    rownames(metadata) <- metadata[,1]
    metadata <- metadata[,-1]
    
    covariables <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/FTD_TDP_neuropath_SOM.csv")
    covariables$X <- gsub("long", "", covariables$X)
    
    # Selecció de mostres TDP
    selection <- rownames(metadata[metadata$group.ID == "TDP", , drop = FALSE])
    
    # Afegim columna Sample_clean
    A$Sample_clean <- gsub("X", "", A@meta.data$Sample)
    metadata_df <- as.data.frame(metadata)
    metadata_df$Sample_clean <- rownames(metadata_df)
    
    meta_joined <- A@meta.data %>%
      mutate(Sample_clean = gsub("^X", "", Sample)) %>%
      left_join(metadata_df, by = "Sample_clean") %>%
      left_join(covariables, by = c("Sample_clean" = "X"))
    
    # Afegim l’expressió dels gens d’interès
    expr <- FetchData(A, vars = c("STMN2", "TDP43b"))
    meta_joined <- cbind(meta_joined, expr)
    A@meta.data <- meta_joined
    
    # Eigengenes
    MEs <- hdWGCNA::GetMEs(A)
    MEs <- MEs[match(selection, gsub("X", "",rownames(MEs))), , drop = FALSE]
    
    # Correlacions
    CS_cor_list <- list()
    for (marker in c("STMN2", "TDP43b")) {
      if (!marker %in% colnames(meta_joined)) {
        warning("Marker ", marker, " no trobat a meta_joined per ", CS)
        next
      }
      y <- meta_joined[match(selection, gsub("X","",rownames(meta_joined))), marker]
      if (all(is.na(y))) {
        warning("Marker ", marker, " tot NA per ", CS)
        next
      }
      
      cor_results <- apply(MEs, 2, function(module) {
        cor.test(module, y)
      })
      
      cor_df <- data.frame(
        module = names(cor_results),
        cor = sapply(cor_results, function(x) x$estimate),
        p.value = sapply(cor_results, function(x) x$p.value),
        cell = CS,
        neuropath_marker = marker
      )
      CS_cor_list[[marker]] <- cor_df
    }
    
    # Combina i guarda
    if (length(CS_cor_list) > 0) {
      cor_df_combined <- bind_rows(CS_cor_list)
      
      outdir <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/EGG_VS_COV/FTLD/TDP/CS_bo_ambhubs2/"
      dir.create(outdir, recursive = TRUE, showWarnings = FALSE)
      
      write.csv(cor_df_combined,
                file = paste0(outdir, CS, ".csv"),
                row.names = FALSE)
      
      all_correlations[[CS]] <- cor_df_combined
    }
  })
}

# Guardem totes les correlacions juntes
if (length(all_correlations) > 0) {
  all_cor_df <- bind_rows(all_correlations)
  write.csv(all_cor_df, "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/EGG_VS_COV/FTLD/TDP/TDP_CS_combined_correlations.csv", row.names = FALSE)
}

# C9


all_correlations <- list()

for (CS in list.dirs("/media/jaumatell/datos/URI/BAYESPRISM_12_3/hdWGCNA/FTLD/c9/CS_0.25_npcs2/", full.names = FALSE, recursive = FALSE)) {
  try({
    A <- readRDS(paste0("/media/jaumatell/datos/URI/BAYESPRISM_12_3/hdWGCNA/FTLD/c9/CS_0.25_npcs2/",CS,"/",CS,"_seurat.rds"))
    
    metadata <- xlsx::read.xlsx("/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx", row.names = 1, sheetIndex = 1)
    covariables <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/FTD_C9_neuropath_SOM.csv")
    
    covariables$X <- gsub("X", "", covariables$X)
    A$Sample_clean <- gsub("X", "", A@meta.data$Sample)
    
    metadata_df <- as.data.frame(metadata)
    metadata_df$Sample_clean <- rownames(metadata_df)
    
    meta_joined <- A@meta.data %>%
      mutate(Sample_clean = gsub("^X", "", Sample)) %>%
      left_join(metadata_df, by = "Sample_clean") %>%
      left_join(covariables, by = c("Sample_clean" = "X"))
    
    A@meta.data <- meta_joined
    MEs <- hdWGCNA::GetMEs(A)
    
    # Store all marker correlations for this CS
    CS_cor_list <- list()
    
    for (marker in c("STMN2", "ACSL3", "lncRNA", "polyGP", "polyGA", "polyGR", "pTDP43", "fociSENSE", "fociANTI")) {
      cor_results <- apply(MEs, 2, function(module) {
        cor.test(module, as.numeric(meta_joined[, marker]))
      })
      
      cor_df <- data.frame(
        module = names(cor_results),
        cor = sapply(cor_results, function(x) x$estimate),
        p.value = sapply(cor_results, function(x) x$p.value),
        cell = CS,
        neuropath_marker = marker
      )
      
      CS_cor_list[[marker]] <- cor_df
    }
    
    # Combine all marker results for this CS
    cor_df_combined <- bind_rows(CS_cor_list)
    
    # Save per CS
    dir.create(paste0("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/EGG_VS_COV/FTLD/C9/CS_bo/"), recursive = TRUE)
    write.csv(cor_df_combined,
              file = paste0("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/EGG_VS_COV/FTLD/C9/CS_bo/",CS,".csv"),
              row.names = FALSE)
    
    # Append to master list
    all_correlations[[CS]] <- cor_df_combined
  })
}

# Optional: Save all correlations across all CSs in one file
all_cor_df <- bind_rows(all_correlations)
write.csv(all_cor_df, "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/EGG_VS_COV/FTLD/C9/C9_CS_combined_correlations.csv", row.names = FALSE)
```

```{r code_9_correlation_modules_resum_correlacions_moduls_r, eval=FALSE}
A <-read.delim("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CELL_PROP/FTLD/TDP/significatives_nonparametric_with_means_cs.tsv")



# Defineix el directori on tens els fitxers
directori <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/EGG_VS_COV/FTLD/TDP/CS/TDP43"  

# Llista de fitxers (assumint que són .tsv o .csv, adapta segons calgui)
fitxers <- list.files(path = directori, pattern = "\\.txt$|\\.tsv$|\\.csv$", full.names = TRUE)

# Inicialitza una llista per guardar els resultats
resultats <- data.frame(
  fitxer = character(),
  pvalue_significatius = integer(),
  total_files = integer(),
  stringsAsFactors = FALSE
)

# Itera sobre cada fitxer
for (fitxer in fitxers) {
  # Llegeix el fitxer (ajusta el separador si cal)
  taula <- read.csv(fitxer, header = TRUE)
  
  # Compta les files amb p.value < 0.05
  significatius <- sum(taula$p.value < 0.05, na.rm = TRUE)
  
  # Compta el total de files
  total <- nrow(taula)
  
  # Afegeix a la taula de resultats
  resultats <- rbind(resultats, data.frame(
    fitxer = basename(fitxer),
    pvalue_significatius = significatius,
    total_files = total,
    stringsAsFactors = FALSE
  ))
}

# Mostra el resultat
print(resultats)
write.csv(resultats, file = "/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/EGG_VS_COV/FTLD/TDP/CS/resum_resultats_TDP43.csv", row.names = FALSE)



# Defineix el directori on hi ha les carpetes de cell states
directori_base <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/hdWGCNA/FTLD/TDP/CS"  # Canvia això per la teva ruta

# Llista de subcarpetes (cell states)
cell_states <- list.dirs(path = directori_base, recursive = FALSE, full.names = TRUE)

# Inicialitza la taula de resultats
resultats <- data.frame(
  cell_state = character(),
  pvalue_significatius = integer(),
  total_moduls = integer(),
  stringsAsFactors = FALSE
)

# Itera per cada carpeta de cell state
for (carpeta in cell_states) {
  fitxer <- file.path(carpeta, "MODULES/cor_summary.csv")
  
  if (file.exists(fitxer)) {
    # Llegeix l’arxiu
    taula <- read.csv(fitxer, header = TRUE)
    
    # Compta mòduls significatius
    significatius <- sum(taula$p.value < 0.05, na.rm = TRUE)
    
    # Compta mòduls totals
    total <- nrow(taula)
    
    # Nom del cell state (nom de la carpeta)
    cell_state_nom <- basename(carpeta)
    
    # Afegeix-ho a la taula de resultats
    resultats <- rbind(resultats, data.frame(
      cell_state = cell_state_nom,
      pvalue_significatius = significatius,
      total_moduls = total,
      stringsAsFactors = FALSE
    ))
  }
}

# Guarda el resultat en un CSV
write.csv(resultats, file = "/media/jaumatell/datos/URI/BAYESPRISM_12_3/hdWGCNA/FTLD/TDP/resum_correlacio_moduls_Healthy_vs_ctrl_CS.csv", row.names = FALSE)


# Defineix el directori base amb les carpetes de tipus cel·lular
directori_base <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/EDGER/NEW/CS"  # Substitueix amb la ruta correcta

# Llista de subcarpetes (tipus cel·lular)
carpetes <- list.dirs(path = directori_base, recursive = FALSE, full.names = TRUE)

# Inicialitza la taula de resultats
resultats <- data.frame(
  tipus_cellular = character(),
  n_positius = integer(),
  n_negatius = integer(),
  stringsAsFactors = FALSE
)

# Itera per cada carpeta
for (carpeta in carpetes) {
  fitxer <- file.path(carpeta, "FTLD/results_adj_h.csv")
  
  if (file.exists(fitxer)) {
    # Llegeix el fitxer
    taula <- read.csv(fitxer, header = TRUE)
    
    # Compta valors 1 i -1 en la columna "X1.FTLD..1.Control"
    positius <- sum(taula$X1.FTLD..1.Control == 1, na.rm = TRUE)
    negatius <- sum(taula$X1.FTLD..1.Control == -1, na.rm = TRUE)
    
    # Nom del tipus cel·lular (nom de la carpeta)
    nom_cell <- basename(carpeta)
    
    # Afegeix a la taula de resultats
    resultats <- rbind(resultats, data.frame(
      tipus_cellular = nom_cell,
      n_positius = positius,
      n_negatius = negatius,
      stringsAsFactors = FALSE
    ))
  }
}

# Guarda el resultat en un fitxer CSV
write.csv(resultats, file = "/media/jaumatell/datos/URI/BAYESPRISM_12_3/EDGER/NEW/CS/resum_resultats_up_down.csv", row.names = FALSE)


###### VOLCANOPLOTS
library(ggplot2)
library(EnhancedVolcano)
library(tidyverse)

results_dir <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/EDGER/FTLD/TDP/CS"
output_dir <- file.path(results_dir, "volcano_plots")
dir.create(output_dir, showWarnings = FALSE)

files <- list.files(results_dir, pattern = "results_adj_h\\.csv$", full.names = TRUE, recursive = TRUE)

for (file in files) {
  file_base <- basename(dirname(file))
  df <- tryCatch({
    read_csv(file, show_col_types = FALSE)
  }, error = function(e) {
    warning(paste("Error reading", file, ":", e$message))
    return(NULL)
  })
  if (is.null(df)) next
  colnames(df) <- c("Gene", "logFC", "logCPM", "LR", "PValue", "adj_pval", "TDP_vs_Healthy")
  required_cols <- c("logFC", "PValue", "adj_pval", "Gene")
  if (!all(required_cols %in% colnames(df))) {
    warning(paste("Skipping", file, "- missing required columns"))
    next
  }
  df$Gene <- as.character(df$Gene)
  p <- EnhancedVolcano(df,
                       lab = df$Gene,
                       x = 'logFC',
                       y = 'PValue',
                       title = paste("Volcano Plot -", file_base),
                       pCutoff = 0.05,
                       FCcutoff = 0,
                       pointSize = 2.5,
                       labSize = 3.5,
                       selectLab = df$Gene)
  ggsave(filename = file.path(output_dir, paste0(file_base, "_volcano.png")),
         plot = p, width = 8, height = 6, dpi = 300)
}

####################### VENN DIAGRAM OVERLAP 


# Install necessary packages if not already installed
packages <- c("eulerr", "patchwork", "purrr")
install_if_missing <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(install_if_missing)) install.packages(install_if_missing)

# Load libraries
library(eulerr)
library(patchwork)
library(purrr)

# Sample data frame with group-wise counts
predf <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/OVERLAP/TDP/CS/Validation_results_cs_FTLD_NEW.csv")
df <- data.frame(
  Group = predf$X,
  Healthy = predf$Upregulated.Nou,           # Total Healthy in each group
  FTLD_TDP = predf$Upregulated.FTLD_TDP,           # Total FTLD-TDP in each group
  Common = predf$CU.FTLD...Nou              # Overlap between Healthy and FTLD-TDP
)

# Generate Euler diagrams for each group
plots <- pmap(df, function(Group, Healthy, FTLD_TDP, Common) {
  fit <- euler(c(
    "Pottier" = Healthy - Common,
    "Sant Pau" = FTLD_TDP - Common,
    "Common genes" = Common
  ))
  
  plot(fit,
       main = Group,
       fills = list(fill = c("#1b9e77", "#d95f02"), alpha = 0.6),
       quantities = TRUE)
})

# Combine all plots using patchwork (like facet_wrap)
wrap_plots(plots) + plot_annotation(title = "Faceted Venn Diagrams by Group")
```

```{r fig_9_correlation_modules_1, echo=FALSE, eval=FALSE}
# knitr::include_graphics("figures/fig_9_correlation_modules_1.png")
```

```{r fig_9_correlation_modules_2, echo=FALSE, eval=FALSE}
# knitr::include_graphics("figures/fig_9_correlation_modules_2.png")
```

## 10. VALIDATION

Validate overlap between hdWGCNA modules across cohorts using Jaccard similarity analyses.

Scripts included in this step:

-   `10. VALIDATION/Jaccard test for C9 and TDP43.R`

```{r code_10_validation_jaccard_test_for_c9_and_tdp43_r, eval=FALSE}
# JACCARD 
library("openxlsx")
library("GeneOverlap")
library("VennDiagram")
library("grid")

# Define functions
# Jaccard similarity index
jaccard_similarity <- function(list1, list2) {
  intersection_size <- length(intersect(list1, list2))
  union_size <- length(union(list1, list2))
  return(intersection_size / union_size)
}

# Perform permutation test for p-value
permutation_test <- function(list1, list2, n_permutations = 10000) {
  observed_jaccard <- jaccard_similarity(list1, list2)
  
  permuted_jaccards <- replicate(n_permutations, {
    permuted_list1 <- sample(list1)
    permuted_list2 <- sample(list2)
    jaccard_similarity(permuted_list1, permuted_list2)
  })
  p_value <- mean(permuted_jaccards >= observed_jaccard)
  return(p_value)
}

hypergeometric_test <- function(list1, list2, total_population_size) {
  intersection_size <- length(intersect(list1, list2))
  total_genes <- total_population_size  # Total number of possible genes
  
  # Number of DEGs in list1 and list2
  K1 <- length(list1)
  K2 <- length(list2)
  
  # Hypergeometric test to calculate p-value
  p_value <- phyper(intersection_size - 1, K1, total_genes - K1, K2, lower.tail = FALSE)
  
  return(p_value)
}


# TDP43

# Define variables
CStates <- c(
  "Arterial", "DISC1_RELN", "Pericyte", "SMC", "TLE4_CCBE1",
  "Capillary", "GFAP-neg", "PVALB_CEMIP", "SST_ADAMTS19", "TLE4_MEGF11",
  "CDH4_CCK", "GFAP-pos", "PVALB_MYBPC1", "SST_BRINP3", "TLE4_SEMA3D",
  "CDH4_SCGN", "LAMP5_CA3", "PVALB_PTHLH", "SST_GALNT14", "VAT1L_EYA4",
  "CLMP_KCNMA1", "LAMP5_PMEPA1", "RORB_ADGRL4", "SST_NPY", "Venous",
  "CLMP_PDGFRA", "Micro", "RORB_FOXO1", "VIP_CLSTN2",
  "CUX2_RASGRF2", "Oligo", "RORB_LRRK1", "T_Cell", "VIP_HTR2C",
  "CUX2_RORB", "OPC", "RORB_POU3F2", "THEMIS_NR4A2", "VIP_LAMA3",
  "DISC1_CCK", "PCP4_NXPH2", "SCN4B_NEFH", "THEMIS_TMEM233"
)

FTLD_TDP <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/EDGER/FTLD/TDP/CS_LRT/"
NOU <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/EDGER/NEW/CS_SVcorrect/"
RESULTS_PATH <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/OVERLAP/TDP_NEW/CS_Correcte"

# Generate output dataframe
Results <- data.frame(matrix(ncol = length(CStates), nrow = 10))
colnames(Results) <- CStates
rownames(Results) <- c(
  "Upregulated FTLD_TDP", "Upregulated Nou", 
  "Downregulated FTLD_TDP", "Downregulated Nou",
  "CU FTLD – Nou", "CD FTLD – Nou", 
  "JU FTLD – Nou", "JD FTLD – Nou",
  "GU FTLD – Nou", "GD FTLD – Nou")

# Iterate to obtain the results for each case.
for (i in seq_along(CStates)) {
  CS <- CStates[i]
    # Read data
  if (file.exists(paste0(FTLD_TDP, CS ,"/", "TDP/results_adj_h.csv"))){
    ftld_tdp <- read.csv(paste0(FTLD_TDP, CS ,"/", "TDP/results_adj_h.csv"))
  } else {
    ftld_tdp <- c()
  }
  
  if (file.exists(paste0(NOU,CS,"/" ,"TDP/results_adj_h.csv"))){
    nou <- read.csv(paste0(NOU,CS,"/" ,"TDP/results_adj_h.csv"))
  } else {
    nou <- c()
  }
  
  # Extract DEG

  # For U_ftld
  if (is.null(ftld_tdp$X[ftld_tdp$X1.TDP..1.Healthy == 1])) {
    U_ftld <- character(0)  # Assign an empty vector if NULL
  } else {
    U_ftld <- ftld_tdp$X[ftld_tdp$X1.TDP..1.Healthy == 1]
  }
  
  # For U_nou
  if (is.null(nou$X[nou$X.1.Control.1.TDP == 1])) {
    U_nou <- character(0)  # Assign an empty vector if NULL
  } else {
    U_nou <- nou$X[nou$X.1.Control.1.TDP == 1]
  }
  
  # For D_ftld
  if (is.null(ftld_tdp$X[ftld_tdp$X1.TDP..1.Healthy == -1])) {
    D_ftld <-character(0)  # Assign an empty vector if NULL
  } else {
    D_ftld <- ftld_tdp$X[ftld_tdp$X1.TDP..1.Healthy == -1]
  }
  
  # For D_nou
  if (is.null(nou$X[nou$X.1.Control.1.TDP == -1])) {
    D_nou <-character(0) # Assign an empty vector if NULL
  } else {
    D_nou <- nou$X[nou$X.1.Control.1.TDP == -1]
  }
  
  # OVERLAP GENES
  C_U_ftld_nou <- intersect(U_ftld, U_nou)
  C_D_ftld_nou <- intersect(D_ftld, D_nou)

  # SIMILARITY INDEX
  Ujaccard13 <- jaccard_similarity(U_ftld, U_nou)
  Djaccard13 <- jaccard_similarity(D_ftld, D_nou)

  # HIPERGEOMETRIC TESTS
  total_genes_FN <- length(unique(c(ftld_tdp$X, nou$X)))

  # Gene Overlap
  GU_13 = testGeneOverlap(newGeneOverlap(U_ftld, U_nou, total_genes_FN))@pval
  GD_13 = testGeneOverlap(newGeneOverlap(D_ftld, D_nou, total_genes_FN))@pval

  # UPDATE RESULTS TABLE WITH THE CALCULATED VALUES.
  Results["Upregulated FTLD_TDP", CS] <- length(U_ftld)
  Results["Upregulated Nou", CS] <- length(U_nou)
  Results["Downregulated FTLD_TDP", CS] <- length(D_ftld)
  Results["Downregulated Nou", CS] <- length(D_nou)
  Results["CU FTLD – Nou", CS] <- length(C_U_ftld_nou)
  Results["CD FTLD – Nou", CS] <- length(C_D_ftld_nou)
  Results["JU FTLD – Nou", CS] <- Ujaccard13
  Results["JD FTLD – Nou", CS] <- Djaccard13
  Results["GU FTLD – Nou", CS] <- GU_13
  Results["GD FTLD – Nou", CS] <- GD_13
  
}
Results <- t(Results)
View(Results)
View(Results[rowSums(Results[, 1:4]) > 0, ])

write.csv(Results, file = paste0(RESULTS_PATH, "/TDP43_Validation_results_cs.csv"))



# C9

FTLD_TDP <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/EDGER/FTLD/C9/CS_SV/"
NOU <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/EDGER/RIMOD/CS_SV/"
RESULTS_PATH <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/OVERLAP/C9_NEW/CS"

# Generate output dataframe
Results <- data.frame(matrix(ncol = length(CStates), nrow = 10))
colnames(Results) <- CStates
rownames(Results) <- c(
  "Upregulated FTLD_TDP", "Upregulated Rimod", 
  "Downregulated FTLD_TDP", "Downregulated Rimod",
  "CU FTLD – Rimod", "CD FTLD – Rimod", 
  "JU FTLD – Rimod", "JD FTLD – Rimod",
  "GU FTLD – Rimod", "GD FTLD – Rimod")

# Iterate to obtain the results for each case.
for (i in seq_along(CStates)) {
  CS <- CStates[i]
  # Read data
  if (file.exists(paste0(FTLD_TDP, CS ,"/", "C9orf72/results_adj_h.csv"))){
    ftld_tdp <- read.csv(paste0(FTLD_TDP, CS ,"/", "C9orf72/results_adj_h.csv"))
  } else {
    ftld_tdp <- c()
  }
  
  if (file.exists(paste0(NOU,CS,"/" ,"C9orf72/results_adj_h.csv"))){
    nou <- read.csv(paste0(NOU,CS,"/" ,"C9orf72/results_adj_h.csv"))
  } else {
    nou <- c()
  }
  
  # Extract DEG
  
  # For U_ftld
  if (is.null(ftld_tdp$X[ftld_tdp$X.1.Healthy.1.C9orf72 == 1])) {
    U_ftld <- character(0)  # Assign an empty vector if NULL
  } else {
    U_ftld <- ftld_tdp$X[ftld_tdp$X.1.Healthy.1.C9orf72 == 1]
  }
  
  # For U_nou
  if (is.null(nou$X[nou$X.1.Healthy.1.C9orf72 == 1])) {
    U_nou <- character(0)  # Assign an empty vector if NULL
  } else {
    U_nou <- nou$X[nou$X.1.Healthy.1.C9orf72 == 1]
  }
  
  # For D_ftld
  if (is.null(ftld_tdp$X[ftld_tdp$X.1.Healthy.1.C9orf72 == -1])) {
    D_ftld <-character(0)  # Assign an empty vector if NULL
  } else {
    D_ftld <- ftld_tdp$X[ftld_tdp$X.1.Healthy.1.C9orf72 == -1]
  }
  
  # For D_nou
  if (is.null(nou$X[nou$X.1.Healthy.1.c9orf72 == -1])) {
    D_nou <-character(0) # Assign an empty vector if NULL
  } else {
    D_nou <- nou$X[nou$X.1.Healthy.1.C9orf72 == -1]
  }
  
  # OVERLAP GENES
  C_U_ftld_nou <- intersect(U_ftld, U_nou)
  C_D_ftld_nou <- intersect(D_ftld, D_nou)
  
  # SIMILARITY INDEX
  Ujaccard13 <- jaccard_similarity(U_ftld, U_nou)
  Djaccard13 <- jaccard_similarity(D_ftld, D_nou)
  
  # HIPERGEOMETRIC TESTS
  total_genes_FN <- length(unique(c(ftld_tdp$X, nou$X)))
  
  # Gene Overlap
  GU_13 = testGeneOverlap(newGeneOverlap(U_ftld, U_nou, total_genes_FN))@pval
  GD_13 = testGeneOverlap(newGeneOverlap(D_ftld, D_nou, total_genes_FN))@pval
  
  # UPDATE RESULTS TABLE WITH THE CALCULATED VALUES.
  Results["Upregulated FTLD_TDP", CS] <- length(U_ftld)
  Results["Upregulated Rimod", CS] <- length(U_nou)
  Results["Downregulated FTLD_TDP", CS] <- length(D_ftld)
  Results["Downregulated Rimod", CS] <- length(D_nou)
  Results["CU FTLD – Rimod", CS] <- length(C_U_ftld_nou)
  Results["CD FTLD – Rimod", CS] <- length(C_D_ftld_nou)
  Results["JU FTLD – Rimod", CS] <- Ujaccard13
  Results["JD FTLD – Rimod", CS] <- Djaccard13
  Results["GU FTLD – Rimod", CS] <- GU_13
  Results["GD FTLD – Rimod", CS] <- GD_13
  
}
Results <- t(Results)
View(Results)
View(Results[rowSums(Results[, 1:4]) > 0, ])
write.csv(Results, file = paste0(RESULTS_PATH, "/C9_Validation_results_cs.csv"))
```

```{r fig_10_validation_1, echo=FALSE, eval=FALSE}
# knitr::include_graphics("figures/fig_10_validation_1.png")
```

```{r fig_10_validation_2, echo=FALSE, eval=FALSE}
# knitr::include_graphics("figures/fig_10_validation_2.png")
```

## Additional Repository Scripts

Scripts not covered in the numbered workflow are listed here for completeness.

Scripts included in this step:

-   `CORRELATION PLOTS RETREAT.R`

```{r code_correlation_plots_retreat_r, eval=FALSE}


##### CELL PROP DIF PLOT
######################################################################
## 
# metadatas
SP_metadata <- readxl::read_xlsx("/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx")
case_legend <- read.delim("/media/jaumatell/datos/URI/BAYESPRISM_12_3/NEW_BULK/METADATA/Sample_info.txt", sep =  "\t", row.names = 1)
case_legend <- case_legend[case_legend$GROUP != "FTLD-TDP-C",]
case_legend$GROUP[case_legend$GROUP != "Control"] <- "TDP"

# RORB_LRRK1 (Sant pau)
sp1<-read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/TDP/theta.state_original.csv", row.names = 1)

# RORB_LRRK1 (Validació)
n1<-read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/NEW/theta.state_cellstate.csv", row.names = 1)

# NPTX2 (Sant pau)
sp2<-read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/TDP/CELL STATE ORIGINAL/RORB_LRRK1.csv", row.names = 1)

# NPTX2 (Validació)
n2<-read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/NEW/CELL STATE ORIGINAL/RORB_LRRK1.csv", row.names = 1)




# Match metadata and sample order
sp1_ids <- gsub("X", "", rownames(sp1))
SP_metadata_filtered <- SP_metadata[SP_metadata$sample.ID %in% sp1_ids, ]
SP_metadata_filtered <- SP_metadata_filtered[match(sp1_ids, SP_metadata_filtered$sample.ID), ]
Pheno <- SP_metadata_filtered$group.ID
Pheno[Pheno == "Healthy"] <- "Control"

# List of target cell states to visualize
target_cell_states <- c("GFAP.pos", "PVALB_PTHLH", "LAMP5_PMEPA1", "PVALB_CEMIP")
nice_names <- c("GFAP+", "PVALB PTHLH", "LAMP5 PMEPA1", "PVALB CEMIP")

# Initialize dataframe
cell_data <- data.frame()

# Loop through each cell type and collect data
for (i in seq_along(target_cell_states)) {
  cell_type <- target_cell_states[i]
  label <- nice_names[i]
  cell_prop <- sp1[rownames(sp1) %in% paste0("X", SP_metadata_filtered$sample.ID), cell_type]
  
  temp_df <- data.frame(
    Phenotype = Pheno,
    Cell_proportion = cell_prop,
    Cell_state = label
  )
  
  cell_data <- rbind(cell_data, temp_df)
}

# Ensure Phenotype is factor and ordered
cell_data$Phenotype <- factor(cell_data$Phenotype, levels = c("Control", "TDP"))

library(dplyr)
library(ggplot2)

# Step 1: Compute max y per facet (cell state)
max_y_per_state <- cell_data %>%
  group_by(Cell_state) %>%
  summarise(y = max(Cell_proportion, na.rm = TRUE) * 0.95)

# Step 2: Create annotation data frame
annotation_df <- data.frame(
  Cell_state = c("GFAP+", "PVALB PTHLH", "LAMP5 PMEPA1", "PVALB CEMIP"),
  label = c(
    "P = 0.003\nFC = 7.62",
    "P = 0.017\nFC = 0.72",
    "P = 0.023\nFC = 0.59",
    "P = 0.030\nFC = 0.62"
  ),
  x = 1.5  # halfway between Control and TDP
)

# Step 3: Merge y positions into annotation df
annotation_df <- left_join(annotation_df, max_y_per_state, by = "Cell_state")

# Step 4: Plot
ggplot(cell_data, aes(x = Phenotype, y = Cell_proportion, fill = Phenotype)) +
  geom_boxplot(size = 0.4, outlier.alpha = 0.3, alpha = 0.5) +
  facet_wrap(~Cell_state, scales = "free", nrow = 1) +
  labs(x = "", y = "Cell type proportion (%)") +
  scale_fill_manual(values = c("Control" = "deepskyblue4", "TDP" = "darkgoldenrod2")) +
  geom_text(data = annotation_df, aes(x = x, y = y, label = label), inherit.aes = FALSE, size = 3.5) +
  theme_bw(base_size = 12) +
  theme(
    strip.text = element_text(face = "bold"),
    axis.title = element_text(size = 12),
    panel.spacing = unit(5, "pt"),
    legend.position = "right"
  )


# C9
# metadatas
SP_metadata <- readxl::read_xlsx("/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx")
case_legend <- read.delim("/media/jaumatell/datos/URI/BAYESPRISM_12_3/NEW_BULK/METADATA/Sample_info.txt", sep =  "\t", row.names = 1)
case_legend <- case_legend[case_legend$GROUP != "FTLD-TDP-C",]
case_legend$GROUP[case_legend$GROUP != "Control"] <- "TDP"

# RORB_LRRK1 (Sant pau)
sp1<-read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/C9/theta.state_cellstate.csv", row.names = 1)

# RORB_LRRK1 (Validació)
n1<-read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/NEW/theta.state_cellstate.csv", row.names = 1)

# NPTX2 (Sant pau)
sp2<-read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/C9/CELL STATE ORIGINAL/RORB_LRRK1.csv", row.names = 1)

# NPTX2 (Validació)
n2<-read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/NEW/CELL STATE ORIGINAL/RORB_LRRK1.csv", row.names = 1)




# Match metadata and sample order
sp1_ids <- gsub("X", "", rownames(sp1))
SP_metadata_filtered <- SP_metadata[SP_metadata$sample.ID %in% sp1_ids, ]
SP_metadata_filtered <- SP_metadata_filtered[match(sp1_ids, SP_metadata_filtered$sample.ID), ]
Pheno <- SP_metadata_filtered$group.ID
Pheno[Pheno == "Healthy"] <- "Control"

# List of target cell states to visualize
target_cell_states <- c("VAT1L_EYA4", "GFAP.pos", "T_Cell", "PVALB_MYBPC1", "RORB_POU3F2")
nice_names <- c("VAT1L EYA4", "GFAP+", "T Cell", "PVALB MYBPC1", "RORB POU3F2")

# Initialize dataframe
cell_data <- data.frame()

# Loop through each cell type and collect data
for (i in seq_along(target_cell_states)) {
  cell_type <- target_cell_states[i]
  label <- nice_names[i]
  cell_prop <- sp1[rownames(sp1) %in% paste0("X", SP_metadata_filtered$sample.ID), cell_type]
  
  temp_df <- data.frame(
    Phenotype = Pheno,
    Cell_proportion = cell_prop,
    Cell_state = label
  )
  
  cell_data <- rbind(cell_data, temp_df)
}

# Ensure Phenotype is factor and ordered
cell_data$Phenotype <- factor(cell_data$Phenotype, levels = c("Control", "C9orf72"))

library(dplyr)
library(ggplot2)

# Step 1: Compute max y per facet (cell state)
max_y_per_state <- cell_data %>%
  group_by(Cell_state) %>%
  summarise(y = max(Cell_proportion, na.rm = TRUE) * 0.95)

# Step 2: Create annotation data frame
annotation_df <- data.frame(
  Cell_state = c("VAT1L EYA4", "GFAP+", "T Cell", "PVALB MYBPC1", "RORB POU3F2"),
  label = c(
    "P = 0.013\nFC = 0.067",
    "P = 0.026\nFC = 202.85",
    "P = 0.033\nFC = 1.24",
    "P = 0.009\nFC = 1.49",
    "P = 0.042\nFC = 0.87"
  ),
  x = 1.5  # halfway between Control and C9
)

# Step 3: Merge y positions into annotation df
annotation_df <- left_join(annotation_df, max_y_per_state, by = "Cell_state")

# Step 4: Plot
ggplot(cell_data, aes(x = Phenotype, y = Cell_proportion, fill = Phenotype)) +
  geom_boxplot(size = 0.4, outlier.alpha = 0.3, alpha = 0.5) +
  facet_wrap(~Cell_state, scales = "free", nrow = 1) +
  labs(x = "", y = "Cell type proportion (%)") +
  scale_fill_manual(values = c("Control" = "deepskyblue4", "C9orf72" = "darkgoldenrod2")) +
  geom_text(data = annotation_df, aes(x = x, y = y, label = label), inherit.aes = FALSE, size = 3.5) +
  theme_bw(base_size = 12) +
  theme(
    strip.text = element_text(face = "bold"),
    axis.title = element_text(size = 12),
    panel.spacing = unit(5, "pt"),
    legend.position = "right"
  )


############################################################################
#
# Load data
A <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/TDP/theta.state_original.csv", row.names = 1)
C <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/FTD_TDP_neuropath_SOM.csv")
C$X <- gsub("long", "X", C$X)
A1 <- A[C$X,]

library(ggpubr)
library(ggplot2)
library(dplyr)
library(tidyr)

# Prepare the data
SP <- data.frame(
  GFAP_pos = A1$GFAP.pos,
  LAMP5_PMEPA1 = A1$LAMP5_PMEPA1,
  RORB_LRRK1 = A1$RORB_LRRK1,
  pTDP43 = C$TDP43b
)

# Convert to long format
SP_long <- SP %>%
  pivot_longer(cols = c(GFAP_pos, LAMP5_PMEPA1, RORB_LRRK1),
               names_to = "cell_type",
               values_to = "proportion")

# Compute Spearman correlations
corr_stats <- SP_long %>%
  group_by(cell_type) %>%
  summarise(
    rho = cor(pTDP43, proportion, method = "spearman", use = "complete.obs"),
    pval = cor.test(pTDP43, proportion, method = "spearman")$p.value
  )

# Format labels
corr_stats$label <- paste0("Rho = ", round(corr_stats$rho, 2), 
                           "\nP = ", signif(corr_stats$pval, 2))

# Set positions for annotation
corr_stats$x <- 0.00007  # adjust as needed
corr_stats$y <- c(0.23, 0.18, 0.13)  # one y per cell type for visual spacing

# Define inverted colors
inverted_colors <- c(
  "GFAP_pos" = "#00BFC4",     # cyan
  "LAMP5_PMEPA1" = "green", 
  "RORB_LRRK1" = "#F8766D"    # red
)

# Plot with annotations
ggplot(SP_long, aes(x = pTDP43, y = proportion, color = cell_type)) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = TRUE) +
  scale_color_manual(values = inverted_colors) +
  theme_minimal(base_size = 14) +
  labs(
    title = "Cell proportion vs pTDP-43 density",
    x = "pTDP-43 density",
    y = "Cell proportion",
    color = "Cell Type"
  ) +
  geom_text(data = corr_stats,
            aes(x = x, y = y, label = label, color = cell_type),
            inherit.aes = FALSE,
            size = 5, hjust = 0, )



# Load required libraries
library(ggplot2)
library(dplyr)
library(tidyr)

# Assume `A` and `C` already read in as before
# A: cell proportions
# C: covariates with STMN2

C$X <- gsub("long", "X", C$X)
A1 <- A[C$X,]

# Build the data
SP_stmn2 <- data.frame(
  TLE4_CCBE1 = A1$TLE4_CCBE1,
  CUX2_RORB = A1$CUX2_RORB,
  DISC1_RELN = A1$DISC1_RELN,
  STMN2 = C$STMN2
)

# Pivot longer for plotting
SP_stmn2_long <- SP_stmn2 %>%
  pivot_longer(cols = c(TLE4_CCBE1, CUX2_RORB, DISC1_RELN),
               names_to = "cell_type",
               values_to = "proportion")

# Calculate Spearman correlations
corr_stats_stmn2 <- SP_stmn2_long %>%
  group_by(cell_type) %>%
  summarise(
    rho = cor(STMN2, proportion, method = "spearman", use = "complete.obs"),
    pval = cor.test(STMN2, proportion, method = "spearman")$p.value
  )

# Create labels
corr_stats_stmn2$label <- paste0("Rho = ", round(corr_stats_stmn2$rho, 2), 
                                 "\nP = ", signif(corr_stats_stmn2$pval, 2))

# Adjust text position manually
corr_stats_stmn2$x <- 0.13
corr_stats_stmn2$y <- c(0.000013, 0.000009, 0.000005)

# Set colors
cell_colors <- c(
  "TLE4_CCBE1" = "#F8766D",
  "CUX2_RORB" = "#00BFC4",
  "DISC1_RELN" = "orchid"
)

# Plot
ggplot(SP_stmn2_long, aes(x = STMN2, y = proportion, color = cell_type)) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = TRUE) +
  scale_color_manual(values = cell_colors) +
  theme_minimal(base_size = 14) +
  labs(
    title = "Cell proportion vs STMN2 expression",
    x = "STMN2 expression",
    y = "Cell proportion",
    color = "Cell Type"
  ) +
  geom_text(data = corr_stats_stmn2,
            aes(x = x, y = y, label = label, color = cell_type),
            inherit.aes = FALSE,
            size = 4, hjust = 0)
#######################################################################################

#C9 cell proportions Corr plots

### ACSL3

# Load data
A <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/C9/theta.state_cellstate.csv", row.names = 1)
C <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/FTD_C9_neuropath_SOM.csv")
C$X <- gsub("long", "X", C$X)
A1 <- A[C$X,]

library(ggpubr)
library(ggplot2)
library(dplyr)
library(tidyr)

# Prepare the data
SP <- data.frame(
  OPC = A1$OPC,
  GFAP_neg = A1$GFAP.neg,
  RORB_ADGRL4 = A1$RORB_ADGRL4,
  RORB_LRRK1 = A1$RORB_LRRK1,
  ACSL3 = C$ACSL3
)

# Convert to long format
SP_long <- SP %>%
  pivot_longer(cols = c(OPC, RORB_ADGRL4, RORB_LRRK1, GFAP_neg),
               names_to = "cell_type",
               values_to = "proportion")

# Compute Spearman correlations
corr_stats <- SP_long %>%
  group_by(cell_type) %>%
  summarise(
    rho = cor(ACSL3, proportion, method = "spearman", use = "complete.obs"),
    pval = cor.test(ACSL3, proportion, method = "spearman")$p.value
  )

# Format labels
corr_stats$label <- paste0("Rho = ", round(corr_stats$rho, 2), 
                           "\nP = ", signif(corr_stats$pval, 2))

# Set positions for annotation
corr_stats$x <- 0.31
corr_stats$y <- c(0.22, 0.17, 0.12, 0.07)  # one per cell type, spaced out



# Define inverted colors
cell_colors <- c(
  "OPC" = "#F8766D",
  "RORB_ADGRL4" = "#00BFC4",
  "RORB_LRRK1" = "orchid",
  "GFAP_neg" = "orange"
)

# Plot with annotations
ggplot(SP_long, aes(x = ACSL3, y = proportion, color = cell_type)) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = TRUE) +
  scale_color_manual(values = cell_colors) +
  theme_minimal(base_size = 14) +
  labs(
    title = "Cell proportion vs pTDP-43 density",
    x = "ACSL3 density",
    y = "Cell proportion",
    color = "Cell Type"
  ) +
  geom_text(data = corr_stats,
            aes(x = x, y = y, label = label, color = cell_type),
            inherit.aes = FALSE,
            size = 5, hjust = 0)



### FociAnti

# Load data
A <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/C9/theta.state_cellstate.csv", row.names = 1)
C <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/FTD_C9_neuropath_SOM.csv")
C$X <- gsub("long", "X", C$X)
A1 <- A[C$X,]

library(ggpubr)
library(ggplot2)
library(dplyr)
library(tidyr)

# Prepare the data
SP <- data.frame(
  PCP4_NXPH2 = A1$PCP4_NXPH2,
  fociAnti = C$fociANTI
)

# Convert to long format
SP_long <- SP %>%
  pivot_longer(cols = c(PCP4_NXPH2),
               names_to = "cell_type",
               values_to = "proportion")

# Compute Spearman correlations
corr_stats <- SP_long %>%
  group_by(cell_type) %>%
  summarise(
    rho = cor(fociAnti, proportion, method = "spearman", use = "complete.obs"),
    pval = cor.test(fociAnti, proportion, method = "spearman")$p.value
  )

# Format labels
corr_stats$label <- paste0("Rho = ", round(corr_stats$rho, 2), 
                           "\nP = ", signif(corr_stats$pval, 2))

# Set positions for annotation
corr_stats$x <- 0.3  # adjust as needed
corr_stats$y <- c(0.00001)  # one y per cell type for visual spacing

# Define inverted colors
inverted_colors <- c(
  "PCP4_NXPH2" = "#00BFC4"     # cyan
)

# Plot with annotations
ggplot(SP_long, aes(x = fociAnti, y = proportion, color = cell_type)) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = TRUE) +
  scale_color_manual(values = inverted_colors) +
  theme_minimal(base_size = 14) +
  labs(
    title = "Cell proportion vs C9 cell proportions",
    x = "fociAnti density",
    y = "Cell proportion",
    color = "Cell Type"
  ) +
  geom_text(data = corr_stats,
            aes(x = x, y = y, label = label, color = cell_type),
            inherit.aes = FALSE,
            size = 5, hjust = 0)


### FociSENSE

# Load data
A <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/C9/theta.state_cellstate.csv", row.names = 1)
C <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/FTD_C9_neuropath_SOM.csv")
C$X <- gsub("long", "X", C$X)
A1 <- A[C$X,]

library(ggpubr)
library(ggplot2)
library(dplyr)
library(tidyr)

# Prepare the data
SP <- data.frame(
  PCP4_NXPH2 = A1$PCP4_NXPH2,
  PVALB_MYBPC1 = A1$PVALB_MYBPC1,
  Pericyte = A1$Pericyte,
  VIP_LAMA3 = A1$VIP_LAMA3,
  capillary = A1$Capillary,
  RORB_LRRK1 = A1$RORB_LRRK1,
  PVALB_CEMIP = A1$PVALB_CEMIP,
  fociSense = C$fociSENSE
)

# Convert to long format
SP_long <- SP %>%
  pivot_longer(cols = c(  PCP4_NXPH2 ,PVALB_MYBPC1,Pericyte ,VIP_LAMA3, capillary, RORB_LRRK1, PVALB_CEMIP),
               names_to = "cell_type",
               values_to = "proportion")

# Compute Spearman correlations
corr_stats <- SP_long %>%
  group_by(cell_type) %>%
  summarise(
    rho = cor(fociSense, proportion, method = "spearman", use = "complete.obs"),
    pval = cor.test(fociSense, proportion, method = "spearman")$p.value
  )

# Format labels
corr_stats$label <- paste0("Rho = ", round(corr_stats$rho, 2), 
                           "\nP = ", signif(corr_stats$pval, 2))

# Set positions for annotation
corr_stats$x <- 0.3  # adjust as needed
corr_stats$y <- seq(0.01, 0.15, length.out = nrow(corr_stats))

# Define inverted colors
inverted_colors <- c(
  "PCP4_NXPH2" = "#00BFC4",     # cyan
  "PVALB_MYBPC1" = "red",
  "Pericyte" = "green",
  "VIP_LAMA3" = "orange",
  "capillary" = "pink",
  "RORB_LRRK1" = "purple",
  "PVALB_CEMIP" = "magenta"
)

# Plot with annotations
ggplot(SP_long, aes(x = fociSense, y = proportion, color = cell_type)) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = TRUE) +
  scale_color_manual(values = inverted_colors) +
  theme_minimal(base_size = 14) +
  labs(
    title = "Cell proportion vs C9 cell proportions",
    x = "fociSense density",
    y = "Cell proportion",
    color = "Cell Type"
  ) +
  geom_text(data = corr_stats,
            aes(x = x, y = y, label = label, color = cell_type),
            inherit.aes = FALSE,
            size = 5, hjust = 0)




### LNCRNA

# Load data
A <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/C9/theta.state_cellstate.csv", row.names = 1)
C <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/FTD_C9_neuropath_SOM.csv")
C$X <- gsub("long", "X", C$X)
A1 <- A[C$X,]

library(ggpubr)
library(ggplot2)
library(dplyr)
library(tidyr)

# Prepare the data
SP <- data.frame(
  Oligo = A1$Oligo,
  THEMIS_NR4A2 = A1$THEMIS_NR4A2,
  RORB_LRRK1 = A1$RORB_LRRK1,
  lncRNA = C$lncRNA
)

# Convert to long format
SP_long <- SP %>%
  pivot_longer(cols = c(   Oligo ,THEMIS_NR4A2,RORB_LRRK1),
               names_to = "cell_type",
               values_to = "proportion")

# Compute Spearman correlations
corr_stats <- SP_long %>%
  group_by(cell_type) %>%
  summarise(
    rho = cor(lncRNA, proportion, method = "spearman", use = "complete.obs"),
    pval = cor.test(lncRNA, proportion, method = "spearman")$p.value
  )

# Format labels
corr_stats$label <- paste0("Rho = ", round(corr_stats$rho, 2), 
                           "\nP = ", signif(corr_stats$pval, 2))

# Set positions for annotation
corr_stats$x <- 0.22  # adjust as needed
corr_stats$y <- seq(0.01, 0.15, length.out = nrow(corr_stats))

# Define inverted colors
inverted_colors <- c(
  "Oligo" = "#00BFC4",     # cyan
  "THEMIS_NR4A2" = "red",
  "RORB_LRRK1" = "purple"
)

# Plot with annotations
ggplot(SP_long, aes(x = lncRNA, y = proportion, color = cell_type)) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = TRUE) +
  scale_color_manual(values = inverted_colors) +
  theme_minimal(base_size = 14) +
  labs(
    title = "Cell proportion vs C9 cell proportions",
    x = "lncRNA density",
    y = "Cell proportion",
    color = "Cell Type"
  ) +
  geom_text(data = corr_stats,
            aes(x = x, y = y, label = label, color = cell_type),
            inherit.aes = FALSE,
            size = 5, hjust = 0)

## PolyGA

# Load data
A <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/C9/theta.state_cellstate.csv", row.names = 1)
C <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/FTD_C9_neuropath_SOM.csv")
C$X <- gsub("long", "X", C$X)
A1 <- A[C$X,]

library(ggpubr)
library(ggplot2)
library(dplyr)
library(tidyr)

# Prepare the data
SP <- data.frame(
  Oligo = A1$Oligo,
  THEMIS_TMEM233 = A1$THEMIS_TMEM233,
  PolyGA = C$polyGA
)

# Convert to long format
SP_long <- SP %>%
  pivot_longer(cols = c(THEMIS_TMEM233),
               names_to = "cell_type",
               values_to = "proportion")

# Compute Spearman correlations
corr_stats <- SP_long %>%
  group_by(cell_type) %>%
  summarise(
    rho = cor(PolyGA, proportion, method = "spearman", use = "complete.obs"),
    pval = cor.test(PolyGA, proportion, method = "spearman")$p.value
  )

# Format labels
corr_stats$label <- paste0("Rho = ", round(corr_stats$rho, 2), 
                           "\nP = ", signif(corr_stats$pval, 2))

# Set positions for annotation
corr_stats$x <- 0.000022  # adjust as needed
corr_stats$y <- seq(0.0001, 0.15, length.out = nrow(corr_stats))

# Define inverted colors
inverted_colors <- c("THEMIS_TMEM233" = "red")

# Plot with annotations
ggplot(SP_long, aes(x = PolyGA, y = proportion, color = cell_type)) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = TRUE) +
  scale_color_manual(values = inverted_colors) +
  theme_minimal(base_size = 14) +
  labs(
    title = "Cell proportion vs C9 cell proportions",
    x = "PolyGA density",
    y = "Cell proportion",
    color = "Cell Type"
  ) +
  geom_text(data = corr_stats,
            aes(x = x, y = y, label = label, color = cell_type),
            inherit.aes = FALSE,
            size = 5, hjust = 0)



## STMN2

# Load data
A <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/C9/theta.state_cellstate.csv", row.names = 1)
C <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/FTD_C9_neuropath_SOM.csv")
C$X <- gsub("long", "X", C$X)
A1 <- A[C$X,]

library(ggpubr)
library(ggplot2)
library(dplyr)
library(tidyr)

# Prepare the data
SP <- data.frame(
  Oligo = A1$Oligo,
  THEMIS_TMEM233 = A1$THEMIS_TMEM233,
  TLE4_CCBE1 = A1$TLE4_CCBE1,
  PolyGP = C$polyGP
)

# Convert to long format
SP_long <- SP %>%
  pivot_longer(cols = c(THEMIS_TMEM233, TLE4_CCBE1),
               names_to = "cell_type",
               values_to = "proportion")

# Compute Spearman correlations
corr_stats <- SP_long %>%
  group_by(cell_type) %>%
  summarise(
    rho = cor(PolyGP, proportion, method = "spearman", use = "complete.obs"),
    pval = cor.test(PolyGP, proportion, method = "spearman")$p.value
  )

# Format labels
corr_stats$label <- paste0("Rho = ", round(corr_stats$rho, 2), 
                           "\nP = ", signif(corr_stats$pval, 2))

# Set positions for annotation
corr_stats$x <- 0.000012  # adjust as needed
corr_stats$y <- seq(0.00006, 0.000015, length.out = nrow(corr_stats))

# Define inverted colors
inverted_colors <- c("THEMIS_TMEM233" = "red",
                     "TLE4_CCBE1" = "blue")

# Plot with annotations
ggplot(SP_long, aes(x = PolyGP, y = proportion, color = cell_type)) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = TRUE) +
  scale_color_manual(values = inverted_colors) +
  theme_minimal(base_size = 14) +
  labs(
    title = "Cell proportion vs C9 cell proportions",
    x = "PolyGP density",
    y = "Cell proportion",
    color = "Cell Type"
  ) +
  geom_text(data = corr_stats,
            aes(x = x, y = y, label = label, color = cell_type),
            inherit.aes = FALSE,
            size = 5, hjust = 0)


### STMN2

# Load data
A <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/C9/theta.state_cellstate.csv", row.names = 1)
C <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/FTD_C9_neuropath_SOM.csv")
C$X <- gsub("long", "X", C$X)
A1 <- A[C$X,]

library(ggpubr)
library(ggplot2)
library(dplyr)
library(tidyr)

# Prepare the data
SP <- data.frame(
  GFAP_pos = A1$GFAP.pos,
  THEMIS_TMEM233 = A1$THEMIS_TMEM233,
  TLE4_SEMA3D = A1$TLE4_SEMA3D,
  RORB_LRRK1 = A1$RORB_LRRK1,
  STMN2 = C$STMN2
)

# Convert to long format
SP_long <- SP %>%
  pivot_longer(cols = c( GFAP_pos, THEMIS_TMEM233, TLE4_SEMA3D, RORB_LRRK1),
               names_to = "cell_type",
               values_to = "proportion")

# Compute Spearman correlations
corr_stats <- SP_long %>%
  group_by(cell_type) %>%
  summarise(
    rho = cor(STMN2, proportion, method = "spearman", use = "complete.obs"),
    pval = cor.test(STMN2, proportion, method = "spearman")$p.value
  )

# Format labels
corr_stats$label <- paste0("Rho = ", round(corr_stats$rho, 2), 
                           "\nP = ", signif(corr_stats$pval, 2))

# Set positions for annotation
corr_stats$x <- 0.03  # adjust as needed
corr_stats$y <- seq(0.1, 0.18, length.out = nrow(corr_stats))

# Define inverted colors
inverted_colors <- c(
  "GFAP_pos" = "#00BFC4",     # cyan
  "THEMIS_TMEM233" = "red",
  "TLE4_SEMA3D" = "green",
  "RORB_LRRK1" = "purple"
)

# Plot with annotations
ggplot(SP_long, aes(x = STMN2, y = proportion, color = cell_type)) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = TRUE) +
  scale_color_manual(values = inverted_colors) +
  theme_minimal(base_size = 14) +
  labs(
    title = "Cell proportion vs C9 cell proportions",
    x = "STMN2 density",
    y = "Cell proportion",
    color = "Cell Type"
  ) +
  geom_text(data = corr_stats,
            aes(x = x, y = y, label = label, color = cell_type),
            inherit.aes = FALSE,
            size = 5, hjust = 0)











## OLD ##
###################################################################################################

#CELL PROPS


# V1

A <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/TDP/theta.state_original.csv", row.names = 1)
C <-  read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/FTD_TDP_neuropath_SOM.csv")

C$X <- gsub("long", "X", C$X)

rownames(A)

A1 <- A[C$X,]

SP <- data.frame(GFAP_pos = A1$GFAP.pos,
                 RORB_LRRK1 = A1$RORB_LRRK1,
                 pTDP43 = C$TDP43b)
library("ggpubr")

ggscatter(
  data = SP,
  x = "pTDP43",
  y = c("GFAP_pos", "RORB_LRRK1"),
  add = "reg.line",      # Adds a regression line
  conf.int = TRUE,       # Adds confidence interval
  cor.coef = TRUE,       # Adds correlation coefficient
  cor.method = "spearman",# Method for correlation
  xlab = "TDP-43 Levels",
  ylab = "Cell proportion",
  title = "Cell proportion vs pTDP-43 density"
)
## V2
library(ggplot2)
library(ggpubr)
library(dplyr)
library(tidyr)

# Prepare the data
SP <- data.frame(
  GFAP_pos = A1$GFAP.pos,
  RORB_LRRK1 = A1$RORB_LRRK1,
  pTDP43 = C$TDP43b
)

# Convert to long format for ggplot
SP_long <- SP %>%
  pivot_longer(cols = c(GFAP_pos, RORB_LRRK1),
               names_to = "cell_type",
               values_to = "proportion")

# Compute correlation statistics for each cell type
corr_stats <- SP_long %>%
  group_by(cell_type) %>%
  summarise(
    cor = cor(proportion, pTDP43, method = "spearman"),
    pval = cor.test(proportion, pTDP43, method = "spearman")$p.value,
    .groups = "drop"
  )

# Merge correlation stats back to the data for plotting
corr_labels <- corr_stats %>%
  mutate(
    label = paste0("r = ", round(cor, 2), "\np = ", signif(pval, 2)),
    x = max(SP$pTDP43) * 0.98,
    y = c(max(SP$GFAP_pos), max(SP$RORB_LRRK1)) * 1.05
  )

# Plot
ggplot(SP_long, aes(x = pTDP43, y = proportion, color = cell_type)) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = TRUE) +
  geom_text(data = corr_labels, aes(x = x, y = y, label = label, color = cell_type),
            inherit.aes = FALSE, hjust = 1) +
  theme_minimal(base_size = 14) +
  labs(
    title = "Cell proportion vs pTDP-43 density",
    x = "TDP-43 Levels",
    y = "Cell proportion",
    color = "Cell Type"
  )
## V3

library(ggplot2)
library(dplyr)
library(tidyr)

# Prepare the data
SP <- data.frame(
  GFAP_pos = A1$GFAP.pos,
  RORB_LRRK1 = A1$RORB_LRRK1,
  pTDP43 = C$TDP43b
)

# Convert to long format
SP_long <- SP %>%
  pivot_longer(cols = c(GFAP_pos, RORB_LRRK1),
               names_to = "cell_type",
               values_to = "proportion")

# Define inverted colors
inverted_colors <- c(
  "GFAP_pos" = "#00BFC4",     # Originally RORB_LRRK1 color (cyan)
  "RORB_LRRK1" = "#F8766D"    # Originally GFAP_pos color (red)
)

# Plot without correlation labels
ggplot(SP_long, aes(x = pTDP43, y = proportion, color = cell_type)) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = TRUE) +
  scale_color_manual(values = inverted_colors) +
  theme_minimal(base_size = 14) +
  labs(
    title = "Cell proportion vs pTDP-43 density",
    x = "pTDP-43 density",
    y = "Cell proportion",
    color = "Cell Type"
  )

########################################################################################################################################

# NPTX2

A <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/TDP/CELL STATE ORIGINAL/RORB_LRRK1.csv", row.names = 1)
C <-  read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/FTD_TDP_neuropath_SOM.csv")

C$X <- gsub("long", "X", C$X)

rownames(A)

A1 <- A[C$X,]

SP <- data.frame(NPTX2 = A1$NPTX2,
                 pTDP43 = C$TDP43b)

corr <- cor(SP$NPTX2, SP$pTDP43, method = "spearman")
# test_result <- cor.test(SP$NPTX2, SP$pTDP43, method = "spearman")
library("ggpubr")

ggscatter(
  data = SP,
  x = "NPTX2",
  y = "pTDP43",
  add = "reg.line",      # Adds a regression line
  conf.int = TRUE,       # Adds confidence interval
  cor.coef = TRUE,       # Adds correlation coefficient
  cor.method = "spearman",# Method for correlation
  xlab = "NPTX2 Expression",
  ylab = "TDP-43 Levels",
  title = "NPTX2 vs TDP-43"
)
## V2

library(ggplot2)

# Llegir dades
A <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/TDP/CELL STATE ORIGINAL/RORB_LRRK1.csv", row.names = 1)
C <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/FTD_TDP_neuropath_SOM.csv")

C$X <- gsub("long", "X", C$X)
A1 <- A[C$X, ]

# Preparar dades
SP <- data.frame(
  NPTX2 = A1$NPTX2,
  pTDP43 = C$TDP43b
)

# Definir el color manualment (mateix que RORB_LRRK1 anterior)
nptx2_color <- "#F8766D"

# Fer la gràfica
ggplot(SP, aes(x = pTDP43, y = NPTX2)) +
  geom_point(color = nptx2_color, size = 2) +
  geom_smooth(method = "lm", se = TRUE, color = nptx2_color) +
  theme_minimal(base_size = 14) +
  labs(
    title = "NPTX2 vs TDP-43",
    x = "pTDP-43 density",
    y = "NPTX2 Expression"
  )

#################################################################################################
#BOXPLOTS


### EXAMPLE URI

CELLS <- read.csv('/home/usuario/Documentos/AFTD/data/Elements/BlackTotalRNA/DESeq2/CellSubClusters_ALL_AAIC.csv')

CELLS$Cell_type_reordered <- factor(CELLS$Cell_type, levels=c("Ex8", "Ex4", "Mic2", "Ast2", "Ast3", "Oli5"))

png("/home/usuario/Documentos/AFTD/data/Elements/BlackTotalRNA/DESeq2/AAIC_3.pdf", width=20)

ggplot(CELLS,
       aes(x=Phenotype,
           y=Cell_proportion,
           fill=Phenotype)) +
  (theme_classic()) +   
  labs(x="", 
       y="Cell type proportion (%)")+  
  geom_boxplot(size=0.4, 
               outlier.alpha = 0.3, 
               alpha=0.5)+   
  facet_wrap(~`Cell_type_reordered`, 
             scales = "free", 
             nrow=1)+   
  theme_bw(base_size=12)+   
  theme(strip.text=element_text(face="bold"), 
        axis.title=element_text(size=12))+   
  scale_fill_manual(values=c("darkgoldenrod2", 
                             "deepskyblue4", 
                             "red", 
                             "black"))+  
  theme(panel.spacing = unit(5, "point"))+ 
  theme(legend.position="right")+ 
  scale_x_discrete(limits=rev(levels(CELLS$Phenotype)))

###### dades

# metadatas
SP_metadata <- readxl::read_xlsx("/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx")
case_legend <- read.delim("/media/jaumatell/datos/URI/BAYESPRISM_12_3/NEW_BULK/METADATA/Sample_info.txt", sep =  "\t", row.names = 1)
case_legend <- case_legend[case_legend$GROUP != "FTLD-TDP-C",]
case_legend$GROUP[case_legend$GROUP != "Control"] <- "TDP"

# RORB_LRRK1 (Sant pau)
sp1<-read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/TDP/theta.state_original.csv", row.names = 1)

# RORB_LRRK1 (Validació)
n1<-read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/NEW/theta.state_cellstate.csv", row.names = 1)

# NPTX2 (Sant pau)
sp2<-read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/TDP/CELL STATE ORIGINAL/RORB_LRRK1.csv", row.names = 1)

# NPTX2 (Validació)
n2<-read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/NEW/CELL STATE ORIGINAL/RORB_LRRK1.csv", row.names = 1)



####################### Sant pau LRRK1 prop #####################################
library(ggplot2)

sp1_ids <- gsub("X", "", rownames(sp1))
SP_metadata_filtered <- SP_metadata[SP_metadata$sample.ID %in% sp1_ids, ]
SP_metadata_filtered <- SP_metadata_filtered[match(sp1_ids, SP_metadata_filtered$sample.ID), ]
Pheno <- SP_metadata_filtered$group.ID
Cell_proportion <- sp1[rownames(sp1) %in% paste0("X", SP_metadata_filtered$sample.ID), "RORB_LRRK1"]
stopifnot(length(Pheno) == length(Cell_proportion))

CELLS <- data.frame(
  Phenotype = Pheno,
  Cell_proportion = Cell_proportion
)

colnames(CELLS)<- c("Phenotype", "Cell_proportion")
ggplot(CELLS,
       aes(x=Phenotype,
           y=Cell_proportion,
           fill=Phenotype)) +
  (theme_classic()) +   
  labs(x="", 
       y="Cell type proportion (%)")+  
  geom_boxplot(size=0.4, 
               outlier.alpha = 0.3, 
               alpha=0.5)+   
  #  facet_wrap(~`Cell_type_reordered`, 
  #             scales = "free", 
  #             nrow=1)+   
  theme_bw(base_size=12)+   
  theme(strip.text=element_text(face="bold"), 
        axis.title=element_text(size=12))+   
  scale_fill_manual(values=c("darkgoldenrod2", 
                             "deepskyblue4", 
                             "red", 
                             "black"))+  
  theme(panel.spacing = unit(5, "point"))+ 
  theme(legend.position="right")+ 
  scale_x_discrete(limits=rev(levels(CELLS$Phenotype)))


kruskal.test(Cell_proportion ~ Phenotype, data = CELLS)


###########################NPTX2 STPAU#############################

sp2_ids <- gsub("X", "", rownames(sp2))
SP_metadata_filtered <- SP_metadata[SP_metadata$sample.ID %in% sp2_ids, ]
SP_metadata_filtered <- SP_metadata_filtered[match(sp2_ids, SP_metadata_filtered$sample.ID), ]
Pheno <- SP_metadata_filtered$group.ID
Cell_proportion <- sp2[rownames(sp2) %in% paste0("X", SP_metadata_filtered$sample.ID), "NPTX2"]

stopifnot(length(Pheno) == length(Cell_proportion))

CELLS <- data.frame(
  Phenotype = Pheno,
  Cell_proportion = Cell_proportion
)

CELLS$sample.ID <- SP_metadata_filtered$sample.ID
colnames(CELLS)<- c("Phenotype", "Cell_proportion")

ggplot(CELLS,
       aes(x=Phenotype,
           y=Cell_proportion,
           fill=Phenotype)) +
  (theme_classic()) +   
  labs(x="", 
       y="NPTX2 expression")+  
  geom_boxplot(size=0.4, 
               outlier.alpha = 0.3, 
               alpha=0.5)+   
  #  facet_wrap(~`Cell_type_reordered`, 
  #             scales = "free", 
  #             nrow=1)+   
  theme_bw(base_size=12)+   
  theme(strip.text=element_text(face="bold"), 
        axis.title=element_text(size=12))+   
  scale_fill_manual(values=c("darkgoldenrod2", 
                             "deepskyblue4", 
                             "red", 
                             "black"))+  
  theme(panel.spacing = unit(5, "point"))+ 
  theme(legend.position="right")+ 
  scale_x_discrete(limits=rev(levels(CELLS$Phenotype)))


########################## RORB LRRK1 NEW##################################

n1_ids <- gsub("\\.", "-", rownames(n1))
common_ids <- intersect(rownames(case_legend), n1_ids)
case_legend_filtered <- case_legend[match(common_ids, rownames(case_legend)), ]
n1_filtered <- n1[match(common_ids, n1_ids), ]
Pheno <- case_legend_filtered$GROUP
Cell_proportion <- n1_filtered$RORB_LRRK1

CELLS <- data.frame(
  Phenotype = Pheno,
  Cell_proportion = Cell_proportion,
  sample.ID = common_ids  # optional, for checking alignment
)


ggplot(CELLS,
       aes(x=Phenotype,
           y=Cell_proportion,
           fill=Phenotype)) +
  (theme_classic()) +   
  labs(x="", 
       y="Cell type proportion (%)")+  
  geom_boxplot(size=0.4, 
               outlier.alpha = 0.3, 
               alpha=0.5)+   
  #  facet_wrap(~`Cell_type_reordered`, 
  #             scales = "free", 
  #             nrow=1)+   
  theme_bw(base_size=12)+   
  theme(strip.text=element_text(face="bold"), 
        axis.title=element_text(size=12))+   
  scale_fill_manual(values=c("darkgoldenrod2", 
                             "deepskyblue4", 
                             "red", 
                             "black"))+  
  theme(panel.spacing = unit(5, "point"))+ 
  theme(legend.position="right")+ 
  scale_x_discrete(limits=rev(levels(CELLS$Phenotype)))


########################## NPTX2 NEW##################################

n2_ids <- gsub("\\.", "-", rownames(n2))
common_ids <- intersect(rownames(case_legend), n2_ids)
case_legend_filtered <- case_legend[match(common_ids, rownames(case_legend)), ]
n2_filtered <- n2[match(common_ids, n2_ids), ]
Pheno <- case_legend_filtered$GROUP
Cell_proportion <- n2_filtered$NPTX2

CELLS <- data.frame(
  Phenotype = Pheno,
  Cell_proportion = Cell_proportion,
  sample.ID = common_ids
)

ggplot(CELLS,
       aes(x=Phenotype,
           y=Cell_proportion,
           fill=Phenotype)) +
  (theme_classic()) +   
  labs(x="", 
       y="NPTX2 expression")+  
  geom_boxplot(size=0.4, 
               outlier.alpha = 0.3, 
               alpha=0.5)+   
  #  facet_wrap(~`Cell_type_reordered`, 
  #             scales = "free", 
  #             nrow=1)+   
  theme_bw(base_size=12)+   
  theme(strip.text=element_text(face="bold"), 
        axis.title=element_text(size=12))+   
  scale_fill_manual(values=c("darkgoldenrod2", 
                             "deepskyblue4", 
                             "red", 
                             "black"))+  
  theme(panel.spacing = unit(5, "point"))+ 
  theme(legend.position="right")+ 
  scale_x_discrete(limits=rev(levels(CELLS$Phenotype)))

#pTDP-43

library(dplyr)
library(tidyr)
library(ggplot2)
library(readr)

# ----------------------
# 1. Read covariate data
# ----------------------
C <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/FTD_TDP_neuropath_SOM.csv")
C$X <- gsub("long", "X", C$X)  # Ensure matching sample IDs

# -----------------------------------------------
# 2. Define cell types and genes you want to load
# -----------------------------------------------
cell_types <- c("RORB_POU3F2", "SMC", "RORB_LRRK1", "GFAP-neg", "Capillary", "T_Cell")

# Define folder
folder_path <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/TDP/CELL STATE ORIGINAL/"

# -------------------------------
# 3. Load and bind only needed files
# -------------------------------
expression_list <- lapply(cell_types, function(cell_type) {
  file_path <- paste0(folder_path, cell_type, ".csv")
  expr_df <- read.csv(file_path, row.names = 1)
  expr_df$ID <- rownames(expr_df)
  expr_long <- pivot_longer(expr_df, cols = -ID, names_to = "gene", values_to = "SP")
  expr_long$cell_type <- cell_type
  return(expr_long)
})

# Combine into one dataframe
expr_data <- bind_rows(expression_list)

# ----------------------------
# 4. Merge with pTDP-43 values
# ----------------------------
expr_data <- expr_data %>%
  left_join(C %>% select(X, TDP43b), by = c("ID" = "X")) %>%
  rename(pTDP43 = TDP43b)

# ----------------------------
# 5. Filter genes of interest
# ----------------------------
genes_of_interest <- c("KRT5", "CCDC184", "CHI3L1", "NRN1", "CST3", "TMEM160", "VGF", "NPTX2", "ADRA1D")
expr_data_filtered <- expr_data %>% filter(gene %in% genes_of_interest)

# -----------------------------
# 6. Plot using facet_wrap
# -----------------------------
ggplot(expr_data_filtered, aes(x = pTDP43, y = SP)) +
  geom_point(aes(color = gene), size = 2) +
  geom_smooth(method = "lm", se = TRUE, color = "black", size = 0.5) +
  facet_wrap(~ cell_type + gene, scales = "free_y") +
  theme_minimal(base_size = 14) +
  labs(
    title = "Expression of Cell-State Markers vs. pTDP-43",
    x = "pTDP-43 density",
    y = "Gene expression (SP)"
  ) +
  theme(
    strip.text = element_text(face = "bold", size = 10),
    legend.position = "none"
  )

## STMN2

library(dplyr)
library(tidyr)
library(ggplot2)
library(readr)

# ----------------------
# 1. Read covariate data
# ----------------------
C <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/CORRELATION/COVARIABLES/FTD_TDP_neuropath_SOM.csv")
C$X <- gsub("long", "X", C$X)  # Ensure matching sample IDs

# -----------------------------------------------
# 2. Define cell types and genes you want to load
# -----------------------------------------------
cell_types <- c("RORB_POU3F2", "SMC", "RORB_LRRK1", "GFAP-neg", "Capillary", "T_Cell")

# Define folder
folder_path <- "/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/TDP/CELL STATE ORIGINAL/"

# -------------------------------
# 3. Load and bind only needed files
# -------------------------------
expression_list <- lapply(cell_types, function(cell_type) {
  file_path <- paste0(folder_path, cell_type, ".csv")
  expr_df <- read.csv(file_path, row.names = 1)
  expr_df$ID <- rownames(expr_df)
  expr_long <- pivot_longer(expr_df, cols = -ID, names_to = "gene", values_to = "SP")
  expr_long$cell_type <- cell_type
  return(expr_long)
})

# Combine into one dataframe
expr_data <- bind_rows(expression_list)

# ----------------------------
# 4. Merge with pTDP-43 values
# ----------------------------
expr_data <- expr_data %>%
  left_join(C %>% select(X, TDP43b), by = c("ID" = "X")) %>%
  rename(pTDP43 = TDP43b)

# ----------------------------
# 5. Filter genes of interest
# ----------------------------
genes_of_interest <- c(
  "KRT5", "CCDC184", "CHI3L1", "NRN1", "CST3", "TMEM160",
  "VGF", "NPTX2", "ADRA1D", "SOX11", "SLC24A4", "USH1C",
  "CPLX1", "C1QTNF4", "CCDC85B", "SCN9A", "RCAN2", "TAC1",
  "FOXJ1", "OR7D2", "FOXS1"
)

expr_data_filtered <- expr_data %>%
  filter(gene %in% genes_of_interest)

# -----------------------------
# 6. Plot using facet_wrap by cell type only
# -----------------------------
ggplot(expr_data_filtered, aes(x = pTDP43, y = SP, color = gene)) +
  geom_point(size = 2, alpha = 0.8) +
  geom_smooth(method = "lm", se = TRUE, size = 0.5, aes(group = gene), color = "black") +
  facet_wrap(~ cell_type, scales = "free_y") +
  theme_minimal(base_size = 14) +
  labs(
    title = "Expression of Cell-State Markers vs. pTDP-43",
    x = "pTDP-43 density",
    y = "Gene expression (SP)",
    color = "Gene"
  ) +
  theme(
    strip.text = element_text(face = "bold", size = 12),
    legend.position = "right"
  )
###########################################################
library(xlsx)
library(dplyr)
library(tidyr)
library(ggplot2)

# Load data
counts <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/TDP/theta.state_original.csv", row.names = 1)
rownames(counts) <- gsub("X", "", rownames(counts))

meta <- read.xlsx("/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx", 
                  row.names = 1, sheetIndex = 1)

# Filter metadata for groups of interest
meta <- meta[meta$group.ID %in% c("Healthy", "TDP"), ]
meta$group2.ID <- NULL

# Normalize counts rows to proportions summing to 1
counts_norm <- counts / rowSums(counts)

# Join counts and metadata by sample IDs
counts_norm$SampleID <- rownames(counts_norm)
meta$SampleID <- rownames(meta)

data_combined <- counts_norm %>%
  inner_join(meta, by = "SampleID") %>%
  filter(!is.na(group.ID))

# Sort samples by group.ID, keep order for plotting
data_combined <- data_combined %>%
  arrange(group.ID, SampleID) %>%
  mutate(SampleID = factor(SampleID, levels = SampleID))  # preserve order in plot

# Pivot longer for plotting
df_long <- data_combined %>%
  pivot_longer(cols = -c(SampleID, group.ID), 
               names_to = "CellState", 
               values_to = "Proportion")

# Define colors for groups
group_colors <- c("Healthy" = "blue", "TDP" = "red")

# Plot horizontal stacked barplot per sample
ggplot(df_long, aes(x = SampleID, y = Proportion, fill = CellState)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(x = "Sample", y = "Proportion of cells") +
  theme_minimal() +
  # Color y-axis labels by condition
  theme(axis.text.y = element_text(color = group_colors[df_long$group.ID][match(levels(df_long$SampleID), df_long$SampleID)])) +
  # Add manual legend for sample label colors
  guides(fill = guide_legend(title = "Cell State"))






library(dplyr)
library(tidyr)
library(ggplot2)

# Load data
counts <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/NEW/theta.state_cellstate.csv", row.names = 1)
rownames(counts) <- gsub("\\.", "-", rownames(counts))

meta <- read.delim("/media/jaumatell/datos/URI/BAYESPRISM_12_3/NEW_BULK/METADATA/Sample_info.txt", row.names = 1)

# Filter metadata for groups of interest
meta <- meta[meta$GROUP != "FTLD-TDP-C", ]
meta$GROUP[meta$GROUP == "Control"] <- "Healthy"
meta$GROUP[meta$GROUP != "Healthy"] <- "TDP"
meta <- meta[meta$GROUP %in% c("Healthy", "TDP"), ]
meta <- meta[, "GROUP", drop = FALSE]

# Normalize counts rows to proportions summing to 1
counts_norm <- counts / rowSums(counts)

# Join counts and metadata by sample IDs
counts_norm$SampleID <- rownames(counts_norm)
meta$SampleID <- rownames(meta)

data_combined <- counts_norm %>%
  inner_join(meta, by = "SampleID") %>%
  filter(!is.na(GROUP)) %>%
  arrange(GROUP, SampleID) %>%
  mutate(SampleID = factor(SampleID, levels = unique(SampleID)))  # preserve order

# Pivot longer for plotting
df_long <- data_combined %>%
  pivot_longer(cols = -c(SampleID, GROUP), names_to = "CellState", values_to = "Proportion")

# Define colors for groups
group_colors <- c("Healthy" = "blue", "TDP" = "red")

# Create named vector of colors for y-axis labels (sample names)
label_colors <- setNames(group_colors[data_combined$GROUP], data_combined$SampleID)

# Plot horizontal stacked barplot per sample
ggplot(df_long, aes(x = SampleID, y = Proportion, fill = CellState)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(x = "Sample", y = "Proportion of cells") +
  theme_minimal() +
  theme(axis.text.y = element_text(color = label_colors)) +
  guides(fill = guide_legend(title = "Cell State"))


#######################################################################
# Cell props New



CELLS <- data.frame(
  Phenotype = Pheno,
  Cell_proportion = Cell_proportion,
  sample.ID = common_ids
)

ggplot(CELLS,
       aes(x=Phenotype,
           y=Cell_proportion,
           fill=Phenotype)) +
  (theme_classic()) +   
  labs(x="", 
       y="NPTX2 expression")+  
  geom_boxplot(size=0.4, 
               outlier.alpha = 0.3, 
               alpha=0.5)+   
  #  facet_wrap(~`Cell_type_reordered`, 
  #             scales = "free", 
  #             nrow=1)+   
  theme_bw(base_size=12)+   
  theme(strip.text=element_text(face="bold"), 
        axis.title=element_text(size=12))+   
  scale_fill_manual(values=c("darkgoldenrod2", 
                             "deepskyblue4", 
                             "red", 
                             "black"))+  
  theme(panel.spacing = unit(5, "point"))+ 
  theme(legend.position="right")+ 
  scale_x_discrete(limits=rev(levels(CELLS$Phenotype)))


SP_metadata <- readxl::read_xlsx("/media/jaumatell/datos/URI/BAYESPRISM_12_3/FTLD_BULK/METADATA/decoder_DeSeq2_FTD_FINAL.xlsx")
case_legend <- read.delim("/media/jaumatell/datos/URI/BAYESPRISM_12_3/NEW_BULK/METADATA/Sample_info.txt", sep =  "\t", row.names = 1)
case_legend <- case_legend[case_legend$GROUP != "FTLD-TDP-C",]
case_legend$GROUP[case_legend$GROUP != "Control"] <- "TDP"

# RORB_LRRK1 (Sant pau)
sp1<-read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/TDP/theta.state_original.csv", row.names = 1)

# RORB_LRRK1 (Validació)
n1<-read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/NEW/theta.state_cellstate.csv", row.names = 1)

# NPTX2 (Sant pau)
sp2<-read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/FTLD/TDP/CELL STATE ORIGINAL/RORB_LRRK1.csv", row.names = 1)

# NPTX2 (Validació)
n2<-read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/NEW/CELL STATE ORIGINAL/RORB_LRRK1.csv", row.names = 1)




case_legend <- read.delim("/media/jaumatell/datos/URI/BAYESPRISM_12_3/NEW_BULK/METADATA/Sample_info.txt", sep = "\t", row.names = 1)
case_legend <- case_legend[case_legend$GROUP != "FTLD-TDP-C", ]
case_legend$GROUP[case_legend$GROUP != "Control"] <- "TDP"

n1 <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/NEW/theta.state_cellstate.csv", row.names = 1)
n2 <- read.csv("/media/jaumatell/datos/URI/BAYESPRISM_12_3/BAYESPRISM/NEW/CELL STATE ORIGINAL/RORB_LRRK1.csv", row.names = 1)

n2_ids <- gsub("\\.", "-", rownames(n2))
common_ids <- intersect(rownames(case_legend), n2_ids)
case_legend_filtered <- case_legend[match(common_ids, rownames(case_legend)), ]
n2_filtered <- n2[match(common_ids, n2_ids), ]
Pheno <- case_legend_filtered$GROUP

target_cell_states <- c(
  "VAT1L_EYA4", "PVALB_CEMIP", "Arterial", "CUX2_RORB", "PCP4_NXPH2",
  "GFAP.pos", "SST_ADAMTS19", "PVALB_MYBPC1", "CDH4_CCK", "LAMP5_PMEPA1",
  "PVALB_PTHLH", "DISC1_CCK", "RORB_POU3F2", "SST_GALNT14", "THEMIS_TMEM233",
  "RORB_LRRK1", "DISC1_RELN", "LAMP5_CA3", "VIP_HTR2C", "VIP_LAMA3", "SST_BRINP3"
)

nice_names <- c(
  "VAT1L EYA4", "PVALB CEMIP", "Arterial", "CUX2 RORB", "PCP4 NXPH2",
  "GFAP+", "SST ADAMTS19", "PVALB MYBPC1", "CDH4 CCK", "LAMP5 PMEPA1",
  "PVALB PTHLH", "DISC1 CCK", "RORB POU3F2", "SST GALNT14", "THEMIS TMEM233",
  "RORB LRRK1", "DISC1 RELN", "LAMP5 CA3", "VIP HTR2C", "VIP LAMA3", "SST BRINP3"
)

cell_data <- data.frame()

for (i in seq_along(target_cell_states)) {
  cell_type <- target_cell_states[i]
  label <- nice_names[i]
  cell_prop <- n1[rownames(n1) %in% gsub("-" , "\\.", rownames(case_legend_filtered)), cell_type]
  temp_df <- data.frame(
    Phenotype = Pheno,
    Cell_proportion = cell_prop,
    Cell_state = label
  )
  cell_data <- rbind(cell_data, temp_df)
}

cell_data$Phenotype <- factor(cell_data$Phenotype, levels = c("Control", "TDP"))

library(dplyr)
library(ggplot2)

max_y_per_state <- cell_data %>%
  group_by(Cell_state) %>%
  summarise(y = max(Cell_proportion, na.rm = TRUE) * 0.95)

annotation_df <- data.frame(
  Cell_state = c(
    "VAT1L EYA4", "PVALB CEMIP", "Arterial", "CUX2 RORB", "PCP4 NXPH2",
    "GFAP+", "SST ADAMTS19", "PVALB MYBPC1", "CDH4 CCK", "LAMP5 PMEPA1",
    "PVALB PTHLH", "DISC1 CCK", "RORB POU3F2", "SST GALNT14", "THEMIS TMEM233",
    "RORB LRRK1", "DISC1 RELN", "LAMP5 CA3", "VIP HTR2C", "VIP LAMA3", "SST BRINP3"
  ),
  label = c(
    "P = 0.0001\nFC = 0.04", "P = 0.0004\nFC = 0.60", "P = 0.0007\nFC = 1.65", "P = 0.0012\nFC = 0.50", "P = 0.0017\nFC = 0.58",
    "P = 0.0032\nFC = 115.25", "P = 0.0046\nFC = 0.71", "P = 0.0046\nFC = 0.62", "P = 0.0054\nFC = 0.60", "P = 0.0082\nFC = 0.97",
    "P = 0.0085\nFC = 0.69", "P = 0.0092\nFC = 0.67", "P = 0.0099\nFC = 0.62", "P = 0.0119\nFC = 0.70", "P = 0.0137\nFC = 0.65",
    "P = 0.0164\nFC = 0.63", "P = 0.0239\nFC = 0.72", "P = 0.0256\nFC = 0.62", "P = 0.0291\nFC = 0.67", "P = 0.0331\nFC = 0.64", "P = 0.0353\nFC = 0.73"
  ),
  x = 1.5
)

annotation_df <- left_join(annotation_df, max_y_per_state, by = "Cell_state")

ggplot(cell_data, aes(x = Phenotype, y = Cell_proportion, fill = Phenotype)) +
  geom_boxplot(size = 0.4, outlier.alpha = 0.3, alpha = 0.5) +
  facet_wrap(~Cell_state, scales = "free", nrow = 3) +
  labs(x = "", y = "Cell type proportion (%)") +
  scale_fill_manual(values = c("Control" = "deepskyblue4", "TDP" = "darkgoldenrod2")) +
  geom_text(data = annotation_df, aes(x = x, y = y, label = label), inherit.aes = FALSE, size = 3.5) +
  theme_bw(base_size = 12) +
  theme(
    strip.text = element_text(face = "bold"),
    axis.title = element_text(size = 12),
    panel.spacing = unit(5, "pt"),
    legend.position = "right"
  )
```

```{r fig_additional_scripts_1, echo=FALSE, eval=FALSE}
# knitr::include_graphics("figures/fig_additional_scripts_1.png")
```

```{r fig_additional_scripts_2, echo=FALSE, eval=FALSE}
# knitr::include_graphics("figures/fig_additional_scripts_2.png")
```
